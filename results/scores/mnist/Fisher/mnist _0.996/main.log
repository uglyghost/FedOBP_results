==================== FedDpa ====================                               
Experiment Arguments:                                                          
{
    'method': 'feddpa',
    'dataset': {
        'name': 'mnist',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'mnist-100clients-0%IID-Dir(0.1)-seed42',
        'alpha': 0.1,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'serial',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': None,
        'num_gpus': None,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 200,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 0,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'feddpa': {
        'fisher_threshold': 0.996
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 0.2368 -> 0.0757  accuracy: 91.78% -> 97.95%     
client [81] (testset)   loss: 0.1132 -> 0.0165  accuracy: 98.15% -> 99.38%     
client [21] (testset)   loss: 0.1904 -> 0.0436  accuracy: 94.12% -> 99.02%     
client [68] (testset)   loss: 0.1217 -> 0.0776  accuracy: 96.61% -> 98.31%     
client [93] (testset)   loss: 0.1915 -> 0.0181  accuracy: 96.77% -> 100.00%    
client [31] (testset)   loss: 0.2232 -> 0.1019  accuracy: 85.71% -> 100.00%    
client [20] (testset)   loss: 0.2967 -> 0.1478  accuracy: 91.86% -> 95.02%     
client [59] (testset)   loss: 0.2659 -> 0.0614  accuracy: 87.50% -> 100.00%    
client [48] (testset)   loss: 0.1378 -> 0.0178  accuracy: 94.17% -> 99.03%     
client [34] (testset)   loss: 0.1022 -> 0.4139  accuracy: 94.44% -> 94.44%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 0.0262 -> 0.0157  accuracy: 99.09% -> 99.64%     
client [99] (testset)   loss: 0.3306 -> 0.0363  accuracy: 90.48% -> 100.00%    
client [67] (testset)   loss: 0.2121 -> 0.0000  accuracy: 94.59% -> 100.00%    
client [0]  (testset)   loss: 0.1794 -> 0.0076  accuracy: 92.45% -> 100.00%    
client [76] (testset)   loss: 0.3222 -> 0.0477  accuracy: 89.61% -> 98.70%     
client [41] (testset)   loss: 0.1490 -> 0.0113  accuracy: 94.74% -> 98.95%     
client [62] (testset)   loss: 0.1575 -> 0.0206  accuracy: 93.92% -> 98.90%     
client [2]  (testset)   loss: 0.8479 -> 0.0104  accuracy: 73.57% -> 99.62%     
client [14] (testset)   loss: 0.1170 -> 0.0160  accuracy: 95.83% -> 99.31%     
client [46] (testset)   loss: 0.0978 -> 0.0369  accuracy: 97.52% -> 98.87%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 0.0398 -> 0.1378  accuracy: 98.65% -> 97.30%     
client [68] (testset)   loss: 0.0893 -> 0.0683  accuracy: 96.61% -> 98.31%     
client [57] (testset)   loss: 0.0513 -> 0.0142  accuracy: 99.03% -> 99.52%     
client [17] (testset)   loss: 0.0310 -> 0.0186  accuracy: 98.44% -> 99.61%     
client [54] (testset)   loss: 0.0731 -> 0.1359  accuracy: 97.67% -> 95.35%     
client [23] (testset)   loss: 0.1981 -> 0.0016  accuracy: 88.57% -> 100.00%    
client [35] (testset)   loss: 0.0706 -> 0.0152  accuracy: 98.04% -> 100.00%    
client [59] (testset)   loss: 0.0032 -> 0.0131  accuracy: 100.00% -> 100.00%   
client [31] (testset)   loss: 0.3705 -> 0.0922  accuracy: 85.71% -> 100.00%    
client [9]  (testset)   loss: 0.0725 -> 0.0395  accuracy: 97.39% -> 98.70%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 0.0455 -> 0.0130  accuracy: 98.61% -> 99.72%     
client [33] (testset)   loss: 0.1132 -> 0.0592  accuracy: 96.90% -> 99.18%     
client [16] (testset)   loss: 0.0717 -> 0.0007  accuracy: 98.57% -> 100.00%    
client [44] (testset)   loss: 0.1399 -> 0.0366  accuracy: 95.82% -> 98.81%     
client [8]  (testset)   loss: 0.1144 -> 0.0073  accuracy: 95.24% -> 100.00%    
client [31] (testset)   loss: 0.7773 -> 0.0637  accuracy: 85.71% -> 100.00%    
client [47] (testset)   loss: 0.1802 -> 0.0012  accuracy: 95.45% -> 100.00%    
client [36] (testset)   loss: 0.1663 -> 0.0292  accuracy: 95.94% -> 98.98%     
client [20] (testset)   loss: 0.2373 -> 0.1014  accuracy: 94.12% -> 96.38%     
client [56] (testset)   loss: 0.0487 -> 0.0136  accuracy: 98.92% -> 98.92%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 0.0461 -> 0.0050  accuracy: 98.53% -> 100.00%    
client [60] (testset)   loss: 0.1866 -> 0.0591  accuracy: 94.00% -> 99.00%     
client [28] (testset)   loss: 0.0032 -> 0.0002  accuracy: 100.00% -> 100.00%   
client [25] (testset)   loss: 0.0673 -> 0.0011  accuracy: 96.55% -> 100.00%    
client [58] (testset)   loss: 0.0682 -> 0.0460  accuracy: 96.45% -> 98.58%     
client [44] (testset)   loss: 0.1052 -> 0.0333  accuracy: 96.72% -> 99.10%     
client [39] (testset)   loss: 0.0211 -> 0.0044  accuracy: 99.26% -> 100.00%    
client [29] (testset)   loss: 0.0507 -> 0.0287  accuracy: 97.79% -> 99.26%     
client [3]  (testset)   loss: 0.1078 -> 0.0176  accuracy: 96.02% -> 99.58%     
client [84] (testset)   loss: 0.0521 -> 0.0079  accuracy: 100.00% -> 100.00%   
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 0.0604 -> 0.0049  accuracy: 99.02% -> 100.00%    
client [84] (testset)   loss: 0.0052 -> 0.0041  accuracy: 100.00% -> 100.00%   
client [10] (testset)   loss: 0.0051 -> 0.0018  accuracy: 100.00% -> 100.00%   
client [36] (testset)   loss: 0.0505 -> 0.0356  accuracy: 98.98% -> 98.98%     
client [65] (testset)   loss: 0.0873 -> 0.0343  accuracy: 98.74% -> 98.74%     
client [81] (testset)   loss: 0.0824 -> 0.0173  accuracy: 98.77% -> 99.38%     
client [79] (testset)   loss: 0.0137 -> 0.0009  accuracy: 98.46% -> 100.00%    
client [42] (testset)   loss: 0.1309 -> 0.1351  accuracy: 97.81% -> 98.36%     
client [11] (testset)   loss: 0.0000 -> 0.0008  accuracy: 100.00% -> 100.00%   
client [96] (testset)   loss: 0.0300 -> 0.0012  accuracy: 98.04% -> 100.00%    
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 0.1010 -> 0.0421  accuracy: 97.62% -> 97.62%     
client [53] (testset)   loss: 0.0125 -> 0.0103  accuracy: 100.00% -> 100.00%   
client [52] (testset)   loss: 0.0712 -> 0.0000  accuracy: 97.37% -> 100.00%    
client [42] (testset)   loss: 0.1411 -> 0.1563  accuracy: 96.17% -> 98.36%     
client [69] (testset)   loss: 0.0254 -> 0.0101  accuracy: 99.09% -> 99.64%     
client [59] (testset)   loss: 0.0009 -> 0.0037  accuracy: 100.00% -> 100.00%   
client [7]  (testset)   loss: 0.0274 -> 0.0002  accuracy: 100.00% -> 100.00%   
client [26] (testset)   loss: 0.0557 -> 0.0655  accuracy: 95.83% -> 95.83%     
client [49] (testset)   loss: 0.0090 -> 0.0004  accuracy: 99.55% -> 100.00%    
client [98] (testset)   loss: 0.1221 -> 0.0092  accuracy: 91.18% -> 100.00%    
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 0.0146 -> 0.0054  accuracy: 100.00% -> 100.00%   
client [47] (testset)   loss: 0.0830 -> 0.0018  accuracy: 96.59% -> 100.00%    
client [21] (testset)   loss: 0.0303 -> 0.0077  accuracy: 99.02% -> 100.00%    
client [77] (testset)   loss: 0.0871 -> 0.0416  accuracy: 95.89% -> 98.63%     
client [95] (testset)   loss: 0.0250 -> 0.0003  accuracy: 99.28% -> 100.00%    
client [91] (testset)   loss: 0.0447 -> 0.0099  accuracy: 98.51% -> 99.67%     
client [14] (testset)   loss: 0.0604 -> 0.0290  accuracy: 97.92% -> 98.61%     
client [99] (testset)   loss: 0.1877 -> 0.0145  accuracy: 95.24% -> 100.00%    
client [20] (testset)   loss: 0.1219 -> 0.0746  accuracy: 96.83% -> 97.29%     
client [39] (testset)   loss: 0.0304 -> 0.0017  accuracy: 98.77% -> 100.00%    
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 0.0084 -> 0.0000  accuracy: 100.00% -> 100.00%   
client [62] (testset)   loss: 0.0059 -> 0.0010  accuracy: 100.00% -> 100.00%   
client [71] (testset)   loss: 0.0070 -> 0.0017  accuracy: 99.54% -> 100.00%    
client [97] (testset)   loss: 0.0151 -> 0.0008  accuracy: 99.33% -> 100.00%    
client [30] (testset)   loss: 0.0015 -> 0.0115  accuracy: 100.00% -> 100.00%   
client [88] (testset)   loss: 0.2337 -> 0.0022  accuracy: 97.06% -> 100.00%    
client [60] (testset)   loss: 0.1683 -> 0.0608  accuracy: 94.00% -> 99.00%     
client [82] (testset)   loss: 0.0135 -> 0.0134  accuracy: 100.00% -> 100.00%   
client [91] (testset)   loss: 0.0232 -> 0.0098  accuracy: 99.34% -> 99.67%     
client [57] (testset)   loss: 0.0078 -> 0.0060  accuracy: 99.52% -> 99.52%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 0.0938 -> 0.0011  accuracy: 100.00% -> 100.00%   
client [15] (testset)   loss: 0.1914 -> 0.0455  accuracy: 94.50% -> 99.08%     
client [71] (testset)   loss: 0.0098 -> 0.0012  accuracy: 99.54% -> 100.00%    
client [97] (testset)   loss: 0.0144 -> 0.0008  accuracy: 99.00% -> 100.00%    
client [53] (testset)   loss: 0.0291 -> 0.0219  accuracy: 96.00% -> 100.00%    
client [77] (testset)   loss: 0.1098 -> 0.0439  accuracy: 97.26% -> 98.63%     
client [76] (testset)   loss: 0.0064 -> 0.0403  accuracy: 100.00% -> 98.70%    
client [79] (testset)   loss: 0.0157 -> 0.0010  accuracy: 100.00% -> 100.00%   
client [28] (testset)   loss: 0.0015 -> 0.0002  accuracy: 100.00% -> 100.00%   
client [99] (testset)   loss: 0.2030 -> 0.0109  accuracy: 90.48% -> 100.00%    
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 0.0449 -> 0.0009  accuracy: 98.33% -> 100.00%    
client [86] (testset)   loss: 0.0836 -> 0.0016  accuracy: 96.16% -> 100.00%    
client [34] (testset)   loss: 0.0363 -> 0.0974  accuracy: 100.00% -> 94.44%    
client [73] (testset)   loss: 0.0038 -> 0.0435  accuracy: 100.00% -> 100.00%   
client [5]  (testset)   loss: 0.0675 -> 0.0264  accuracy: 97.93% -> 98.62%     
client [96] (testset)   loss: 0.0484 -> 0.0012  accuracy: 96.08% -> 100.00%    
client [22] (testset)   loss: 0.0461 -> 0.0005  accuracy: 97.87% -> 100.00%    
client [60] (testset)   loss: 0.1892 -> 0.0597  accuracy: 94.00% -> 99.00%     
client [66] (testset)   loss: 0.0210 -> 0.0184  accuracy: 98.23% -> 99.12%     
client [83] (testset)   loss: 0.0981 -> 0.0797  accuracy: 97.51% -> 97.51%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 0.0211 -> 0.0756  accuracy: 100.00% -> 98.70%    
client [65] (testset)   loss: 0.0907 -> 0.0445  accuracy: 98.32% -> 98.74%     
client [95] (testset)   loss: 0.0118 -> 0.0005  accuracy: 99.64% -> 100.00%    
client [17] (testset)   loss: 0.0087 -> 0.0174  accuracy: 100.00% -> 99.61%    
client [8]  (testset)   loss: 0.2323 -> 0.0823  accuracy: 95.24% -> 97.62%     
client [35] (testset)   loss: 0.0743 -> 0.0242  accuracy: 98.04% -> 99.02%     
client [98] (testset)   loss: 0.0740 -> 0.0169  accuracy: 97.06% -> 100.00%    
client [53] (testset)   loss: 0.0377 -> 0.0156  accuracy: 96.00% -> 100.00%    
client [43] (testset)   loss: 0.1095 -> 0.0791  accuracy: 98.93% -> 97.86%     
client [64] (testset)   loss: 0.0335 -> 0.0182  accuracy: 98.89% -> 99.44%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 0.0267 -> 0.0152  accuracy: 99.02% -> 99.02%     
client [88] (testset)   loss: 0.1347 -> 0.0017  accuracy: 97.06% -> 100.00%    
client [38] (testset)   loss: 0.0783 -> 0.0359  accuracy: 98.25% -> 98.25%     
client [3]  (testset)   loss: 0.0547 -> 0.0131  accuracy: 98.32% -> 99.58%     
client [5]  (testset)   loss: 0.0643 -> 0.0128  accuracy: 97.93% -> 99.31%     
client [41] (testset)   loss: 0.0211 -> 0.0011  accuracy: 98.95% -> 100.00%    
client [7]  (testset)   loss: 0.0509 -> 0.0029  accuracy: 100.00% -> 100.00%   
client [37] (testset)   loss: 0.0939 -> 0.0878  accuracy: 96.54% -> 96.97%     
client [45] (testset)   loss: 0.0275 -> 0.0176  accuracy: 99.08% -> 99.69%     
client [47] (testset)   loss: 0.0909 -> 0.0005  accuracy: 96.59% -> 100.00%    
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 0.0107 -> 0.0001  accuracy: 100.00% -> 100.00%   
client [11] (testset)   loss: 0.0000 -> 0.0000  accuracy: 100.00% -> 100.00%   
client [37] (testset)   loss: 0.0943 -> 0.0837  accuracy: 96.97% -> 96.97%     
client [41] (testset)   loss: 0.0308 -> 0.0006  accuracy: 98.95% -> 100.00%    
client [95] (testset)   loss: 0.0320 -> 0.0001  accuracy: 98.92% -> 100.00%    
client [53] (testset)   loss: 0.0588 -> 0.0183  accuracy: 96.00% -> 100.00%    
client [22] (testset)   loss: 0.0209 -> 0.0015  accuracy: 97.87% -> 100.00%    
client [25] (testset)   loss: 0.0435 -> 0.0002  accuracy: 96.55% -> 100.00%    
client [69] (testset)   loss: 0.0464 -> 0.0077  accuracy: 98.54% -> 99.64%     
client [46] (testset)   loss: 0.0223 -> 0.0195  accuracy: 99.10% -> 99.55%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 0.0772 -> 0.0131  accuracy: 97.73% -> 98.86%     
client [69] (testset)   loss: 0.0483 -> 0.0066  accuracy: 98.91% -> 99.64%     
client [82] (testset)   loss: 0.0210 -> 0.0136  accuracy: 98.59% -> 100.00%    
client [45] (testset)   loss: 0.0502 -> 0.0216  accuracy: 97.85% -> 99.69%     
client [7]  (testset)   loss: 0.0521 -> 0.0070  accuracy: 100.00% -> 100.00%   
client [50] (testset)   loss: 0.0738 -> 0.0052  accuracy: 97.95% -> 100.00%    
client [35] (testset)   loss: 0.0925 -> 0.0248  accuracy: 97.06% -> 99.02%     
client [24] (testset)   loss: 0.0213 -> 0.0392  accuracy: 100.00% -> 98.65%    
client [15] (testset)   loss: 0.1195 -> 0.0406  accuracy: 98.17% -> 99.08%     
client [58] (testset)   loss: 0.1087 -> 0.0424  accuracy: 95.74% -> 98.58%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 0.0144 -> 0.0013  accuracy: 99.03% -> 100.00%    
client [76] (testset)   loss: 0.0114 -> 0.0541  accuracy: 100.00% -> 98.70%    
client [67] (testset)   loss: 0.0281 -> 0.0000  accuracy: 100.00% -> 100.00%   
client [37] (testset)   loss: 0.1033 -> 0.0899  accuracy: 96.54% -> 97.40%     
client [58] (testset)   loss: 0.0884 -> 0.0695  accuracy: 97.16% -> 98.58%     
client [64] (testset)   loss: 0.0640 -> 0.0378  accuracy: 98.06% -> 99.17%     
client [77] (testset)   loss: 0.0847 -> 0.0531  accuracy: 97.26% -> 98.63%     
client [55] (testset)   loss: 0.0224 -> 0.0036  accuracy: 99.49% -> 99.74%     
client [12] (testset)   loss: 0.0565 -> 0.0220  accuracy: 98.02% -> 99.01%     
client [89] (testset)   loss: 0.0094 -> 0.0065  accuracy: 100.00% -> 100.00%   
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 0.0003 -> 0.0002  accuracy: 100.00% -> 100.00%   
client [51] (testset)   loss: 0.0259 -> 0.0039  accuracy: 97.14% -> 100.00%    
client [8]  (testset)   loss: 0.5376 -> 0.0009  accuracy: 85.71% -> 100.00%    
client [18] (testset)   loss: 0.0325 -> 0.0216  accuracy: 99.31% -> 99.66%     
client [94] (testset)   loss: 0.0005 -> 0.0000  accuracy: 100.00% -> 100.00%   
client [81] (testset)   loss: 0.0652 -> 0.0295  accuracy: 98.77% -> 99.38%     
client [3]  (testset)   loss: 0.0278 -> 0.0087  accuracy: 98.95% -> 99.58%     
client [11] (testset)   loss: 0.0000 -> 0.0001  accuracy: 100.00% -> 100.00%   
client [95] (testset)   loss: 0.0176 -> 0.0011  accuracy: 99.64% -> 100.00%    
client [67] (testset)   loss: 0.0177 -> 0.0001  accuracy: 100.00% -> 100.00%   
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 0.0217 -> 0.0051  accuracy: 99.02% -> 100.00%    
client [79] (testset)   loss: 0.0074 -> 0.0003  accuracy: 100.00% -> 100.00%   
client [58] (testset)   loss: 0.0269 -> 0.0147  accuracy: 99.29% -> 99.29%     
client [88] (testset)   loss: 0.0872 -> 0.0165  accuracy: 97.06% -> 98.53%     
client [46] (testset)   loss: 0.0268 -> 0.0189  accuracy: 99.10% -> 99.55%     
client [11] (testset)   loss: 0.0000 -> 0.0000  accuracy: 100.00% -> 100.00%   
client [55] (testset)   loss: 0.0555 -> 0.0061  accuracy: 97.96% -> 99.74%     
client [13] (testset)   loss: 0.1895 -> 0.0033  accuracy: 95.83% -> 100.00%    
client [31] (testset)   loss: 0.0028 -> 0.0010  accuracy: 100.00% -> 100.00%   
client [75] (testset)   loss: 0.0978 -> 0.0188  accuracy: 97.83% -> 99.38%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 0.0520 -> 0.0197  accuracy: 96.30% -> 100.00%    
client [7]  (testset)   loss: 0.0024 -> 0.0003  accuracy: 100.00% -> 100.00%   
client [57] (testset)   loss: 0.0014 -> 0.0001  accuracy: 100.00% -> 100.00%   
client [13] (testset)   loss: 0.0497 -> 0.0074  accuracy: 95.83% -> 100.00%    
client [43] (testset)   loss: 0.1088 -> 0.0582  accuracy: 98.40% -> 98.93%     
client [91] (testset)   loss: 0.0344 -> 0.0103  accuracy: 99.01% -> 99.83%     
client [10] (testset)   loss: 0.0035 -> 0.0009  accuracy: 100.00% -> 100.00%   
client [64] (testset)   loss: 0.0224 -> 0.0132  accuracy: 99.17% -> 99.44%     
client [82] (testset)   loss: 0.0046 -> 0.0028  accuracy: 100.00% -> 100.00%   
client [22] (testset)   loss: 0.0126 -> 0.0033  accuracy: 100.00% -> 100.00%   
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 0.1051 -> 0.0587  accuracy: 95.93% -> 98.64%     
client [23] (testset)   loss: 0.0005 -> 0.0000  accuracy: 100.00% -> 100.00%   
client [88] (testset)   loss: 0.1208 -> 0.0102  accuracy: 97.06% -> 100.00%    
client [98] (testset)   loss: 0.0482 -> 0.0300  accuracy: 97.06% -> 97.06%     
client [79] (testset)   loss: 0.0028 -> 0.0004  accuracy: 100.00% -> 100.00%   
client [21] (testset)   loss: 0.0135 -> 0.0105  accuracy: 99.02% -> 99.02%     
client [92] (testset)   loss: 0.0000 -> 0.0000  accuracy: 100.00% -> 100.00%   
client [56] (testset)   loss: 0.0215 -> 0.0000  accuracy: 98.92% -> 100.00%    
client [5]  (testset)   loss: 0.0214 -> 0.0093  accuracy: 98.62% -> 99.31%     
client [52] (testset)   loss: 0.0085 -> 0.0000  accuracy: 100.00% -> 100.00%   
FedDpa's average time taken by each global epoch: 0 min 2.67 sec.              
FedDpa's total running time: 0 h 8 m 59 s.                                     
==================== FedDpa Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.0661 -> 0.0000",                                    
                "accuracy": "98.08% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.0500 -> 0.0000",                                    
                "accuracy": "98.49% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedDpa Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 98.49% at epoch 200                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
