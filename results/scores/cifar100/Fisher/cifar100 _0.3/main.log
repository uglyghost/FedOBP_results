==================== FedDpa ====================                               
Experiment Arguments:                                                          
{
    'method': 'feddpa',
    'dataset': {
        'name': 'cifar100',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'cifar100-100clients-0%IID-use20superclasses-Dir(0.1)-seed42',
        'super_class': False,
        'alpha': 0.1,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'parallel',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': 32.0,
        'num_gpus': 1.0,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 200,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 0,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'feddpa': {
        'fisher_threshold': 0.3
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [81] (testset)   loss: 4.5837 -> 2.7322  accuracy: 0.66% -> 32.45%      
client [77] (testset)   loss: 2.1381 -> 1.9389  accuracy: 46.07% -> 49.44%     
client [21] (testset)   loss: 4.6034 -> 2.5990  accuracy: 1.36% -> 30.61%      
client [68] (testset)   loss: 2.5558 -> 2.2242  accuracy: 29.41% -> 40.76%     
client [93] (testset)   loss: 4.6055 -> 2.6883  accuracy: 0.00% -> 34.40%      
client [31] (testset)   loss: 2.3763 -> 2.2266  accuracy: 34.74% -> 43.68%     
client [20] (testset)   loss: 4.5329 -> 2.2769  accuracy: 0.00% -> 43.07%      
client [48] (testset)   loss: 2.7382 -> 2.9967  accuracy: 29.70% -> 30.91%     
client [59] (testset)   loss: 4.5938 -> 2.3519  accuracy: 0.00% -> 36.05%      
client [34] (testset)   loss: 2.8157 -> 2.9381  accuracy: 24.31% -> 26.52%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [99] (testset)   loss: 4.5937 -> 3.4153  accuracy: 2.92% -> 26.28%      
client [69] (testset)   loss: 2.0444 -> 2.0792  accuracy: 46.93% -> 42.24%     
client [67] (testset)   loss: 4.5464 -> 2.7139  accuracy: 0.00% -> 28.02%      
client [0]  (testset)   loss: 4.6177 -> 2.4363  accuracy: 0.98% -> 36.27%      
client [76] (testset)   loss: 4.6033 -> 2.5006  accuracy: 1.12% -> 29.61%      
client [41] (testset)   loss: 4.5871 -> 2.8454  accuracy: 0.81% -> 20.97%      
client [2]  (testset)   loss: 4.6239 -> 2.9584  accuracy: 0.00% -> 25.00%      
client [62] (testset)   loss: 4.5996 -> 2.3140  accuracy: 0.97% -> 44.17%      
client [14] (testset)   loss: 2.7756 -> 3.2813  accuracy: 31.17% -> 24.68%     
client [46] (testset)   loss: 2.1441 -> 2.1344  accuracy: 47.62% -> 48.57%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 2.4447 -> 2.4601  accuracy: 31.90% -> 37.93%     
client [68] (testset)   loss: 2.2893 -> 2.2931  accuracy: 36.97% -> 39.50%     
client [57] (testset)   loss: 2.0995 -> 2.0615  accuracy: 46.63% -> 46.01%     
client [17] (testset)   loss: 2.8971 -> 2.7700  accuracy: 27.07% -> 33.83%     
client [54] (testset)   loss: 3.8181 -> 4.9343  accuracy: 34.17% -> 35.83%     
client [23] (testset)   loss: 4.6544 -> 2.6236  accuracy: 0.00% -> 35.45%      
client [35] (testset)   loss: 2.2822 -> 2.5653  accuracy: 39.29% -> 39.29%     
client [59] (testset)   loss: 2.3751 -> 2.6927  accuracy: 36.05% -> 37.77%     
client [31] (testset)   loss: 2.8084 -> 3.5782  accuracy: 41.58% -> 40.53%     
client [9]  (testset)   loss: 4.5564 -> 2.4845  accuracy: 0.67% -> 35.57%      
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [33] (testset)   loss: 2.4464 -> 3.4443  accuracy: 31.19% -> 24.77%     
client [64] (testset)   loss: 2.3712 -> 2.6238  accuracy: 45.27% -> 35.14%     
client [16] (testset)   loss: 2.8755 -> 2.8212  accuracy: 17.36% -> 28.93%     
client [44] (testset)   loss: 4.6114 -> 2.9273  accuracy: 0.65% -> 20.26%      
client [8]  (testset)   loss: 2.8092 -> 3.6781  accuracy: 43.22% -> 44.22%     
client [31] (testset)   loss: 3.1991 -> 3.6010  accuracy: 42.11% -> 44.21%     
client [47] (testset)   loss: 2.5406 -> 3.1113  accuracy: 40.87% -> 40.00%     
client [36] (testset)   loss: 2.7152 -> 2.6544  accuracy: 27.43% -> 36.28%     
client [56] (testset)   loss: 2.5749 -> 2.6112  accuracy: 29.76% -> 26.19%     
client [20] (testset)   loss: 3.1036 -> 2.7370  accuracy: 33.17% -> 46.53%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [60] (testset)   loss: 2.5443 -> 3.0349  accuracy: 36.36% -> 27.27%     
client [4]  (testset)   loss: 2.2048 -> 2.7462  accuracy: 47.97% -> 47.97%     
client [28] (testset)   loss: 2.6035 -> 2.5148  accuracy: 40.32% -> 37.90%     
client [25] (testset)   loss: 2.4383 -> 2.3714  accuracy: 37.50% -> 41.67%     
client [58] (testset)   loss: 3.4016 -> 3.7717  accuracy: 35.38% -> 32.31%     
client [44] (testset)   loss: 2.8874 -> 2.6803  accuracy: 20.26% -> 31.37%     
client [39] (testset)   loss: 2.4497 -> 2.4648  accuracy: 37.13% -> 40.12%     
client [29] (testset)   loss: 2.5376 -> 2.7845  accuracy: 32.00% -> 34.67%     
client [3]  (testset)   loss: 2.2021 -> 2.5150  accuracy: 41.41% -> 36.72%     
client [84] (testset)   loss: 3.3636 -> 4.4481  accuracy: 30.93% -> 35.17%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 2.5827 -> 2.4939  accuracy: 26.53% -> 31.29%     
client [84] (testset)   loss: 3.0447 -> 3.4465  accuracy: 32.20% -> 37.29%     
client [10] (testset)   loss: 2.7059 -> 2.8929  accuracy: 35.58% -> 38.46%     
client [36] (testset)   loss: 2.7775 -> 2.6431  accuracy: 23.01% -> 33.63%     
client [65] (testset)   loss: 3.0702 -> 3.8149  accuracy: 31.82% -> 26.36%     
client [81] (testset)   loss: 2.5177 -> 3.0698  accuracy: 43.71% -> 39.74%     
client [79] (testset)   loss: 2.0026 -> 2.7173  accuracy: 47.49% -> 53.07%     
client [42] (testset)   loss: 2.7766 -> 3.3177  accuracy: 47.26% -> 47.26%     
client [11] (testset)   loss: 2.5821 -> 2.9370  accuracy: 44.07% -> 48.02%     
client [96] (testset)   loss: 3.1774 -> 3.1489  accuracy: 40.46% -> 38.73%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [53] (testset)   loss: 2.8811 -> 3.6858  accuracy: 37.59% -> 43.26%     
client [8]  (testset)   loss: 3.7034 -> 4.3993  accuracy: 42.71% -> 42.21%     
client [52] (testset)   loss: 3.0670 -> 5.2544  accuracy: 38.81% -> 40.30%     
client [42] (testset)   loss: 2.5503 -> 3.1947  accuracy: 43.15% -> 42.47%     
client [69] (testset)   loss: 2.9247 -> 2.8973  accuracy: 50.54% -> 49.10%     
client [59] (testset)   loss: 2.7144 -> 3.1592  accuracy: 34.33% -> 37.34%     
client [26] (testset)   loss: 2.9198 -> 3.4724  accuracy: 36.28% -> 37.17%     
client [7]  (testset)   loss: 2.9580 -> 3.8288  accuracy: 28.95% -> 30.26%     
client [49] (testset)   loss: 2.5223 -> 3.0125  accuracy: 30.86% -> 45.06%     
client [98] (testset)   loss: 3.8426 -> 4.3389  accuracy: 29.58% -> 33.10%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [47] (testset)   loss: 3.1662 -> 3.7278  accuracy: 38.26% -> 42.61%     
client [98] (testset)   loss: 3.2777 -> 3.9072  accuracy: 28.17% -> 32.39%     
client [21] (testset)   loss: 2.5245 -> 2.9739  accuracy: 36.73% -> 36.73%     
client [77] (testset)   loss: 2.7745 -> 3.2482  accuracy: 43.82% -> 46.63%     
client [95] (testset)   loss: 3.9837 -> 4.6507  accuracy: 35.54% -> 37.35%     
client [91] (testset)   loss: 2.6418 -> 2.8254  accuracy: 30.26% -> 28.95%     
client [14] (testset)   loss: 3.5262 -> 3.9997  accuracy: 29.87% -> 29.87%     
client [99] (testset)   loss: 4.0439 -> 5.0863  accuracy: 24.09% -> 23.36%     
client [20] (testset)   loss: 3.1052 -> 3.3579  accuracy: 46.04% -> 48.02%     
client [39] (testset)   loss: 2.3905 -> 3.0019  accuracy: 41.32% -> 38.92%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 2.5440 -> 3.2987  accuracy: 39.55% -> 40.30%     
client [62] (testset)   loss: 3.5740 -> 4.0176  accuracy: 39.81% -> 40.78%     
client [71] (testset)   loss: 3.9760 -> 4.7842  accuracy: 28.24% -> 24.43%     
client [97] (testset)   loss: 3.8807 -> 4.6294  accuracy: 25.71% -> 27.62%     
client [30] (testset)   loss: 4.5705 -> 5.1064  accuracy: 27.07% -> 24.86%     
client [88] (testset)   loss: 2.7174 -> 2.6061  accuracy: 27.93% -> 37.43%     
client [60] (testset)   loss: 3.1629 -> 3.8303  accuracy: 34.85% -> 37.88%     
client [82] (testset)   loss: 4.3178 -> 4.4156  accuracy: 34.88% -> 32.56%     
client [91] (testset)   loss: 2.9058 -> 3.2862  accuracy: 29.61% -> 30.26%     
client [57] (testset)   loss: 2.1941 -> 2.9592  accuracy: 44.17% -> 33.74%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [15] (testset)   loss: 3.3677 -> 3.7039  accuracy: 27.74% -> 28.47%     
client [31] (testset)   loss: 3.4894 -> 3.7418  accuracy: 42.11% -> 43.68%     
client [71] (testset)   loss: 3.7813 -> 4.6526  accuracy: 20.61% -> 23.66%     
client [97] (testset)   loss: 3.1398 -> 3.8031  accuracy: 24.76% -> 25.71%     
client [53] (testset)   loss: 4.0689 -> 4.7392  accuracy: 36.88% -> 34.75%     
client [77] (testset)   loss: 2.9446 -> 3.1949  accuracy: 45.51% -> 46.63%     
client [76] (testset)   loss: 2.6268 -> 3.5848  accuracy: 38.55% -> 33.52%     
client [79] (testset)   loss: 2.5683 -> 2.9901  accuracy: 52.51% -> 54.19%     
client [28] (testset)   loss: 3.1273 -> 3.0551  accuracy: 38.71% -> 42.74%     
client [99] (testset)   loss: 4.5858 -> 5.4632  accuracy: 24.09% -> 24.82%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 3.3196 -> 4.0555  accuracy: 26.67% -> 29.52%     
client [86] (testset)   loss: 4.0876 -> 4.2359  accuracy: 36.44% -> 39.83%     
client [73] (testset)   loss: 3.4809 -> 4.0998  accuracy: 32.37% -> 35.25%     
client [34] (testset)   loss: 3.6116 -> 4.3570  accuracy: 29.28% -> 35.91%     
client [5]  (testset)   loss: 3.6405 -> 3.9584  accuracy: 38.65% -> 40.49%     
client [96] (testset)   loss: 3.9867 -> 4.3243  accuracy: 40.46% -> 41.04%     
client [60] (testset)   loss: 3.9657 -> 4.3665  accuracy: 40.91% -> 42.42%     
client [22] (testset)   loss: 4.3765 -> 4.2534  accuracy: 33.55% -> 31.58%     
client [83] (testset)   loss: 3.4426 -> 4.0366  accuracy: 42.11% -> 42.11%     
client [66] (testset)   loss: 2.6678 -> 3.0430  accuracy: 36.41% -> 44.17%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [65] (testset)   loss: 4.0052 -> 3.7657  accuracy: 25.45% -> 33.64%     
client [76] (testset)   loss: 4.1257 -> 4.4213  accuracy: 34.08% -> 34.08%     
client [95] (testset)   loss: 4.3097 -> 4.9692  accuracy: 39.16% -> 38.55%     
client [17] (testset)   loss: 3.6934 -> 4.2399  accuracy: 32.33% -> 35.34%     
client [8]  (testset)   loss: 4.3170 -> 4.7411  accuracy: 41.71% -> 43.72%     
client [35] (testset)   loss: 4.3896 -> 4.6592  accuracy: 38.78% -> 36.22%     
client [98] (testset)   loss: 4.1705 -> 4.5375  accuracy: 33.80% -> 33.80%     
client [53] (testset)   loss: 2.5384 -> 2.6152  accuracy: 31.21% -> 41.13%     
client [43] (testset)   loss: 4.2847 -> 4.2341  accuracy: 24.44% -> 28.89%     
client [64] (testset)   loss: 2.7399 -> 3.4503  accuracy: 41.22% -> 41.89%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 2.7324 -> 2.8559  accuracy: 35.37% -> 40.82%     
client [88] (testset)   loss: 4.1282 -> 4.2648  accuracy: 41.34% -> 36.31%     
client [3]  (testset)   loss: 3.2840 -> 3.3641  accuracy: 46.09% -> 45.31%     
client [38] (testset)   loss: 3.6044 -> 3.7810  accuracy: 44.69% -> 41.34%     
client [5]  (testset)   loss: 3.7543 -> 4.4343  accuracy: 41.72% -> 41.10%     
client [41] (testset)   loss: 3.7402 -> 4.2104  accuracy: 29.84% -> 28.23%     
client [37] (testset)   loss: 3.7953 -> 4.4796  accuracy: 35.58% -> 35.58%     
client [7]  (testset)   loss: 4.1808 -> 4.5606  accuracy: 33.33% -> 31.14%     
client [45] (testset)   loss: 2.0515 -> 2.3123  accuracy: 45.58% -> 45.58%     
client [47] (testset)   loss: 3.3919 -> 3.7934  accuracy: 44.35% -> 40.00%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 4.0911 -> 4.6170  accuracy: 33.88% -> 36.36%     
client [11] (testset)   loss: 2.6786 -> 3.2272  accuracy: 47.46% -> 48.59%     
client [37] (testset)   loss: 4.1611 -> 4.6355  accuracy: 36.54% -> 38.46%     
client [41] (testset)   loss: 3.7917 -> 4.2947  accuracy: 28.23% -> 28.23%     
client [95] (testset)   loss: 4.8179 -> 5.1922  accuracy: 35.54% -> 36.75%     
client [53] (testset)   loss: 4.0380 -> 4.4551  accuracy: 39.72% -> 41.84%     
client [25] (testset)   loss: 3.2483 -> 3.8436  accuracy: 40.62% -> 46.88%     
client [22] (testset)   loss: 3.8700 -> 4.6296  accuracy: 26.32% -> 33.55%     
client [46] (testset)   loss: 2.7050 -> 3.0745  accuracy: 53.33% -> 54.29%     
client [69] (testset)   loss: 3.3672 -> 3.1408  accuracy: 50.18% -> 51.62%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 2.9514 -> 3.8734  accuracy: 41.74% -> 43.48%     
client [82] (testset)   loss: 3.5436 -> 3.9825  accuracy: 27.91% -> 30.23%     
client [69] (testset)   loss: 3.2435 -> 3.5851  accuracy: 51.26% -> 51.26%     
client [45] (testset)   loss: 2.5091 -> 2.9198  accuracy: 43.81% -> 45.58%     
client [7]  (testset)   loss: 4.2917 -> 4.6526  accuracy: 31.14% -> 34.65%     
client [50] (testset)   loss: 2.7114 -> 2.4993  accuracy: 36.00% -> 41.00%     
client [24] (testset)   loss: 3.4116 -> 3.6463  accuracy: 40.52% -> 37.07%     
client [35] (testset)   loss: 4.2351 -> 4.6242  accuracy: 36.73% -> 36.22%     
client [15] (testset)   loss: 4.3120 -> 4.6613  accuracy: 35.04% -> 35.77%     
client [58] (testset)   loss: 4.3002 -> 4.5114  accuracy: 35.38% -> 35.38%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 3.9506 -> 4.2882  accuracy: 37.58% -> 36.36%     
client [76] (testset)   loss: 3.7684 -> 4.4170  accuracy: 33.52% -> 31.84%     
client [37] (testset)   loss: 3.7066 -> 4.7720  accuracy: 35.58% -> 38.46%     
client [67] (testset)   loss: 4.1241 -> 4.4337  accuracy: 37.91% -> 38.46%     
client [58] (testset)   loss: 4.2821 -> 4.5412  accuracy: 36.15% -> 36.15%     
client [64] (testset)   loss: 3.7318 -> 3.9938  accuracy: 45.27% -> 44.59%     
client [77] (testset)   loss: 3.3689 -> 3.5643  accuracy: 44.38% -> 50.00%     
client [55] (testset)   loss: 3.2094 -> 3.3341  accuracy: 47.83% -> 46.38%     
client [12] (testset)   loss: 3.0376 -> 3.4182  accuracy: 53.03% -> 54.55%     
client [89] (testset)   loss: 5.5152 -> 5.6337  accuracy: 29.94% -> 30.57%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [51] (testset)   loss: 4.0558 -> 4.4908  accuracy: 37.84% -> 39.19%     
client [84] (testset)   loss: 3.9571 -> 4.7554  accuracy: 37.71% -> 36.02%     
client [8]  (testset)   loss: 4.6526 -> 4.7043  accuracy: 43.22% -> 44.72%     
client [18] (testset)   loss: 3.3806 -> 3.7339  accuracy: 50.00% -> 50.00%     
client [94] (testset)   loss: 4.5121 -> 4.8864  accuracy: 40.77% -> 38.46%     
client [81] (testset)   loss: 3.9826 -> 4.2175  accuracy: 40.40% -> 43.71%     
client [3]  (testset)   loss: 3.0443 -> 3.3685  accuracy: 46.09% -> 46.09%     
client [11] (testset)   loss: 3.0991 -> 3.4019  accuracy: 44.07% -> 47.46%     
client [95] (testset)   loss: 4.8319 -> 5.1792  accuracy: 37.35% -> 38.55%     
client [67] (testset)   loss: 3.7436 -> 3.9187  accuracy: 41.21% -> 34.62%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 2.9254 -> 3.2771  accuracy: 39.46% -> 40.14%     
client [79] (testset)   loss: 3.0899 -> 3.2549  accuracy: 53.63% -> 54.75%     
client [58] (testset)   loss: 4.1047 -> 4.3669  accuracy: 36.92% -> 36.92%     
client [88] (testset)   loss: 3.7643 -> 4.3808  accuracy: 40.22% -> 37.43%     
client [46] (testset)   loss: 3.3486 -> 3.6769  accuracy: 53.33% -> 55.24%     
client [11] (testset)   loss: 3.0801 -> 3.3515  accuracy: 46.33% -> 46.89%     
client [55] (testset)   loss: 3.0650 -> 3.2790  accuracy: 48.55% -> 47.10%     
client [13] (testset)   loss: 3.8741 -> 4.1307  accuracy: 38.01% -> 38.01%     
client [31] (testset)   loss: 3.7185 -> 3.9707  accuracy: 44.21% -> 44.74%     
client [75] (testset)   loss: 4.4358 -> 4.6642  accuracy: 41.98% -> 41.51%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 4.0905 -> 4.2940  accuracy: 37.20% -> 36.59%     
client [7]  (testset)   loss: 4.6666 -> 4.5308  accuracy: 35.09% -> 29.39%     
client [57] (testset)   loss: 3.6403 -> 3.7783  accuracy: 48.47% -> 50.31%     
client [13] (testset)   loss: 3.9240 -> 4.3109  accuracy: 37.43% -> 26.90%     
client [43] (testset)   loss: 4.8576 -> 5.1077  accuracy: 26.67% -> 26.67%     
client [91] (testset)   loss: 4.0393 -> 4.3451  accuracy: 35.53% -> 36.18%     
client [10] (testset)   loss: 4.1012 -> 4.3141  accuracy: 35.58% -> 37.50%     
client [82] (testset)   loss: 4.0256 -> 4.7494  accuracy: 26.74% -> 31.40%     
client [64] (testset)   loss: 3.7644 -> 4.0103  accuracy: 42.57% -> 42.57%     
client [22] (testset)   loss: 4.8274 -> 4.9005  accuracy: 32.89% -> 27.63%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [23] (testset)   loss: 3.5880 -> 3.9777  accuracy: 38.18% -> 40.91%     
client [20] (testset)   loss: 3.2840 -> 3.5093  accuracy: 46.53% -> 48.51%     
client [88] (testset)   loss: 4.1557 -> 4.5660  accuracy: 39.66% -> 38.55%     
client [98] (testset)   loss: 4.6089 -> 4.8071  accuracy: 34.51% -> 33.10%     
client [79] (testset)   loss: 3.1193 -> 3.3455  accuracy: 54.19% -> 54.19%     
client [21] (testset)   loss: 3.2489 -> 3.5026  accuracy: 40.14% -> 39.46%     
client [92] (testset)   loss: 4.5230 -> 4.9780  accuracy: 34.69% -> 33.67%     
client [56] (testset)   loss: 3.5096 -> 3.6432  accuracy: 39.29% -> 38.10%     
client [52] (testset)   loss: 4.4044 -> 4.6354  accuracy: 41.79% -> 42.54%     
client [5]  (testset)   loss: 4.1452 -> 4.5869  accuracy: 39.26% -> 37.42%     
FedDpa's average time taken by each global epoch: 0 min 5.21 sec.              
FedDpa's total running time: 0 h 18 m 28 s.                                    
==================== FedDpa Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "3.4030 -> 0.0000",                                    
                "accuracy": "37.47% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "4.0572 -> 0.0000",                                    
                "accuracy": "38.99% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedDpa Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 38.99% at epoch 200                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
