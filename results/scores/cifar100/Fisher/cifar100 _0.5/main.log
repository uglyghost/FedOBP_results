==================== FedDpa ====================                               
Experiment Arguments:                                                          
{
    'method': 'feddpa',
    'dataset': {
        'name': 'cifar100',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'cifar100-100clients-0%IID-use20superclasses-Dir(0.1)-seed42',
        'super_class': False,
        'alpha': 0.1,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'parallel',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': 32.0,
        'num_gpus': 1.0,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 200,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 0,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'feddpa': {
        'fisher_threshold': 0.5
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [81] (testset)   loss: 2.7784 -> 2.7446  accuracy: 33.77% -> 33.11%     
client [77] (testset)   loss: 2.1080 -> 1.9800  accuracy: 42.13% -> 44.94%     
client [21] (testset)   loss: 4.5883 -> 2.4808  accuracy: 1.36% -> 27.89%      
client [68] (testset)   loss: 2.4380 -> 2.4238  accuracy: 31.09% -> 30.25%     
client [93] (testset)   loss: 4.5816 -> 2.6195  accuracy: 0.00% -> 33.60%      
client [31] (testset)   loss: 2.3816 -> 2.3611  accuracy: 35.79% -> 35.79%     
client [20] (testset)   loss: 4.4429 -> 2.1735  accuracy: 4.46% -> 44.55%      
client [48] (testset)   loss: 2.8739 -> 2.9466  accuracy: 27.27% -> 29.09%     
client [59] (testset)   loss: 4.5677 -> 2.4083  accuracy: 0.00% -> 39.91%      
client [34] (testset)   loss: 2.7847 -> 2.8225  accuracy: 24.86% -> 28.18%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [99] (testset)   loss: 4.5407 -> 3.6370  accuracy: 1.46% -> 19.71%      
client [69] (testset)   loss: 2.1132 -> 2.0046  accuracy: 41.16% -> 48.01%     
client [67] (testset)   loss: 4.5134 -> 2.5359  accuracy: 0.55% -> 34.62%      
client [0]  (testset)   loss: 4.6814 -> 2.2506  accuracy: 0.00% -> 41.18%      
client [76] (testset)   loss: 4.5888 -> 2.5357  accuracy: 1.12% -> 25.70%      
client [41] (testset)   loss: 4.5966 -> 2.7725  accuracy: 0.00% -> 26.61%      
client [2]  (testset)   loss: 4.6544 -> 2.6986  accuracy: 0.89% -> 25.00%      
client [62] (testset)   loss: 4.6060 -> 2.4209  accuracy: 0.49% -> 37.38%      
client [14] (testset)   loss: 2.8194 -> 3.0334  accuracy: 41.56% -> 36.36%     
client [46] (testset)   loss: 4.5857 -> 2.0919  accuracy: 0.00% -> 44.76%      
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 2.4485 -> 3.1281  accuracy: 33.62% -> 29.31%     
client [68] (testset)   loss: 4.6593 -> 2.1943  accuracy: 0.00% -> 40.34%      
client [57] (testset)   loss: 2.2075 -> 2.0472  accuracy: 41.72% -> 47.24%     
client [17] (testset)   loss: 2.7047 -> 3.0820  accuracy: 35.34% -> 33.08%     
client [54] (testset)   loss: 3.2031 -> 4.2411  accuracy: 40.83% -> 34.17%     
client [23] (testset)   loss: 4.7276 -> 2.5993  accuracy: 0.00% -> 32.73%      
client [35] (testset)   loss: 2.5229 -> 2.5590  accuracy: 31.12% -> 38.78%     
client [59] (testset)   loss: 2.2380 -> 2.8077  accuracy: 36.91% -> 40.34%     
client [31] (testset)   loss: 2.6586 -> 2.7707  accuracy: 37.37% -> 44.74%     
client [9]  (testset)   loss: 4.5830 -> 2.2938  accuracy: 0.00% -> 37.58%      
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [33] (testset)   loss: 2.5427 -> 3.1764  accuracy: 30.28% -> 27.52%     
client [64] (testset)   loss: 2.4367 -> 2.9716  accuracy: 37.16% -> 43.92%     
client [16] (testset)   loss: 2.7613 -> 3.0633  accuracy: 29.75% -> 26.45%     
client [44] (testset)   loss: 4.6750 -> 2.5754  accuracy: 0.00% -> 29.41%      
client [8]  (testset)   loss: 2.7446 -> 3.6442  accuracy: 40.20% -> 45.23%     
client [31] (testset)   loss: 2.4268 -> 3.1284  accuracy: 41.58% -> 46.32%     
client [47] (testset)   loss: 2.5715 -> 3.3307  accuracy: 45.22% -> 37.39%     
client [36] (testset)   loss: 2.8479 -> 2.8750  accuracy: 31.86% -> 30.97%     
client [56] (testset)   loss: 2.3482 -> 2.3585  accuracy: 40.48% -> 42.86%     
client [20] (testset)   loss: 3.0911 -> 3.0071  accuracy: 34.65% -> 45.54%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [60] (testset)   loss: 2.4867 -> 2.9753  accuracy: 40.91% -> 42.42%     
client [4]  (testset)   loss: 2.2946 -> 2.8552  accuracy: 47.30% -> 47.30%     
client [28] (testset)   loss: 2.5923 -> 2.6212  accuracy: 37.90% -> 37.90%     
client [25] (testset)   loss: 2.6480 -> 2.5992  accuracy: 38.54% -> 45.83%     
client [58] (testset)   loss: 3.8337 -> 3.4895  accuracy: 32.31% -> 36.15%     
client [44] (testset)   loss: 2.6950 -> 2.9034  accuracy: 27.45% -> 32.68%     
client [39] (testset)   loss: 2.4171 -> 2.8262  accuracy: 40.12% -> 38.32%     
client [29] (testset)   loss: 2.7951 -> 3.1224  accuracy: 28.67% -> 34.67%     
client [3]  (testset)   loss: 2.3046 -> 2.5767  accuracy: 39.06% -> 43.75%     
client [84] (testset)   loss: 3.4500 -> 4.0958  accuracy: 32.20% -> 35.17%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 2.5030 -> 2.7112  accuracy: 35.37% -> 35.37%     
client [84] (testset)   loss: 3.6641 -> 4.7210  accuracy: 32.63% -> 31.78%     
client [10] (testset)   loss: 2.7542 -> 3.0043  accuracy: 33.65% -> 41.35%     
client [36] (testset)   loss: 2.6613 -> 3.1513  accuracy: 23.01% -> 34.51%     
client [65] (testset)   loss: 3.4494 -> 3.3664  accuracy: 27.27% -> 33.64%     
client [81] (testset)   loss: 2.7340 -> 3.1280  accuracy: 37.75% -> 49.67%     
client [79] (testset)   loss: 2.0330 -> 2.6465  accuracy: 48.60% -> 51.96%     
client [42] (testset)   loss: 2.8561 -> 2.9275  accuracy: 42.47% -> 48.63%     
client [11] (testset)   loss: 2.3541 -> 2.5906  accuracy: 41.81% -> 47.46%     
client [96] (testset)   loss: 2.7813 -> 3.2805  accuracy: 36.99% -> 38.73%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [53] (testset)   loss: 3.1110 -> 3.7926  accuracy: 41.84% -> 34.75%     
client [8]  (testset)   loss: 3.6571 -> 4.3525  accuracy: 43.72% -> 44.22%     
client [52] (testset)   loss: 3.3804 -> 4.0698  accuracy: 39.55% -> 41.04%     
client [42] (testset)   loss: 2.8521 -> 3.2035  accuracy: 42.47% -> 43.84%     
client [59] (testset)   loss: 2.8229 -> 3.3886  accuracy: 39.06% -> 40.77%     
client [69] (testset)   loss: 2.8142 -> 3.1352  accuracy: 48.74% -> 50.54%     
client [26] (testset)   loss: 2.7168 -> 3.0389  accuracy: 38.94% -> 34.51%     
client [7]  (testset)   loss: 3.5305 -> 4.3789  accuracy: 33.77% -> 31.14%     
client [49] (testset)   loss: 2.5480 -> 3.2672  accuracy: 43.21% -> 43.21%     
client [98] (testset)   loss: 3.3349 -> 3.9959  accuracy: 33.80% -> 30.28%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [47] (testset)   loss: 3.2452 -> 3.9387  accuracy: 33.91% -> 44.35%     
client [98] (testset)   loss: 3.7320 -> 4.0834  accuracy: 27.46% -> 30.28%     
client [21] (testset)   loss: 2.4880 -> 3.1188  accuracy: 38.10% -> 39.46%     
client [77] (testset)   loss: 2.9431 -> 3.4028  accuracy: 39.89% -> 44.94%     
client [95] (testset)   loss: 4.2304 -> 4.6019  accuracy: 36.14% -> 39.16%     
client [91] (testset)   loss: 2.8676 -> 3.7009  accuracy: 29.61% -> 34.87%     
client [14] (testset)   loss: 3.3368 -> 4.5242  accuracy: 38.96% -> 31.17%     
client [99] (testset)   loss: 3.8935 -> 5.0460  accuracy: 23.36% -> 25.55%     
client [20] (testset)   loss: 3.1871 -> 3.4019  accuracy: 44.55% -> 49.01%     
client [39] (testset)   loss: 3.0300 -> 3.7989  accuracy: 37.13% -> 37.72%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 2.5771 -> 2.9625  accuracy: 38.81% -> 43.28%     
client [62] (testset)   loss: 3.4102 -> 4.0476  accuracy: 39.32% -> 40.29%     
client [71] (testset)   loss: 4.0166 -> 4.3888  accuracy: 29.01% -> 22.14%     
client [97] (testset)   loss: 4.1569 -> 4.8131  accuracy: 27.62% -> 28.57%     
client [30] (testset)   loss: 4.5344 -> 5.1187  accuracy: 22.65% -> 23.76%     
client [88] (testset)   loss: 2.6882 -> 2.7504  accuracy: 27.93% -> 35.75%     
client [60] (testset)   loss: 3.3632 -> 4.9594  accuracy: 39.39% -> 37.88%     
client [82] (testset)   loss: 4.1660 -> 4.8420  accuracy: 27.91% -> 29.07%     
client [91] (testset)   loss: 3.2320 -> 3.6257  accuracy: 35.53% -> 36.18%     
client [57] (testset)   loss: 2.7542 -> 3.5139  accuracy: 49.69% -> 49.08%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [15] (testset)   loss: 3.5857 -> 3.9541  accuracy: 31.39% -> 35.04%     
client [31] (testset)   loss: 3.3085 -> 3.6529  accuracy: 37.89% -> 43.68%     
client [71] (testset)   loss: 3.8024 -> 4.7425  accuracy: 22.14% -> 24.43%     
client [97] (testset)   loss: 2.9485 -> 3.5785  accuracy: 31.43% -> 27.62%     
client [53] (testset)   loss: 3.9953 -> 4.4055  accuracy: 36.88% -> 39.01%     
client [77] (testset)   loss: 2.9605 -> 3.5643  accuracy: 45.51% -> 45.51%     
client [76] (testset)   loss: 2.6075 -> 3.9959  accuracy: 39.11% -> 29.61%     
client [79] (testset)   loss: 2.5441 -> 3.0427  accuracy: 48.60% -> 51.40%     
client [28] (testset)   loss: 2.5790 -> 3.0685  accuracy: 45.97% -> 45.16%     
client [99] (testset)   loss: 4.3256 -> 5.0867  accuracy: 21.90% -> 24.82%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 3.3045 -> 4.4131  accuracy: 28.57% -> 28.57%     
client [86] (testset)   loss: 3.6165 -> 4.8952  accuracy: 46.61% -> 37.29%     
client [73] (testset)   loss: 3.8809 -> 4.1920  accuracy: 27.34% -> 34.53%     
client [34] (testset)   loss: 3.1087 -> 4.0184  accuracy: 29.83% -> 34.81%     
client [5]  (testset)   loss: 3.7860 -> 4.4382  accuracy: 38.04% -> 40.49%     
client [96] (testset)   loss: 4.1587 -> 4.3120  accuracy: 43.93% -> 41.04%     
client [60] (testset)   loss: 4.1522 -> 4.5852  accuracy: 42.42% -> 40.91%     
client [22] (testset)   loss: 3.4436 -> 4.1583  accuracy: 24.34% -> 29.61%     
client [83] (testset)   loss: 3.5519 -> 4.2274  accuracy: 36.84% -> 37.50%     
client [66] (testset)   loss: 3.3583 -> 3.6305  accuracy: 33.50% -> 41.26%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [65] (testset)   loss: 3.8393 -> 3.9634  accuracy: 34.55% -> 29.09%     
client [76] (testset)   loss: 4.1497 -> 4.4872  accuracy: 33.52% -> 32.96%     
client [95] (testset)   loss: 4.3655 -> 4.8641  accuracy: 38.55% -> 38.55%     
client [17] (testset)   loss: 4.1998 -> 5.0353  accuracy: 34.59% -> 36.84%     
client [8]  (testset)   loss: 4.5357 -> 4.9115  accuracy: 43.22% -> 45.73%     
client [35] (testset)   loss: 4.2175 -> 4.5873  accuracy: 41.84% -> 39.80%     
client [98] (testset)   loss: 4.3907 -> 4.7257  accuracy: 33.10% -> 35.21%     
client [53] (testset)   loss: 2.7302 -> 3.1827  accuracy: 41.84% -> 41.13%     
client [43] (testset)   loss: 4.3072 -> 4.7842  accuracy: 33.33% -> 33.33%     
client [64] (testset)   loss: 3.2105 -> 3.5902  accuracy: 42.57% -> 45.27%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 2.8567 -> 3.2261  accuracy: 39.46% -> 38.78%     
client [88] (testset)   loss: 3.4232 -> 4.0155  accuracy: 40.78% -> 39.66%     
client [3]  (testset)   loss: 3.0926 -> 3.4467  accuracy: 47.66% -> 49.22%     
client [38] (testset)   loss: 3.2911 -> 3.3321  accuracy: 44.13% -> 49.16%     
client [41] (testset)   loss: 3.6322 -> 4.1794  accuracy: 32.26% -> 28.23%     
client [5]  (testset)   loss: 4.0700 -> 4.7101  accuracy: 42.33% -> 37.42%     
client [37] (testset)   loss: 3.6000 -> 4.2394  accuracy: 32.69% -> 32.69%     
client [7]  (testset)   loss: 4.3930 -> 4.6617  accuracy: 31.58% -> 38.60%     
client [45] (testset)   loss: 3.0447 -> 3.4510  accuracy: 41.59% -> 45.13%     
client [47] (testset)   loss: 3.4707 -> 3.6400  accuracy: 40.87% -> 41.74%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 4.0990 -> 4.3211  accuracy: 38.02% -> 37.19%     
client [11] (testset)   loss: 2.9588 -> 3.4173  accuracy: 47.46% -> 41.81%     
client [37] (testset)   loss: 4.3800 -> 4.8353  accuracy: 38.46% -> 36.54%     
client [41] (testset)   loss: 3.5344 -> 4.2188  accuracy: 29.03% -> 27.42%     
client [95] (testset)   loss: 4.7211 -> 5.1302  accuracy: 33.73% -> 37.35%     
client [53] (testset)   loss: 4.2169 -> 4.6419  accuracy: 46.10% -> 42.55%     
client [25] (testset)   loss: 3.0129 -> 3.7211  accuracy: 43.75% -> 43.75%     
client [22] (testset)   loss: 4.4276 -> 4.9668  accuracy: 29.61% -> 30.92%     
client [46] (testset)   loss: 2.9133 -> 3.3752  accuracy: 55.24% -> 55.24%     
client [69] (testset)   loss: 3.3788 -> 3.2746  accuracy: 48.74% -> 51.62%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 3.6387 -> 4.0923  accuracy: 42.61% -> 43.48%     
client [82] (testset)   loss: 3.7236 -> 4.2224  accuracy: 30.23% -> 30.23%     
client [69] (testset)   loss: 3.2668 -> 3.5809  accuracy: 52.35% -> 51.62%     
client [45] (testset)   loss: 2.5419 -> 3.2900  accuracy: 44.69% -> 39.82%     
client [7]  (testset)   loss: 3.6351 -> 4.3828  accuracy: 32.89% -> 36.84%     
client [50] (testset)   loss: 3.0758 -> 2.6878  accuracy: 32.00% -> 46.00%     
client [24] (testset)   loss: 3.5711 -> 3.9434  accuracy: 37.07% -> 41.38%     
client [35] (testset)   loss: 4.3183 -> 4.6455  accuracy: 40.82% -> 38.27%     
client [15] (testset)   loss: 4.2484 -> 4.5451  accuracy: 34.31% -> 35.04%     
client [58] (testset)   loss: 3.3207 -> 4.4208  accuracy: 33.85% -> 31.54%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 4.0566 -> 4.2674  accuracy: 38.79% -> 40.00%     
client [76] (testset)   loss: 3.7698 -> 4.2659  accuracy: 36.31% -> 35.75%     
client [37] (testset)   loss: 4.5278 -> 5.0252  accuracy: 33.65% -> 33.65%     
client [67] (testset)   loss: 4.3495 -> 4.6228  accuracy: 40.11% -> 40.11%     
client [58] (testset)   loss: 4.0499 -> 4.5157  accuracy: 33.85% -> 33.85%     
client [64] (testset)   loss: 3.7034 -> 3.9962  accuracy: 43.24% -> 43.24%     
client [77] (testset)   loss: 3.2568 -> 3.7304  accuracy: 46.63% -> 48.31%     
client [55] (testset)   loss: 3.3026 -> 3.4218  accuracy: 43.48% -> 44.20%     
client [12] (testset)   loss: 3.1485 -> 3.5102  accuracy: 53.03% -> 53.03%     
client [89] (testset)   loss: 5.3332 -> 5.5510  accuracy: 31.21% -> 31.85%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [51] (testset)   loss: 4.0837 -> 4.6194  accuracy: 35.81% -> 36.49%     
client [84] (testset)   loss: 5.0757 -> 5.2450  accuracy: 34.75% -> 35.17%     
client [8]  (testset)   loss: 4.8321 -> 4.9638  accuracy: 45.23% -> 44.72%     
client [18] (testset)   loss: 3.5468 -> 3.7995  accuracy: 49.22% -> 50.00%     
client [94] (testset)   loss: 4.4877 -> 4.7609  accuracy: 40.77% -> 40.00%     
client [81] (testset)   loss: 4.0701 -> 4.2916  accuracy: 43.71% -> 44.37%     
client [3]  (testset)   loss: 2.9613 -> 3.2301  accuracy: 46.88% -> 46.88%     
client [11] (testset)   loss: 3.2011 -> 3.6017  accuracy: 44.63% -> 44.63%     
client [95] (testset)   loss: 4.8474 -> 5.2349  accuracy: 37.35% -> 39.16%     
client [67] (testset)   loss: 4.5395 -> 4.7037  accuracy: 39.01% -> 38.46%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 3.5981 -> 3.2927  accuracy: 35.37% -> 43.54%     
client [79] (testset)   loss: 3.3200 -> 3.6106  accuracy: 52.51% -> 51.96%     
client [58] (testset)   loss: 4.3572 -> 4.5481  accuracy: 36.15% -> 34.62%     
client [88] (testset)   loss: 3.7841 -> 4.2166  accuracy: 43.58% -> 43.58%     
client [46] (testset)   loss: 3.3065 -> 3.6186  accuracy: 54.29% -> 54.29%     
client [11] (testset)   loss: 3.3057 -> 3.5311  accuracy: 46.33% -> 43.50%     
client [55] (testset)   loss: 3.4644 -> 3.5176  accuracy: 42.75% -> 45.65%     
client [13] (testset)   loss: 4.0255 -> 4.4291  accuracy: 35.67% -> 37.43%     
client [31] (testset)   loss: 4.1548 -> 4.3161  accuracy: 41.05% -> 41.05%     
client [75] (testset)   loss: 3.8746 -> 4.2790  accuracy: 41.98% -> 42.45%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 3.9619 -> 4.2183  accuracy: 37.80% -> 36.59%     
client [7]  (testset)   loss: 4.4657 -> 4.8234  accuracy: 35.09% -> 35.09%     
client [57] (testset)   loss: 3.4718 -> 3.6870  accuracy: 51.53% -> 53.37%     
client [13] (testset)   loss: 4.0965 -> 4.3162  accuracy: 38.01% -> 37.43%     
client [43] (testset)   loss: 4.1886 -> 4.6174  accuracy: 32.59% -> 31.85%     
client [91] (testset)   loss: 4.0064 -> 4.0983  accuracy: 34.87% -> 32.89%     
client [10] (testset)   loss: 3.3369 -> 3.5733  accuracy: 31.73% -> 42.31%     
client [64] (testset)   loss: 4.0189 -> 4.1948  accuracy: 42.57% -> 43.24%     
client [82] (testset)   loss: 4.0901 -> 4.6187  accuracy: 27.91% -> 31.40%     
client [22] (testset)   loss: 4.4998 -> 4.9170  accuracy: 31.58% -> 30.92%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [23] (testset)   loss: 3.0516 -> 3.8672  accuracy: 35.45% -> 37.27%     
client [20] (testset)   loss: 3.2166 -> 3.5088  accuracy: 48.02% -> 50.50%     
client [88] (testset)   loss: 3.7448 -> 4.2255  accuracy: 43.02% -> 41.34%     
client [98] (testset)   loss: 5.1330 -> 5.3766  accuracy: 31.69% -> 31.69%     
client [79] (testset)   loss: 3.3637 -> 3.5949  accuracy: 49.16% -> 50.84%     
client [21] (testset)   loss: 3.2373 -> 3.2423  accuracy: 41.50% -> 40.14%     
client [92] (testset)   loss: 4.1378 -> 4.4984  accuracy: 36.73% -> 34.69%     
client [56] (testset)   loss: 3.3023 -> 3.5922  accuracy: 44.05% -> 42.86%     
client [5]  (testset)   loss: 4.4838 -> 4.8404  accuracy: 42.33% -> 40.49%     
client [52] (testset)   loss: 3.8994 -> 4.2448  accuracy: 41.04% -> 39.55%     
FedDpa's average time taken by each global epoch: 0 min 5.17 sec.              
FedDpa's total running time: 0 h 18 m 19 s.                                    
==================== FedDpa Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "3.4289 -> 0.0000",                                    
                "accuracy": "38.27% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "4.0331 -> 0.0000",                                    
                "accuracy": "39.75% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedDpa Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 39.75% at epoch 200                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
