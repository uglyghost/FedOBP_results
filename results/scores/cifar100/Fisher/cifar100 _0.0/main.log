==================== FedDpa ====================                               
Experiment Arguments:                                                          
{
    'method': 'feddpa',
    'dataset': {
        'name': 'cifar100',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'cifar100-100clients-0%IID-use20superclasses-Dir(0.1)-seed42',
        'super_class': False,
        'alpha': 0.1,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'parallel',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': 32.0,
        'num_gpus': 1.0,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 200,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 0,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'feddpa': {
        'fisher_threshold': 0.0
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [81] (testset)   loss: 3.1509 -> 3.0927  accuracy: 27.81% -> 33.11%     
client [77] (testset)   loss: 2.2479 -> 1.9791  accuracy: 36.52% -> 45.51%     
client [21] (testset)   loss: 4.6045 -> 2.5577  accuracy: 0.68% -> 27.21%      
client [68] (testset)   loss: 2.3599 -> 2.3813  accuracy: 36.13% -> 31.93%     
client [93] (testset)   loss: 4.6111 -> 2.8804  accuracy: 0.00% -> 28.00%      
client [31] (testset)   loss: 2.4777 -> 2.3565  accuracy: 32.63% -> 37.89%     
client [20] (testset)   loss: 4.5731 -> 2.2158  accuracy: 0.99% -> 43.07%      
client [48] (testset)   loss: 2.8731 -> 2.9970  accuracy: 30.30% -> 21.82%     
client [59] (testset)   loss: 4.6061 -> 2.4141  accuracy: 0.86% -> 31.33%      
client [34] (testset)   loss: 2.8060 -> 2.7258  accuracy: 23.76% -> 20.99%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [99] (testset)   loss: 4.5922 -> 3.6678  accuracy: 3.65% -> 18.98%      
client [69] (testset)   loss: 2.0586 -> 1.9585  accuracy: 48.38% -> 51.26%     
client [67] (testset)   loss: 4.5527 -> 2.8326  accuracy: 0.00% -> 24.18%      
client [0]  (testset)   loss: 4.6052 -> 2.5199  accuracy: 0.00% -> 38.24%      
client [41] (testset)   loss: 4.6087 -> 2.8755  accuracy: 0.00% -> 22.58%      
client [76] (testset)   loss: 4.6165 -> 2.5340  accuracy: 0.00% -> 39.11%      
client [2]  (testset)   loss: 4.6169 -> 2.8249  accuracy: 0.00% -> 26.79%      
client [14] (testset)   loss: 2.8009 -> 3.1302  accuracy: 33.77% -> 28.57%     
client [62] (testset)   loss: 4.6209 -> 2.4512  accuracy: 0.00% -> 37.38%      
client [46] (testset)   loss: 4.5897 -> 2.2495  accuracy: 0.00% -> 43.81%      
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 2.5193 -> 2.2969  accuracy: 35.34% -> 42.24%     
client [68] (testset)   loss: 4.6052 -> 2.4392  accuracy: 1.26% -> 34.03%      
client [57] (testset)   loss: 2.2909 -> 2.0936  accuracy: 33.13% -> 45.40%     
client [17] (testset)   loss: 2.7088 -> 2.8040  accuracy: 34.59% -> 33.08%     
client [54] (testset)   loss: 4.3690 -> 4.8676  accuracy: 29.17% -> 35.83%     
client [23] (testset)   loss: 4.6453 -> 2.7242  accuracy: 0.91% -> 20.91%      
client [35] (testset)   loss: 2.4933 -> 2.4740  accuracy: 26.53% -> 32.65%     
client [59] (testset)   loss: 2.2787 -> 2.5872  accuracy: 39.48% -> 33.91%     
client [31] (testset)   loss: 3.1724 -> 3.7652  accuracy: 41.05% -> 45.26%     
client [9]  (testset)   loss: 4.5772 -> 2.6974  accuracy: 0.00% -> 28.86%      
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [33] (testset)   loss: 2.7029 -> 2.6521  accuracy: 22.94% -> 28.44%     
client [64] (testset)   loss: 2.3593 -> 2.6806  accuracy: 43.92% -> 36.49%     
client [16] (testset)   loss: 2.7717 -> 2.8069  accuracy: 24.79% -> 34.71%     
client [44] (testset)   loss: 4.6011 -> 2.6753  accuracy: 1.96% -> 22.88%      
client [8]  (testset)   loss: 2.7803 -> 3.3484  accuracy: 37.19% -> 41.71%     
client [31] (testset)   loss: 3.3169 -> 3.7341  accuracy: 45.79% -> 46.32%     
client [47] (testset)   loss: 2.8088 -> 3.1316  accuracy: 26.09% -> 34.78%     
client [36] (testset)   loss: 2.8966 -> 2.8029  accuracy: 23.01% -> 25.66%     
client [56] (testset)   loss: 2.6084 -> 2.4155  accuracy: 27.38% -> 39.29%     
client [20] (testset)   loss: 2.5405 -> 3.0463  accuracy: 42.57% -> 50.00%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [60] (testset)   loss: 2.7463 -> 2.6423  accuracy: 28.79% -> 34.85%     
client [4]  (testset)   loss: 2.4225 -> 2.6485  accuracy: 40.54% -> 45.27%     
client [28] (testset)   loss: 3.1049 -> 2.5439  accuracy: 13.71% -> 38.71%     
client [25] (testset)   loss: 2.5436 -> 2.3153  accuracy: 33.33% -> 37.50%     
client [58] (testset)   loss: 2.4693 -> 2.9266  accuracy: 40.00% -> 34.62%     
client [44] (testset)   loss: 2.6739 -> 2.5746  accuracy: 22.88% -> 29.41%     
client [39] (testset)   loss: 2.5793 -> 2.5936  accuracy: 34.13% -> 31.74%     
client [29] (testset)   loss: 2.5879 -> 2.8404  accuracy: 35.33% -> 33.33%     
client [3]  (testset)   loss: 2.3812 -> 2.5517  accuracy: 42.19% -> 38.28%     
client [84] (testset)   loss: 3.7763 -> 4.5921  accuracy: 30.51% -> 34.75%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 2.5369 -> 2.3142  accuracy: 27.89% -> 32.65%     
client [84] (testset)   loss: 2.9997 -> 2.8483  accuracy: 33.90% -> 36.02%     
client [10] (testset)   loss: 2.9633 -> 2.8762  accuracy: 25.96% -> 30.77%     
client [36] (testset)   loss: 2.8389 -> 2.9794  accuracy: 24.78% -> 21.24%     
client [65] (testset)   loss: 2.7117 -> 3.1629  accuracy: 33.64% -> 30.00%     
client [81] (testset)   loss: 2.9266 -> 3.1685  accuracy: 31.13% -> 40.40%     
client [79] (testset)   loss: 1.9213 -> 2.0759  accuracy: 50.28% -> 55.31%     
client [42] (testset)   loss: 2.3709 -> 2.7794  accuracy: 43.84% -> 45.21%     
client [11] (testset)   loss: 2.2388 -> 2.7190  accuracy: 38.98% -> 41.81%     
client [96] (testset)   loss: 2.3575 -> 2.6937  accuracy: 42.77% -> 34.10%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [53] (testset)   loss: 2.6020 -> 3.1515  accuracy: 37.59% -> 29.08%     
client [8]  (testset)   loss: 4.2435 -> 4.8294  accuracy: 41.21% -> 42.71%     
client [52] (testset)   loss: 3.2573 -> 3.9368  accuracy: 38.81% -> 40.30%     
client [42] (testset)   loss: 2.6135 -> 3.0399  accuracy: 49.32% -> 42.47%     
client [69] (testset)   loss: 3.2973 -> 3.5934  accuracy: 52.71% -> 51.62%     
client [59] (testset)   loss: 2.3467 -> 2.7868  accuracy: 39.91% -> 35.62%     
client [26] (testset)   loss: 3.9284 -> 3.5187  accuracy: 29.20% -> 38.05%     
client [7]  (testset)   loss: 2.9512 -> 3.6853  accuracy: 32.02% -> 32.46%     
client [49] (testset)   loss: 2.6273 -> 2.7597  accuracy: 37.65% -> 41.36%     
client [98] (testset)   loss: 4.1398 -> 4.7461  accuracy: 31.69% -> 32.39%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [47] (testset)   loss: 3.1274 -> 3.4055  accuracy: 35.65% -> 36.52%     
client [98] (testset)   loss: 3.5953 -> 4.0926  accuracy: 28.87% -> 33.80%     
client [21] (testset)   loss: 2.5260 -> 2.4964  accuracy: 32.65% -> 45.58%     
client [77] (testset)   loss: 2.6845 -> 3.3809  accuracy: 46.63% -> 46.63%     
client [95] (testset)   loss: 4.5716 -> 5.3077  accuracy: 32.53% -> 34.94%     
client [91] (testset)   loss: 2.4896 -> 3.0732  accuracy: 33.55% -> 23.03%     
client [14] (testset)   loss: 4.0336 -> 4.4348  accuracy: 33.77% -> 22.08%     
client [99] (testset)   loss: 4.0596 -> 4.6509  accuracy: 21.17% -> 24.09%     
client [20] (testset)   loss: 3.3883 -> 3.6193  accuracy: 49.50% -> 47.03%     
client [39] (testset)   loss: 2.3969 -> 2.5757  accuracy: 36.53% -> 37.13%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 2.7754 -> 3.0684  accuracy: 37.31% -> 32.09%     
client [62] (testset)   loss: 4.0769 -> 4.5683  accuracy: 41.75% -> 40.29%     
client [71] (testset)   loss: 4.4040 -> 4.0735  accuracy: 19.85% -> 28.24%     
client [97] (testset)   loss: 4.3043 -> 4.6484  accuracy: 26.67% -> 27.62%     
client [30] (testset)   loss: 5.0163 -> 5.3570  accuracy: 25.97% -> 24.86%     
client [88] (testset)   loss: 2.6542 -> 2.4677  accuracy: 26.26% -> 36.31%     
client [60] (testset)   loss: 3.1449 -> 3.7708  accuracy: 30.30% -> 37.88%     
client [82] (testset)   loss: 3.9577 -> 4.7683  accuracy: 26.74% -> 30.23%     
client [91] (testset)   loss: 3.0128 -> 3.4592  accuracy: 23.03% -> 30.26%     
client [57] (testset)   loss: 2.1520 -> 2.3045  accuracy: 44.17% -> 43.56%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [15] (testset)   loss: 2.7118 -> 3.0572  accuracy: 31.39% -> 32.85%     
client [31] (testset)   loss: 4.3887 -> 4.4820  accuracy: 44.74% -> 45.79%     
client [71] (testset)   loss: 4.4073 -> 5.0604  accuracy: 27.48% -> 27.48%     
client [97] (testset)   loss: 2.7865 -> 2.9710  accuracy: 29.52% -> 24.76%     
client [53] (testset)   loss: 4.4430 -> 4.9375  accuracy: 34.75% -> 34.04%     
client [77] (testset)   loss: 3.3667 -> 3.6726  accuracy: 46.07% -> 46.63%     
client [76] (testset)   loss: 2.3452 -> 2.8563  accuracy: 41.34% -> 32.40%     
client [79] (testset)   loss: 2.3368 -> 2.6812  accuracy: 53.63% -> 54.19%     
client [28] (testset)   loss: 2.6821 -> 3.1839  accuracy: 37.10% -> 42.74%     
client [99] (testset)   loss: 4.6550 -> 5.3129  accuracy: 24.09% -> 22.63%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 2.9619 -> 3.7060  accuracy: 24.76% -> 31.43%     
client [86] (testset)   loss: 4.4805 -> 4.8331  accuracy: 45.76% -> 44.07%     
client [73] (testset)   loss: 2.8965 -> 3.5885  accuracy: 36.69% -> 30.94%     
client [34] (testset)   loss: 3.6927 -> 4.4887  accuracy: 30.94% -> 32.60%     
client [5]  (testset)   loss: 4.0320 -> 4.5756  accuracy: 40.49% -> 39.88%     
client [96] (testset)   loss: 4.8814 -> 5.1161  accuracy: 43.35% -> 43.35%     
client [60] (testset)   loss: 4.0339 -> 4.4068  accuracy: 31.82% -> 33.33%     
client [22] (testset)   loss: 3.6797 -> 4.1777  accuracy: 28.95% -> 28.95%     
client [83] (testset)   loss: 3.7434 -> 4.0735  accuracy: 44.08% -> 43.42%     
client [66] (testset)   loss: 2.7712 -> 3.2497  accuracy: 34.95% -> 36.41%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [65] (testset)   loss: 2.9659 -> 3.4167  accuracy: 30.00% -> 29.09%     
client [76] (testset)   loss: 4.8904 -> 5.1108  accuracy: 35.75% -> 34.64%     
client [95] (testset)   loss: 5.8606 -> 6.1601  accuracy: 35.54% -> 34.94%     
client [17] (testset)   loss: 3.2495 -> 3.7722  accuracy: 33.08% -> 34.59%     
client [8]  (testset)   loss: 4.9833 -> 5.1921  accuracy: 42.71% -> 43.72%     
client [35] (testset)   loss: 4.9790 -> 5.3049  accuracy: 36.73% -> 36.73%     
client [98] (testset)   loss: 4.8457 -> 5.2265  accuracy: 34.51% -> 34.51%     
client [53] (testset)   loss: 3.0636 -> 3.9887  accuracy: 34.04% -> 34.75%     
client [43] (testset)   loss: 4.3952 -> 5.1333  accuracy: 32.59% -> 28.15%     
client [64] (testset)   loss: 3.3387 -> 4.3732  accuracy: 41.22% -> 39.19%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 2.4141 -> 2.6043  accuracy: 38.78% -> 40.14%     
client [88] (testset)   loss: 3.7206 -> 4.2418  accuracy: 35.75% -> 40.22%     
client [3]  (testset)   loss: 3.8938 -> 4.0045  accuracy: 41.41% -> 42.19%     
client [38] (testset)   loss: 3.2990 -> 3.8769  accuracy: 47.49% -> 46.93%     
client [41] (testset)   loss: 4.4774 -> 4.9951  accuracy: 25.00% -> 25.00%     
client [5]  (testset)   loss: 4.5226 -> 4.8829  accuracy: 40.49% -> 39.88%     
client [37] (testset)   loss: 3.2039 -> 3.5960  accuracy: 29.81% -> 32.69%     
client [7]  (testset)   loss: 4.5801 -> 5.0155  accuracy: 33.33% -> 33.33%     
client [47] (testset)   loss: 3.3225 -> 3.9528  accuracy: 43.48% -> 33.91%     
client [45] (testset)   loss: 3.0964 -> 3.4887  accuracy: 43.36% -> 42.48%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 3.9316 -> 4.2542  accuracy: 27.27% -> 30.58%     
client [11] (testset)   loss: 2.5830 -> 3.1181  accuracy: 45.20% -> 44.07%     
client [37] (testset)   loss: 4.4819 -> 5.6216  accuracy: 28.85% -> 34.62%     
client [41] (testset)   loss: 4.3341 -> 4.6980  accuracy: 24.19% -> 24.19%     
client [95] (testset)   loss: 6.2143 -> 6.4336  accuracy: 34.34% -> 33.73%     
client [53] (testset)   loss: 5.4016 -> 5.6241  accuracy: 39.72% -> 37.59%     
client [25] (testset)   loss: 2.8256 -> 3.3271  accuracy: 47.92% -> 39.58%     
client [22] (testset)   loss: 4.4818 -> 4.8504  accuracy: 26.32% -> 28.95%     
client [46] (testset)   loss: 2.9470 -> 3.2713  accuracy: 51.43% -> 45.71%     
client [69] (testset)   loss: 4.0203 -> 4.1218  accuracy: 50.90% -> 50.90%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 4.2721 -> 4.9335  accuracy: 37.39% -> 44.35%     
client [82] (testset)   loss: 5.0553 -> 4.7792  accuracy: 19.77% -> 32.56%     
client [69] (testset)   loss: 4.1460 -> 4.2199  accuracy: 50.90% -> 51.26%     
client [45] (testset)   loss: 2.2671 -> 2.2180  accuracy: 42.92% -> 40.27%     
client [7]  (testset)   loss: 4.5494 -> 5.1132  accuracy: 33.77% -> 34.65%     
client [50] (testset)   loss: 2.5502 -> 2.7774  accuracy: 37.00% -> 44.00%     
client [24] (testset)   loss: 3.5169 -> 3.8620  accuracy: 42.24% -> 37.93%     
client [35] (testset)   loss: 5.5600 -> 5.6916  accuracy: 35.71% -> 34.69%     
client [15] (testset)   loss: 4.8358 -> 4.6660  accuracy: 34.31% -> 33.58%     
client [58] (testset)   loss: 5.3415 -> 5.4898  accuracy: 36.15% -> 35.38%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 5.6083 -> 5.7325  accuracy: 38.79% -> 38.79%     
client [76] (testset)   loss: 4.4365 -> 4.7124  accuracy: 35.75% -> 33.52%     
client [37] (testset)   loss: 5.0356 -> 5.6857  accuracy: 28.85% -> 30.77%     
client [67] (testset)   loss: 4.8524 -> 4.9563  accuracy: 39.01% -> 39.01%     
client [58] (testset)   loss: 5.4946 -> 5.5133  accuracy: 35.38% -> 36.15%     
client [64] (testset)   loss: 4.2966 -> 4.6074  accuracy: 41.89% -> 41.22%     
client [77] (testset)   loss: 3.2013 -> 3.5554  accuracy: 46.07% -> 46.63%     
client [55] (testset)   loss: 4.0921 -> 4.2595  accuracy: 43.48% -> 43.48%     
client [12] (testset)   loss: 3.2805 -> 3.6540  accuracy: 51.52% -> 53.79%     
client [89] (testset)   loss: 6.7791 -> 6.9333  accuracy: 31.21% -> 31.21%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [51] (testset)   loss: 4.7249 -> 4.8352  accuracy: 38.51% -> 39.19%     
client [84] (testset)   loss: 6.4206 -> 6.4900  accuracy: 36.44% -> 36.44%     
client [8]  (testset)   loss: 5.5552 -> 5.6506  accuracy: 42.71% -> 42.71%     
client [18] (testset)   loss: 3.7470 -> 4.1249  accuracy: 46.09% -> 45.31%     
client [94] (testset)   loss: 4.7810 -> 4.9817  accuracy: 37.69% -> 36.92%     
client [81] (testset)   loss: 4.6676 -> 4.8387  accuracy: 40.40% -> 40.40%     
client [3]  (testset)   loss: 4.1219 -> 4.1164  accuracy: 41.41% -> 40.62%     
client [11] (testset)   loss: 4.1765 -> 4.2408  accuracy: 44.07% -> 44.63%     
client [95] (testset)   loss: 6.9059 -> 7.0007  accuracy: 34.94% -> 34.94%     
client [67] (testset)   loss: 4.9055 -> 5.0101  accuracy: 41.21% -> 39.56%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 3.5141 -> 3.7694  accuracy: 36.73% -> 41.50%     
client [79] (testset)   loss: 3.8491 -> 3.9814  accuracy: 54.19% -> 55.31%     
client [58] (testset)   loss: 5.8213 -> 5.9211  accuracy: 37.69% -> 36.92%     
client [88] (testset)   loss: 4.5131 -> 4.8665  accuracy: 39.11% -> 37.99%     
client [46] (testset)   loss: 3.5831 -> 3.9040  accuracy: 53.33% -> 52.38%     
client [11] (testset)   loss: 3.1301 -> 3.4873  accuracy: 43.50% -> 48.59%     
client [55] (testset)   loss: 4.4630 -> 4.5525  accuracy: 44.20% -> 44.20%     
client [13] (testset)   loss: 4.6301 -> 4.7824  accuracy: 35.67% -> 35.67%     
client [31] (testset)   loss: 4.5426 -> 4.6276  accuracy: 46.32% -> 46.32%     
client [75] (testset)   loss: 5.2096 -> 5.3383  accuracy: 40.57% -> 40.57%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 4.9921 -> 5.1829  accuracy: 37.20% -> 36.59%     
client [7]  (testset)   loss: 5.6893 -> 5.8374  accuracy: 34.21% -> 33.77%     
client [57] (testset)   loss: 4.2010 -> 4.2968  accuracy: 49.69% -> 49.69%     
client [13] (testset)   loss: 4.9850 -> 5.1668  accuracy: 33.92% -> 33.92%     
client [43] (testset)   loss: 5.1558 -> 5.4240  accuracy: 29.63% -> 31.11%     
client [91] (testset)   loss: 4.2783 -> 4.6053  accuracy: 34.21% -> 33.55%     
client [10] (testset)   loss: 5.3634 -> 5.5251  accuracy: 38.46% -> 37.50%     
client [82] (testset)   loss: 5.1185 -> 5.5507  accuracy: 33.72% -> 30.23%     
client [64] (testset)   loss: 4.6503 -> 4.8197  accuracy: 40.54% -> 41.22%     
client [22] (testset)   loss: 5.9376 -> 6.1573  accuracy: 30.92% -> 30.92%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [23] (testset)   loss: 2.8761 -> 2.5909  accuracy: 27.27% -> 30.00%     
client [20] (testset)   loss: 3.5654 -> 3.7454  accuracy: 49.01% -> 47.03%     
client [88] (testset)   loss: 4.8318 -> 4.9984  accuracy: 37.99% -> 38.55%     
client [98] (testset)   loss: 5.9523 -> 6.0310  accuracy: 31.69% -> 33.10%     
client [79] (testset)   loss: 4.0527 -> 4.1840  accuracy: 55.87% -> 55.87%     
client [21] (testset)   loss: 3.8475 -> 3.9606  accuracy: 42.18% -> 40.82%     
client [56] (testset)   loss: 4.9615 -> 5.0678  accuracy: 39.29% -> 39.29%     
client [92] (testset)   loss: 5.4239 -> 5.7942  accuracy: 29.59% -> 29.59%     
client [52] (testset)   loss: 5.6386 -> 5.7723  accuracy: 37.31% -> 37.31%     
client [5]  (testset)   loss: 4.8847 -> 5.0389  accuracy: 38.04% -> 37.42%     
FedDpa's average time taken by each global epoch: 0 min 5.79 sec.              
FedDpa's total running time: 0 h 20 m 19 s.                                    
==================== FedDpa Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "3.6572 -> 0.0000",                                    
                "accuracy": "36.08% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "4.9063 -> 0.0000",                                    
                "accuracy": "38.57% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedDpa Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 38.57% at epoch 200                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
