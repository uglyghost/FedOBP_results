==================== FedDpa ====================                               
Experiment Arguments:                                                          
{
    'method': 'feddpa',
    'dataset': {
        'name': 'cifar100',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'cifar100-100clients-0%IID-use20superclasses-Dir(0.1)-seed42',
        'super_class': False,
        'alpha': 0.1,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'parallel',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': 32.0,
        'num_gpus': 1.0,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 200,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 0,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'feddpa': {
        'fisher_threshold': 0.4
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [81] (testset)   loss: 2.6406 -> 2.6774  accuracy: 38.41% -> 41.72%     
client [77] (testset)   loss: 2.2599 -> 2.3549  accuracy: 35.96% -> 33.71%     
client [21] (testset)   loss: 4.5839 -> 2.3721  accuracy: 0.00% -> 36.73%      
client [68] (testset)   loss: 2.3629 -> 2.3036  accuracy: 36.13% -> 41.60%     
client [93] (testset)   loss: 4.5813 -> 2.6128  accuracy: 0.00% -> 33.60%      
client [31] (testset)   loss: 2.3491 -> 2.5296  accuracy: 38.95% -> 37.37%     
client [20] (testset)   loss: 4.4983 -> 2.2107  accuracy: 3.96% -> 43.56%      
client [48] (testset)   loss: 2.8993 -> 2.9871  accuracy: 24.24% -> 24.85%     
client [59] (testset)   loss: 4.5838 -> 2.4841  accuracy: 0.00% -> 31.33%      
client [34] (testset)   loss: 2.7192 -> 2.8003  accuracy: 27.07% -> 27.62%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [99] (testset)   loss: 4.5777 -> 3.4054  accuracy: 0.73% -> 25.55%      
client [69] (testset)   loss: 2.2002 -> 1.9344  accuracy: 44.04% -> 52.71%     
client [67] (testset)   loss: 4.5039 -> 2.5640  accuracy: 2.20% -> 38.46%      
client [0]  (testset)   loss: 4.6434 -> 2.3901  accuracy: 0.98% -> 40.20%      
client [76] (testset)   loss: 4.6061 -> 2.4621  accuracy: 1.12% -> 37.99%      
client [41] (testset)   loss: 4.5914 -> 2.7235  accuracy: 0.00% -> 23.39%      
client [2]  (testset)   loss: 4.6097 -> 2.7476  accuracy: 0.00% -> 25.89%      
client [62] (testset)   loss: 4.6087 -> 2.2910  accuracy: 0.49% -> 41.26%      
client [14] (testset)   loss: 2.7302 -> 2.9178  accuracy: 38.96% -> 32.47%     
client [46] (testset)   loss: 4.5783 -> 2.1394  accuracy: 0.00% -> 46.67%      
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 2.5933 -> 2.8835  accuracy: 36.21% -> 43.97%     
client [68] (testset)   loss: 4.6066 -> 2.2774  accuracy: 0.00% -> 41.60%      
client [57] (testset)   loss: 2.1870 -> 2.1574  accuracy: 41.72% -> 47.24%     
client [17] (testset)   loss: 2.6350 -> 2.9632  accuracy: 35.34% -> 35.34%     
client [54] (testset)   loss: 3.5721 -> 4.3473  accuracy: 30.83% -> 35.00%     
client [23] (testset)   loss: 4.6665 -> 2.6949  accuracy: 0.91% -> 27.27%      
client [35] (testset)   loss: 2.3688 -> 2.4494  accuracy: 36.22% -> 37.24%     
client [59] (testset)   loss: 2.3208 -> 2.5981  accuracy: 37.34% -> 38.63%     
client [31] (testset)   loss: 2.4545 -> 2.7202  accuracy: 37.89% -> 40.53%     
client [9]  (testset)   loss: 4.5563 -> 2.4953  accuracy: 0.00% -> 34.23%      
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [33] (testset)   loss: 2.4814 -> 3.0278  accuracy: 31.19% -> 22.02%     
client [64] (testset)   loss: 2.2922 -> 2.5932  accuracy: 41.22% -> 38.51%     
client [16] (testset)   loss: 2.8421 -> 3.0022  accuracy: 22.31% -> 28.10%     
client [44] (testset)   loss: 4.6002 -> 2.7616  accuracy: 0.00% -> 27.45%      
client [8]  (testset)   loss: 2.9534 -> 3.7075  accuracy: 37.19% -> 36.68%     
client [31] (testset)   loss: 2.3768 -> 3.0728  accuracy: 45.79% -> 45.79%     
client [47] (testset)   loss: 2.6462 -> 3.0089  accuracy: 40.00% -> 40.00%     
client [36] (testset)   loss: 2.7244 -> 2.8346  accuracy: 29.20% -> 27.43%     
client [20] (testset)   loss: 2.5503 -> 3.5886  accuracy: 40.59% -> 42.08%     
client [56] (testset)   loss: 2.3781 -> 2.5931  accuracy: 39.29% -> 36.90%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [60] (testset)   loss: 2.4885 -> 2.6795  accuracy: 36.36% -> 39.39%     
client [4]  (testset)   loss: 2.3019 -> 2.7603  accuracy: 46.62% -> 47.30%     
client [28] (testset)   loss: 2.6864 -> 2.5176  accuracy: 27.42% -> 40.32%     
client [25] (testset)   loss: 2.3999 -> 2.5022  accuracy: 38.54% -> 39.58%     
client [58] (testset)   loss: 2.8353 -> 3.8097  accuracy: 40.77% -> 36.92%     
client [44] (testset)   loss: 2.7036 -> 2.6835  accuracy: 26.14% -> 30.07%     
client [39] (testset)   loss: 2.5193 -> 2.7245  accuracy: 36.53% -> 37.13%     
client [29] (testset)   loss: 3.3035 -> 3.1570  accuracy: 29.33% -> 36.00%     
client [3]  (testset)   loss: 2.2390 -> 2.5757  accuracy: 39.84% -> 45.31%     
client [84] (testset)   loss: 3.2997 -> 4.3485  accuracy: 37.29% -> 33.90%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 2.3361 -> 2.4755  accuracy: 37.41% -> 36.73%     
client [84] (testset)   loss: 2.7932 -> 3.4314  accuracy: 31.78% -> 32.63%     
client [10] (testset)   loss: 2.6651 -> 2.7333  accuracy: 34.62% -> 28.85%     
client [36] (testset)   loss: 2.7791 -> 2.9950  accuracy: 28.32% -> 34.51%     
client [65] (testset)   loss: 2.9068 -> 3.1777  accuracy: 33.64% -> 36.36%     
client [81] (testset)   loss: 3.0170 -> 3.5547  accuracy: 30.46% -> 38.41%     
client [79] (testset)   loss: 1.8380 -> 2.7302  accuracy: 55.31% -> 46.93%     
client [42] (testset)   loss: 2.3326 -> 2.8477  accuracy: 42.47% -> 45.21%     
client [11] (testset)   loss: 2.4044 -> 2.8822  accuracy: 45.20% -> 46.33%     
client [96] (testset)   loss: 2.4713 -> 3.3617  accuracy: 36.99% -> 40.46%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [53] (testset)   loss: 2.7456 -> 3.1616  accuracy: 31.91% -> 40.43%     
client [8]  (testset)   loss: 3.2761 -> 4.5650  accuracy: 42.71% -> 40.70%     
client [52] (testset)   loss: 3.1079 -> 3.6833  accuracy: 37.31% -> 35.82%     
client [42] (testset)   loss: 2.9715 -> 3.1497  accuracy: 50.00% -> 45.21%     
client [59] (testset)   loss: 2.8329 -> 3.4907  accuracy: 35.19% -> 40.77%     
client [69] (testset)   loss: 2.6809 -> 3.1348  accuracy: 49.82% -> 52.71%     
client [26] (testset)   loss: 2.6110 -> 2.9777  accuracy: 35.40% -> 40.71%     
client [7]  (testset)   loss: 3.2349 -> 4.3361  accuracy: 37.72% -> 35.09%     
client [49] (testset)   loss: 2.8592 -> 3.1363  accuracy: 41.98% -> 43.21%     
client [98] (testset)   loss: 3.2855 -> 3.7888  accuracy: 29.58% -> 34.51%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [47] (testset)   loss: 2.9058 -> 3.5213  accuracy: 38.26% -> 43.48%     
client [98] (testset)   loss: 3.2837 -> 4.1397  accuracy: 28.17% -> 29.58%     
client [21] (testset)   loss: 2.7813 -> 2.9192  accuracy: 36.73% -> 36.73%     
client [77] (testset)   loss: 3.1312 -> 3.3279  accuracy: 45.51% -> 46.63%     
client [95] (testset)   loss: 4.2862 -> 4.9943  accuracy: 36.14% -> 35.54%     
client [91] (testset)   loss: 2.4840 -> 2.7460  accuracy: 30.92% -> 29.61%     
client [14] (testset)   loss: 3.4869 -> 4.5764  accuracy: 27.27% -> 29.87%     
client [99] (testset)   loss: 3.7556 -> 4.7307  accuracy: 24.09% -> 24.09%     
client [20] (testset)   loss: 3.0198 -> 3.2914  accuracy: 46.04% -> 47.03%     
client [39] (testset)   loss: 2.7323 -> 3.2143  accuracy: 35.33% -> 31.14%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 2.9649 -> 3.6820  accuracy: 38.06% -> 41.04%     
client [62] (testset)   loss: 3.1674 -> 3.7619  accuracy: 43.69% -> 41.26%     
client [71] (testset)   loss: 3.6247 -> 4.2997  accuracy: 29.01% -> 30.53%     
client [97] (testset)   loss: 3.8958 -> 4.5858  accuracy: 26.67% -> 25.71%     
client [30] (testset)   loss: 3.8634 -> 4.6293  accuracy: 24.31% -> 24.31%     
client [88] (testset)   loss: 2.6038 -> 2.5542  accuracy: 28.49% -> 35.75%     
client [60] (testset)   loss: 4.0076 -> 3.7896  accuracy: 34.85% -> 45.45%     
client [82] (testset)   loss: 3.8323 -> 4.4276  accuracy: 31.40% -> 32.56%     
client [91] (testset)   loss: 2.6187 -> 3.3741  accuracy: 31.58% -> 26.97%     
client [57] (testset)   loss: 2.5800 -> 3.0561  accuracy: 45.40% -> 50.31%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [15] (testset)   loss: 3.3380 -> 3.7905  accuracy: 30.66% -> 37.96%     
client [31] (testset)   loss: 3.3619 -> 3.7111  accuracy: 41.58% -> 43.16%     
client [71] (testset)   loss: 3.9638 -> 3.8368  accuracy: 32.82% -> 26.72%     
client [97] (testset)   loss: 3.1213 -> 4.1296  accuracy: 26.67% -> 33.33%     
client [53] (testset)   loss: 3.4081 -> 4.1149  accuracy: 40.43% -> 41.13%     
client [77] (testset)   loss: 2.8170 -> 3.3946  accuracy: 47.19% -> 46.07%     
client [76] (testset)   loss: 3.0346 -> 4.0843  accuracy: 33.52% -> 32.40%     
client [79] (testset)   loss: 2.3680 -> 2.9557  accuracy: 53.07% -> 51.40%     
client [28] (testset)   loss: 2.7701 -> 3.3080  accuracy: 42.74% -> 39.52%     
client [99] (testset)   loss: 3.9483 -> 5.2583  accuracy: 24.82% -> 25.55%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 3.8074 -> 4.3358  accuracy: 34.29% -> 27.62%     
client [86] (testset)   loss: 3.8010 -> 4.2844  accuracy: 31.36% -> 36.44%     
client [73] (testset)   loss: 3.7303 -> 4.3787  accuracy: 31.65% -> 35.25%     
client [34] (testset)   loss: 3.4660 -> 4.0942  accuracy: 31.49% -> 35.91%     
client [5]  (testset)   loss: 3.6462 -> 3.9056  accuracy: 40.49% -> 38.04%     
client [96] (testset)   loss: 3.9148 -> 4.2861  accuracy: 42.77% -> 41.62%     
client [60] (testset)   loss: 3.8444 -> 4.1717  accuracy: 39.39% -> 40.91%     
client [22] (testset)   loss: 3.9723 -> 4.7531  accuracy: 25.66% -> 28.95%     
client [83] (testset)   loss: 3.6028 -> 4.2915  accuracy: 37.50% -> 40.13%     
client [66] (testset)   loss: 3.1214 -> 4.6196  accuracy: 37.38% -> 33.98%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [65] (testset)   loss: 3.5185 -> 4.1606  accuracy: 35.45% -> 32.73%     
client [76] (testset)   loss: 4.0181 -> 4.4637  accuracy: 37.43% -> 34.08%     
client [95] (testset)   loss: 4.6662 -> 5.2271  accuracy: 36.14% -> 36.14%     
client [17] (testset)   loss: 4.2510 -> 4.3272  accuracy: 35.34% -> 35.34%     
client [8]  (testset)   loss: 3.7048 -> 4.6256  accuracy: 34.67% -> 43.22%     
client [35] (testset)   loss: 4.1808 -> 4.4517  accuracy: 37.76% -> 37.76%     
client [98] (testset)   loss: 3.8730 -> 4.3270  accuracy: 33.10% -> 33.80%     
client [53] (testset)   loss: 3.3012 -> 3.8122  accuracy: 37.59% -> 38.30%     
client [43] (testset)   loss: 4.4255 -> 4.9274  accuracy: 31.85% -> 29.63%     
client [64] (testset)   loss: 3.1449 -> 3.6854  accuracy: 39.19% -> 43.24%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 2.6578 -> 3.3056  accuracy: 36.73% -> 42.18%     
client [88] (testset)   loss: 3.7231 -> 4.1181  accuracy: 42.46% -> 42.46%     
client [3]  (testset)   loss: 3.3478 -> 3.6160  accuracy: 40.62% -> 42.19%     
client [38] (testset)   loss: 3.2179 -> 3.7619  accuracy: 42.46% -> 48.04%     
client [5]  (testset)   loss: 3.6204 -> 4.2589  accuracy: 39.88% -> 33.74%     
client [41] (testset)   loss: 3.7307 -> 4.1521  accuracy: 29.84% -> 32.26%     
client [37] (testset)   loss: 3.4962 -> 4.0922  accuracy: 36.54% -> 36.54%     
client [7]  (testset)   loss: 3.6111 -> 4.1476  accuracy: 34.65% -> 33.77%     
client [47] (testset)   loss: 3.2630 -> 3.8084  accuracy: 40.87% -> 46.09%     
client [45] (testset)   loss: 2.3673 -> 3.0428  accuracy: 46.90% -> 42.48%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 3.6014 -> 4.3661  accuracy: 36.36% -> 37.19%     
client [11] (testset)   loss: 2.4187 -> 2.8810  accuracy: 43.50% -> 49.15%     
client [37] (testset)   loss: 4.1990 -> 4.7133  accuracy: 36.54% -> 35.58%     
client [41] (testset)   loss: 3.8036 -> 4.2660  accuracy: 31.45% -> 31.45%     
client [95] (testset)   loss: 4.6182 -> 5.1373  accuracy: 37.35% -> 37.95%     
client [53] (testset)   loss: 3.7783 -> 4.2938  accuracy: 38.30% -> 41.84%     
client [25] (testset)   loss: 3.0262 -> 3.5624  accuracy: 50.00% -> 43.75%     
client [22] (testset)   loss: 3.9340 -> 4.3210  accuracy: 30.26% -> 26.97%     
client [46] (testset)   loss: 2.5737 -> 3.1057  accuracy: 49.52% -> 52.38%     
client [69] (testset)   loss: 3.0833 -> 3.3811  accuracy: 51.99% -> 50.54%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 3.7228 -> 4.1015  accuracy: 46.96% -> 49.57%     
client [82] (testset)   loss: 3.7795 -> 4.1702  accuracy: 27.91% -> 29.07%     
client [69] (testset)   loss: 3.4097 -> 3.5259  accuracy: 51.26% -> 51.26%     
client [45] (testset)   loss: 2.5809 -> 3.1713  accuracy: 44.25% -> 42.92%     
client [7]  (testset)   loss: 3.8941 -> 4.4854  accuracy: 34.21% -> 36.40%     
client [50] (testset)   loss: 2.4310 -> 2.8478  accuracy: 51.00% -> 46.00%     
client [24] (testset)   loss: 3.3348 -> 3.9301  accuracy: 33.62% -> 39.66%     
client [35] (testset)   loss: 4.1656 -> 7.8402  accuracy: 37.24% -> 26.02%     
client [15] (testset)   loss: 4.4058 -> 4.6101  accuracy: 29.20% -> 34.31%     
client [58] (testset)   loss: 3.8041 -> 4.2219  accuracy: 39.23% -> 38.46%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 3.6969 -> 4.0818  accuracy: 40.00% -> 38.79%     
client [76] (testset)   loss: 3.8355 -> 4.4438  accuracy: 34.64% -> 32.40%     
client [37] (testset)   loss: 4.4525 -> 5.0044  accuracy: 32.69% -> 34.62%     
client [67] (testset)   loss: 4.0253 -> 4.3485  accuracy: 36.81% -> 36.81%     
client [58] (testset)   loss: 4.0921 -> 4.2301  accuracy: 36.92% -> 37.69%     
client [64] (testset)   loss: 3.7864 -> 4.0252  accuracy: 42.57% -> 43.24%     
client [77] (testset)   loss: 3.0633 -> 3.7386  accuracy: 46.07% -> 47.19%     
client [55] (testset)   loss: 3.2443 -> 3.2368  accuracy: 40.58% -> 43.48%     
client [12] (testset)   loss: 3.1077 -> 3.5056  accuracy: 46.97% -> 52.27%     
client [89] (testset)   loss: 5.2911 -> 5.5361  accuracy: 29.30% -> 30.57%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [51] (testset)   loss: 3.5703 -> 4.3342  accuracy: 39.86% -> 41.22%     
client [84] (testset)   loss: 3.7828 -> 4.4968  accuracy: 37.29% -> 36.86%     
client [8]  (testset)   loss: 4.2369 -> 4.4788  accuracy: 41.71% -> 42.21%     
client [18] (testset)   loss: 3.1122 -> 3.5380  accuracy: 49.22% -> 50.00%     
client [94] (testset)   loss: 4.2572 -> 4.6578  accuracy: 38.46% -> 39.23%     
client [81] (testset)   loss: 3.9481 -> 4.1910  accuracy: 46.36% -> 45.70%     
client [3]  (testset)   loss: 3.3937 -> 3.6507  accuracy: 44.53% -> 42.19%     
client [11] (testset)   loss: 3.3446 -> 3.6381  accuracy: 42.94% -> 42.37%     
client [95] (testset)   loss: 4.7906 -> 5.2432  accuracy: 33.73% -> 36.75%     
client [67] (testset)   loss: 4.1414 -> 4.3637  accuracy: 36.26% -> 38.46%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 3.1546 -> 3.3417  accuracy: 39.46% -> 44.90%     
client [79] (testset)   loss: 3.0006 -> 3.2436  accuracy: 53.63% -> 52.51%     
client [58] (testset)   loss: 2.7634 -> 3.6565  accuracy: 39.23% -> 37.69%     
client [88] (testset)   loss: 3.8316 -> 4.1598  accuracy: 40.22% -> 40.78%     
client [46] (testset)   loss: 2.6791 -> 3.1125  accuracy: 44.76% -> 55.24%     
client [11] (testset)   loss: 2.6139 -> 3.1577  accuracy: 49.72% -> 47.46%     
client [55] (testset)   loss: 2.9601 -> 3.0696  accuracy: 40.58% -> 41.30%     
client [13] (testset)   loss: 3.9300 -> 4.0353  accuracy: 35.67% -> 36.26%     
client [31] (testset)   loss: 3.4970 -> 3.5712  accuracy: 41.05% -> 40.00%     
client [75] (testset)   loss: 4.1841 -> 4.5426  accuracy: 41.98% -> 41.51%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 3.8388 -> 4.1722  accuracy: 41.46% -> 40.24%     
client [7]  (testset)   loss: 4.4408 -> 4.7067  accuracy: 35.09% -> 35.53%     
client [57] (testset)   loss: 2.8934 -> 3.4089  accuracy: 49.08% -> 50.92%     
client [13] (testset)   loss: 3.9494 -> 3.9128  accuracy: 36.26% -> 28.07%     
client [43] (testset)   loss: 4.4681 -> 4.7548  accuracy: 30.37% -> 31.11%     
client [91] (testset)   loss: 3.9141 -> 4.2636  accuracy: 34.21% -> 36.18%     
client [10] (testset)   loss: 2.8287 -> 3.8906  accuracy: 40.38% -> 44.23%     
client [82] (testset)   loss: 4.1603 -> 4.6267  accuracy: 33.72% -> 32.56%     
client [64] (testset)   loss: 3.9368 -> 4.1105  accuracy: 43.92% -> 41.89%     
client [22] (testset)   loss: 4.3146 -> 4.9424  accuracy: 30.26% -> 32.89%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [23] (testset)   loss: 3.5115 -> 3.7690  accuracy: 31.82% -> 35.45%     
client [20] (testset)   loss: 3.3297 -> 3.5397  accuracy: 48.02% -> 48.51%     
client [88] (testset)   loss: 3.9846 -> 4.2380  accuracy: 42.46% -> 41.90%     
client [98] (testset)   loss: 4.1614 -> 4.5030  accuracy: 34.51% -> 35.92%     
client [79] (testset)   loss: 3.1188 -> 3.3356  accuracy: 51.40% -> 50.84%     
client [21] (testset)   loss: 3.0000 -> 3.4880  accuracy: 35.37% -> 42.18%     
client [92] (testset)   loss: 4.1851 -> 4.6124  accuracy: 33.67% -> 34.69%     
client [56] (testset)   loss: 3.2091 -> 3.4961  accuracy: 44.05% -> 46.43%     
client [52] (testset)   loss: 4.1047 -> 4.4019  accuracy: 42.54% -> 42.54%     
client [5]  (testset)   loss: 4.4038 -> 4.6169  accuracy: 39.26% -> 39.88%     
FedDpa's average time taken by each global epoch: 0 min 5.15 sec.              
FedDpa's total running time: 0 h 18 m 26 s.                                    
==================== FedDpa Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "3.3956 -> 0.0000",                                    
                "accuracy": "38.27% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "3.9968 -> 0.0000",                                    
                "accuracy": "39.39% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedDpa Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 39.39% at epoch 200                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
