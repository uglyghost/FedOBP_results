==================== FedDpa ====================                               
Experiment Arguments:                                                          
{
    'method': 'feddpa',
    'dataset': {
        'name': 'cifar100',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'cifar100-100clients-0%IID-use20superclasses-Dir(0.1)-seed42',
        'super_class': False,
        'alpha': 0.1,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'parallel',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': 32.0,
        'num_gpus': 1.0,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 200,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 0,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'feddpa': {
        'fisher_threshold': 0.7
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [81] (testset)   loss: 2.7983 -> 3.0709  accuracy: 35.10% -> 27.81%     
client [77] (testset)   loss: 2.0547 -> 2.3528  accuracy: 43.82% -> 45.51%     
client [21] (testset)   loss: 4.5429 -> 2.2547  accuracy: 2.04% -> 36.73%      
client [68] (testset)   loss: 2.6273 -> 2.3049  accuracy: 35.71% -> 42.86%     
client [93] (testset)   loss: 4.5267 -> 2.7493  accuracy: 0.00% -> 30.40%      
client [31] (testset)   loss: 2.6461 -> 2.3680  accuracy: 36.84% -> 40.53%     
client [20] (testset)   loss: 4.3351 -> 2.0617  accuracy: 6.44% -> 50.99%      
client [48] (testset)   loss: 2.7939 -> 2.6714  accuracy: 33.94% -> 34.55%     
client [59] (testset)   loss: 4.5136 -> 2.2590  accuracy: 0.43% -> 38.63%      
client [34] (testset)   loss: 2.7570 -> 2.9474  accuracy: 27.07% -> 31.49%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [99] (testset)   loss: 4.5089 -> 3.4916  accuracy: 0.00% -> 29.20%      
client [69] (testset)   loss: 2.1419 -> 2.0597  accuracy: 45.13% -> 49.46%     
client [67] (testset)   loss: 4.5564 -> 2.5995  accuracy: 0.55% -> 32.42%      
client [0]  (testset)   loss: 4.6477 -> 2.4692  accuracy: 0.00% -> 37.25%      
client [41] (testset)   loss: 4.6833 -> 2.8805  accuracy: 1.61% -> 29.03%      
client [76] (testset)   loss: 4.6134 -> 2.9208  accuracy: 0.00% -> 28.49%      
client [2]  (testset)   loss: 4.7866 -> 2.7916  accuracy: 0.00% -> 32.14%      
client [62] (testset)   loss: 4.7024 -> 2.3216  accuracy: 0.49% -> 46.12%      
client [14] (testset)   loss: 2.7803 -> 3.4546  accuracy: 36.36% -> 27.27%     
client [46] (testset)   loss: 2.3246 -> 3.0969  accuracy: 43.81% -> 57.14%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 2.5886 -> 2.5896  accuracy: 33.62% -> 45.69%     
client [68] (testset)   loss: 4.7824 -> 2.4909  accuracy: 0.00% -> 42.02%      
client [57] (testset)   loss: 2.3642 -> 2.4187  accuracy: 41.72% -> 48.47%     
client [17] (testset)   loss: 2.8250 -> 3.5690  accuracy: 36.09% -> 34.59%     
client [54] (testset)   loss: 3.2748 -> 4.1815  accuracy: 39.17% -> 34.17%     
client [23] (testset)   loss: 4.9472 -> 2.9447  accuracy: 0.00% -> 30.00%      
client [35] (testset)   loss: 2.2957 -> 2.8124  accuracy: 39.29% -> 39.29%     
client [59] (testset)   loss: 2.4147 -> 3.2321  accuracy: 42.06% -> 37.34%     
client [31] (testset)   loss: 2.3997 -> 3.0847  accuracy: 44.74% -> 44.74%     
client [9]  (testset)   loss: 4.5238 -> 2.6765  accuracy: 0.67% -> 36.91%      
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [33] (testset)   loss: 2.7830 -> 3.7679  accuracy: 27.52% -> 27.52%     
client [64] (testset)   loss: 2.3192 -> 3.5228  accuracy: 45.27% -> 34.46%     
client [16] (testset)   loss: 2.7200 -> 4.1146  accuracy: 36.36% -> 34.71%     
client [44] (testset)   loss: 4.9629 -> 3.0044  accuracy: 0.00% -> 26.80%      
client [8]  (testset)   loss: 2.9930 -> 3.9163  accuracy: 47.24% -> 40.70%     
client [31] (testset)   loss: 2.9013 -> 3.3424  accuracy: 41.05% -> 46.84%     
client [47] (testset)   loss: 2.8783 -> 3.7872  accuracy: 35.65% -> 38.26%     
client [36] (testset)   loss: 2.6615 -> 3.0154  accuracy: 33.63% -> 33.63%     
client [56] (testset)   loss: 2.3337 -> 2.6441  accuracy: 46.43% -> 44.05%     
client [20] (testset)   loss: 2.4866 -> 3.0498  accuracy: 46.53% -> 47.03%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [60] (testset)   loss: 2.5666 -> 4.4287  accuracy: 42.42% -> 37.88%     
client [4]  (testset)   loss: 2.3113 -> 3.0375  accuracy: 48.65% -> 43.24%     
client [28] (testset)   loss: 3.0718 -> 2.8463  accuracy: 29.84% -> 41.94%     
client [25] (testset)   loss: 2.9819 -> 2.7915  accuracy: 38.54% -> 46.88%     
client [58] (testset)   loss: 3.0378 -> 3.9625  accuracy: 32.31% -> 33.85%     
client [44] (testset)   loss: 2.7883 -> 3.7106  accuracy: 35.29% -> 32.68%     
client [39] (testset)   loss: 2.7332 -> 3.1683  accuracy: 37.13% -> 40.12%     
client [29] (testset)   loss: 2.6616 -> 3.5252  accuracy: 34.00% -> 36.67%     
client [3]  (testset)   loss: 2.5933 -> 2.5289  accuracy: 40.62% -> 49.22%     
client [84] (testset)   loss: 3.0624 -> 4.1482  accuracy: 36.02% -> 37.29%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 2.5910 -> 2.7215  accuracy: 35.37% -> 44.90%     
client [84] (testset)   loss: 3.6169 -> 4.5214  accuracy: 38.98% -> 37.29%     
client [10] (testset)   loss: 2.8308 -> 3.0747  accuracy: 42.31% -> 39.42%     
client [36] (testset)   loss: 2.4904 -> 3.3726  accuracy: 40.71% -> 34.51%     
client [65] (testset)   loss: 3.0269 -> 3.8957  accuracy: 34.55% -> 36.36%     
client [81] (testset)   loss: 3.1498 -> 3.2402  accuracy: 40.40% -> 47.02%     
client [79] (testset)   loss: 2.0796 -> 3.0258  accuracy: 53.07% -> 54.19%     
client [42] (testset)   loss: 2.6378 -> 2.9888  accuracy: 50.68% -> 50.68%     
client [11] (testset)   loss: 2.5259 -> 3.0598  accuracy: 44.07% -> 49.15%     
client [96] (testset)   loss: 2.6202 -> 3.5045  accuracy: 43.35% -> 38.73%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [53] (testset)   loss: 3.0056 -> 4.4052  accuracy: 36.17% -> 35.46%     
client [8]  (testset)   loss: 3.1947 -> 4.4396  accuracy: 46.73% -> 44.72%     
client [52] (testset)   loss: 3.2144 -> 3.8834  accuracy: 43.28% -> 44.78%     
client [42] (testset)   loss: 2.6392 -> 3.4172  accuracy: 43.15% -> 46.58%     
client [69] (testset)   loss: 2.9398 -> 3.3865  accuracy: 50.54% -> 49.82%     
client [59] (testset)   loss: 3.0895 -> 3.6503  accuracy: 36.05% -> 39.48%     
client [26] (testset)   loss: 2.8373 -> 3.8211  accuracy: 38.94% -> 41.59%     
client [7]  (testset)   loss: 3.5923 -> 4.4891  accuracy: 33.77% -> 36.84%     
client [49] (testset)   loss: 2.4716 -> 3.2926  accuracy: 47.53% -> 44.44%     
client [98] (testset)   loss: 3.3987 -> 3.9269  accuracy: 33.10% -> 36.62%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [47] (testset)   loss: 3.1911 -> 4.1685  accuracy: 40.00% -> 40.87%     
client [98] (testset)   loss: 3.6556 -> 4.2082  accuracy: 35.21% -> 37.32%     
client [21] (testset)   loss: 2.7943 -> 3.3225  accuracy: 37.41% -> 38.78%     
client [77] (testset)   loss: 3.1347 -> 4.2689  accuracy: 47.19% -> 42.13%     
client [95] (testset)   loss: 3.7978 -> 4.5684  accuracy: 38.55% -> 39.76%     
client [91] (testset)   loss: 2.8136 -> 3.4458  accuracy: 38.16% -> 34.87%     
client [14] (testset)   loss: 3.1843 -> 4.0481  accuracy: 33.77% -> 37.66%     
client [99] (testset)   loss: 3.7233 -> 4.9675  accuracy: 30.66% -> 30.66%     
client [20] (testset)   loss: 2.8823 -> 3.3670  accuracy: 51.49% -> 49.50%     
client [39] (testset)   loss: 3.0215 -> 4.2070  accuracy: 42.51% -> 35.93%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 3.2772 -> 3.7035  accuracy: 35.07% -> 39.55%     
client [62] (testset)   loss: 3.7470 -> 4.1094  accuracy: 38.35% -> 42.23%     
client [71] (testset)   loss: 3.7011 -> 5.1877  accuracy: 35.88% -> 26.72%     
client [97] (testset)   loss: 4.1840 -> 4.6156  accuracy: 33.33% -> 37.14%     
client [30] (testset)   loss: 4.4543 -> 4.9141  accuracy: 26.52% -> 23.76%     
client [88] (testset)   loss: 2.8680 -> 3.2915  accuracy: 35.20% -> 37.43%     
client [60] (testset)   loss: 3.0081 -> 4.1326  accuracy: 40.91% -> 42.42%     
client [82] (testset)   loss: 3.7513 -> 4.1937  accuracy: 27.91% -> 34.88%     
client [91] (testset)   loss: 2.8740 -> 3.4391  accuracy: 33.55% -> 39.47%     
client [57] (testset)   loss: 2.5133 -> 3.0521  accuracy: 43.56% -> 50.31%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [15] (testset)   loss: 3.1453 -> 3.9490  accuracy: 37.96% -> 38.69%     
client [31] (testset)   loss: 3.3552 -> 3.6597  accuracy: 42.63% -> 45.26%     
client [71] (testset)   loss: 5.2245 -> 4.5826  accuracy: 22.90% -> 29.77%     
client [97] (testset)   loss: 3.4383 -> 4.0742  accuracy: 28.57% -> 28.57%     
client [53] (testset)   loss: 3.1514 -> 3.7085  accuracy: 45.39% -> 44.68%     
client [77] (testset)   loss: 3.3138 -> 3.8130  accuracy: 46.07% -> 47.19%     
client [76] (testset)   loss: 3.3798 -> 4.1859  accuracy: 37.99% -> 33.52%     
client [79] (testset)   loss: 2.5822 -> 3.6333  accuracy: 53.07% -> 49.72%     
client [28] (testset)   loss: 2.6121 -> 3.4099  accuracy: 46.77% -> 41.13%     
client [99] (testset)   loss: 4.0913 -> 5.7101  accuracy: 30.66% -> 24.82%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 3.4160 -> 4.2886  accuracy: 27.62% -> 29.52%     
client [86] (testset)   loss: 3.4252 -> 4.2921  accuracy: 33.05% -> 36.44%     
client [73] (testset)   loss: 3.3142 -> 4.0681  accuracy: 38.13% -> 37.41%     
client [34] (testset)   loss: 3.3944 -> 4.7801  accuracy: 33.70% -> 32.04%     
client [5]  (testset)   loss: 3.5560 -> 4.4409  accuracy: 39.26% -> 40.49%     
client [96] (testset)   loss: 3.2742 -> 4.0529  accuracy: 45.09% -> 42.77%     
client [60] (testset)   loss: 3.3219 -> 3.9287  accuracy: 40.91% -> 45.45%     
client [22] (testset)   loss: 3.6910 -> 4.3439  accuracy: 30.92% -> 30.92%     
client [83] (testset)   loss: 3.5395 -> 3.9201  accuracy: 43.42% -> 43.42%     
client [66] (testset)   loss: 2.9546 -> 3.7620  accuracy: 44.66% -> 39.81%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [65] (testset)   loss: 3.5366 -> 3.9052  accuracy: 37.27% -> 40.91%     
client [76] (testset)   loss: 3.5342 -> 4.0800  accuracy: 35.75% -> 35.75%     
client [95] (testset)   loss: 3.9612 -> 4.8421  accuracy: 36.14% -> 37.95%     
client [17] (testset)   loss: 3.7574 -> 4.7113  accuracy: 36.09% -> 36.09%     
client [8]  (testset)   loss: 4.2347 -> 4.7552  accuracy: 41.71% -> 43.72%     
client [35] (testset)   loss: 3.6449 -> 4.1306  accuracy: 38.78% -> 39.29%     
client [98] (testset)   loss: 3.4230 -> 3.9010  accuracy: 32.39% -> 34.51%     
client [53] (testset)   loss: 3.2074 -> 3.8587  accuracy: 41.13% -> 43.97%     
client [43] (testset)   loss: 3.7508 -> 4.3327  accuracy: 27.41% -> 34.07%     
client [64] (testset)   loss: 3.3355 -> 3.9693  accuracy: 43.92% -> 42.57%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 2.7711 -> 3.1772  accuracy: 38.78% -> 42.86%     
client [88] (testset)   loss: 3.2920 -> 4.0234  accuracy: 34.64% -> 40.78%     
client [3]  (testset)   loss: 2.4842 -> 2.8391  accuracy: 47.66% -> 47.66%     
client [38] (testset)   loss: 2.6283 -> 3.0393  accuracy: 53.07% -> 44.69%     
client [41] (testset)   loss: 3.3812 -> 3.9027  accuracy: 32.26% -> 34.68%     
client [5]  (testset)   loss: 3.8938 -> 4.5768  accuracy: 41.72% -> 41.72%     
client [37] (testset)   loss: 3.7417 -> 4.7013  accuracy: 33.65% -> 33.65%     
client [7]  (testset)   loss: 3.9486 -> 4.6996  accuracy: 35.96% -> 32.89%     
client [45] (testset)   loss: 2.9894 -> 3.3944  accuracy: 43.81% -> 46.02%     
client [47] (testset)   loss: 3.3529 -> 3.7720  accuracy: 40.00% -> 43.48%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 3.7179 -> 4.8962  accuracy: 33.88% -> 32.23%     
client [11] (testset)   loss: 2.5933 -> 3.2600  accuracy: 45.76% -> 45.76%     
client [37] (testset)   loss: 3.6528 -> 4.3589  accuracy: 31.73% -> 37.50%     
client [41] (testset)   loss: 3.5264 -> 4.0792  accuracy: 33.06% -> 32.26%     
client [95] (testset)   loss: 4.1258 -> 4.8245  accuracy: 42.17% -> 40.96%     
client [53] (testset)   loss: 3.6495 -> 3.8917  accuracy: 33.33% -> 45.39%     
client [25] (testset)   loss: 2.6260 -> 3.2907  accuracy: 43.75% -> 51.04%     
client [22] (testset)   loss: 3.8233 -> 4.3818  accuracy: 32.24% -> 34.21%     
client [46] (testset)   loss: 2.8202 -> 3.3282  accuracy: 53.33% -> 59.05%     
client [69] (testset)   loss: 3.1702 -> 3.4964  accuracy: 48.74% -> 49.82%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 3.4698 -> 3.8674  accuracy: 40.87% -> 46.09%     
client [82] (testset)   loss: 3.6485 -> 4.1013  accuracy: 33.72% -> 36.05%     
client [69] (testset)   loss: 3.0233 -> 3.5759  accuracy: 50.18% -> 45.85%     
client [45] (testset)   loss: 3.0231 -> 3.3004  accuracy: 34.51% -> 40.27%     
client [7]  (testset)   loss: 3.6492 -> 4.5517  accuracy: 33.77% -> 33.77%     
client [50] (testset)   loss: 2.6791 -> 3.2382  accuracy: 47.00% -> 47.00%     
client [24] (testset)   loss: 3.3195 -> 4.1258  accuracy: 39.66% -> 38.79%     
client [35] (testset)   loss: 3.6505 -> 4.3414  accuracy: 37.24% -> 41.33%     
client [15] (testset)   loss: 3.7870 -> 4.2864  accuracy: 37.96% -> 40.15%     
client [58] (testset)   loss: 4.0454 -> 3.6815  accuracy: 36.15% -> 40.00%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 3.3236 -> 3.6683  accuracy: 39.39% -> 40.61%     
client [76] (testset)   loss: 3.6596 -> 4.2855  accuracy: 38.55% -> 39.66%     
client [37] (testset)   loss: 3.9280 -> 4.5755  accuracy: 37.50% -> 38.46%     
client [67] (testset)   loss: 3.4040 -> 3.8743  accuracy: 38.46% -> 35.71%     
client [58] (testset)   loss: 3.5452 -> 4.2445  accuracy: 38.46% -> 38.46%     
client [64] (testset)   loss: 3.4454 -> 3.9969  accuracy: 44.59% -> 45.95%     
client [77] (testset)   loss: 2.9792 -> 3.6416  accuracy: 44.38% -> 46.63%     
client [55] (testset)   loss: 2.8232 -> 2.9816  accuracy: 50.00% -> 44.93%     
client [12] (testset)   loss: 2.8399 -> 3.1970  accuracy: 51.52% -> 48.48%     
client [89] (testset)   loss: 4.1846 -> 6.5535  accuracy: 35.67% -> 27.39%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [51] (testset)   loss: 3.3095 -> 4.4639  accuracy: 41.89% -> 37.84%     
client [84] (testset)   loss: 4.5908 -> 4.9501  accuracy: 38.14% -> 38.98%     
client [8]  (testset)   loss: 3.7525 -> 4.4003  accuracy: 44.22% -> 44.72%     
client [18] (testset)   loss: 3.2166 -> 3.6373  accuracy: 47.66% -> 48.44%     
client [94] (testset)   loss: 3.9630 -> 4.4646  accuracy: 37.69% -> 42.31%     
client [81] (testset)   loss: 3.3039 -> 3.7838  accuracy: 44.37% -> 45.70%     
client [3]  (testset)   loss: 2.8363 -> 3.0067  accuracy: 45.31% -> 49.22%     
client [11] (testset)   loss: 3.2464 -> 3.5361  accuracy: 46.89% -> 46.33%     
client [95] (testset)   loss: 4.3711 -> 4.7591  accuracy: 41.57% -> 40.36%     
client [67] (testset)   loss: 3.5461 -> 3.9694  accuracy: 37.36% -> 40.11%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 3.0168 -> 3.3392  accuracy: 40.82% -> 38.10%     
client [79] (testset)   loss: 3.1693 -> 3.6393  accuracy: 53.63% -> 47.49%     
client [58] (testset)   loss: 4.3503 -> 4.9793  accuracy: 33.85% -> 31.54%     
client [88] (testset)   loss: 3.4015 -> 4.1366  accuracy: 42.46% -> 43.58%     
client [46] (testset)   loss: 3.5229 -> 3.4421  accuracy: 51.43% -> 56.19%     
client [55] (testset)   loss: 2.7395 -> 2.9398  accuracy: 48.55% -> 48.55%     
client [11] (testset)   loss: 2.9790 -> 4.0740  accuracy: 43.50% -> 41.81%     
client [13] (testset)   loss: 3.7368 -> 3.9681  accuracy: 40.94% -> 42.11%     
client [31] (testset)   loss: 3.4278 -> 3.7631  accuracy: 41.58% -> 43.16%     
client [75] (testset)   loss: 3.5248 -> 3.8704  accuracy: 45.75% -> 44.34%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 3.3147 -> 3.6476  accuracy: 44.51% -> 41.46%     
client [7]  (testset)   loss: 4.3688 -> 4.7456  accuracy: 34.65% -> 35.09%     
client [57] (testset)   loss: 3.0995 -> 3.5852  accuracy: 53.37% -> 53.37%     
client [13] (testset)   loss: 4.6030 -> 4.2781  accuracy: 40.35% -> 40.94%     
client [43] (testset)   loss: 3.9339 -> 4.2034  accuracy: 34.07% -> 34.07%     
client [91] (testset)   loss: 3.1958 -> 4.2623  accuracy: 37.50% -> 30.92%     
client [10] (testset)   loss: 3.2860 -> 3.6538  accuracy: 41.35% -> 38.46%     
client [82] (testset)   loss: 4.1101 -> 4.3903  accuracy: 31.40% -> 32.56%     
client [64] (testset)   loss: 3.5019 -> 3.8713  accuracy: 41.89% -> 44.59%     
client [22] (testset)   loss: 4.3614 -> 4.6963  accuracy: 34.21% -> 32.24%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [23] (testset)   loss: 2.9828 -> 3.6866  accuracy: 38.18% -> 37.27%     
client [20] (testset)   loss: 3.1272 -> 3.3833  accuracy: 50.99% -> 48.51%     
client [88] (testset)   loss: 3.4217 -> 3.8320  accuracy: 44.69% -> 41.34%     
client [98] (testset)   loss: 4.0080 -> 4.4152  accuracy: 37.32% -> 36.62%     
client [79] (testset)   loss: 3.3313 -> 3.6379  accuracy: 50.28% -> 51.40%     
client [21] (testset)   loss: 2.9544 -> 3.4188  accuracy: 43.54% -> 40.82%     
client [56] (testset)   loss: 2.9073 -> 3.2768  accuracy: 51.19% -> 52.38%     
client [92] (testset)   loss: 3.4236 -> 3.7621  accuracy: 33.67% -> 39.80%     
client [52] (testset)   loss: 3.7212 -> 4.1095  accuracy: 43.28% -> 45.52%     
client [5]  (testset)   loss: 3.9537 -> 4.4925  accuracy: 39.88% -> 39.88%     
FedDpa's average time taken by each global epoch: 0 min 3.52 sec.              
FedDpa's total running time: 0 h 12 m 32 s.                                    
==================== FedDpa Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "3.2612 -> 0.0000",                                    
                "accuracy": "40.36% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "3.7033 -> 0.0000",                                    
                "accuracy": "40.33% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedDpa Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 40.36% at epoch 100                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
