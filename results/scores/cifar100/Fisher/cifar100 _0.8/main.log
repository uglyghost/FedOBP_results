==================== FedDpa ====================                               
Experiment Arguments:                                                          
{
    'method': 'feddpa',
    'dataset': {
        'name': 'cifar100',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'cifar100-100clients-0%IID-use20superclasses-Dir(0.1)-seed42',
        'super_class': False,
        'alpha': 0.1,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'parallel',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': 32.0,
        'num_gpus': 1.0,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 200,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 0,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'feddpa': {
        'fisher_threshold': 0.8
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [81] (testset)   loss: 2.7870 -> 2.8539  accuracy: 33.11% -> 40.40%     
client [77] (testset)   loss: 1.9197 -> 2.1092  accuracy: 50.00% -> 46.07%     
client [21] (testset)   loss: 4.4521 -> 2.1798  accuracy: 1.36% -> 43.54%      
client [68] (testset)   loss: 2.4204 -> 2.4148  accuracy: 36.55% -> 41.60%     
client [93] (testset)   loss: 4.4475 -> 2.7939  accuracy: 0.80% -> 30.40%      
client [31] (testset)   loss: 2.6260 -> 2.5504  accuracy: 34.21% -> 37.37%     
client [20] (testset)   loss: 4.2391 -> 1.9875  accuracy: 4.46% -> 46.53%      
client [48] (testset)   loss: 2.6086 -> 2.7284  accuracy: 41.21% -> 36.97%     
client [59] (testset)   loss: 4.4574 -> 2.4528  accuracy: 0.86% -> 31.76%      
client [34] (testset)   loss: 3.0640 -> 3.0524  accuracy: 20.99% -> 24.86%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [99] (testset)   loss: 4.4668 -> 4.1412  accuracy: 0.00% -> 23.36%      
client [69] (testset)   loss: 2.1656 -> 2.0960  accuracy: 45.13% -> 48.74%     
client [67] (testset)   loss: 4.4879 -> 2.9873  accuracy: 0.00% -> 37.36%      
client [0]  (testset)   loss: 4.6891 -> 2.5152  accuracy: 0.00% -> 40.20%      
client [41] (testset)   loss: 4.6276 -> 2.9848  accuracy: 0.81% -> 26.61%      
client [76] (testset)   loss: 2.6839 -> 3.2290  accuracy: 38.55% -> 29.05%     
client [2]  (testset)   loss: 4.7351 -> 2.9358  accuracy: 0.00% -> 37.50%      
client [62] (testset)   loss: 4.7691 -> 3.0546  accuracy: 0.49% -> 40.29%      
client [14] (testset)   loss: 2.7348 -> 3.9532  accuracy: 36.36% -> 33.77%     
client [46] (testset)   loss: 2.2019 -> 2.7763  accuracy: 51.43% -> 55.24%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 2.7403 -> 3.8801  accuracy: 36.21% -> 45.69%     
client [68] (testset)   loss: 4.9347 -> 2.8617  accuracy: 0.00% -> 36.55%      
client [57] (testset)   loss: 2.2748 -> 2.5913  accuracy: 44.79% -> 49.08%     
client [17] (testset)   loss: 2.9652 -> 3.7372  accuracy: 31.58% -> 36.09%     
client [54] (testset)   loss: 3.4070 -> 4.2354  accuracy: 40.00% -> 35.83%     
client [23] (testset)   loss: 5.0580 -> 3.1115  accuracy: 0.00% -> 29.09%      
client [35] (testset)   loss: 2.6137 -> 2.7823  accuracy: 31.63% -> 37.76%     
client [59] (testset)   loss: 2.6138 -> 3.3858  accuracy: 35.62% -> 35.19%     
client [31] (testset)   loss: 2.3658 -> 2.8662  accuracy: 44.21% -> 47.37%     
client [9]  (testset)   loss: 4.4238 -> 2.7881  accuracy: 2.01% -> 37.58%      
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [33] (testset)   loss: 2.9876 -> 4.0669  accuracy: 28.44% -> 22.02%     
client [64] (testset)   loss: 2.6125 -> 3.1664  accuracy: 43.92% -> 45.27%     
client [16] (testset)   loss: 2.8082 -> 3.6489  accuracy: 40.50% -> 39.67%     
client [44] (testset)   loss: 5.1837 -> 3.0944  accuracy: 0.00% -> 35.29%      
client [8]  (testset)   loss: 2.8209 -> 3.9378  accuracy: 46.73% -> 44.72%     
client [31] (testset)   loss: 2.5786 -> 3.0249  accuracy: 46.84% -> 44.21%     
client [47] (testset)   loss: 2.9106 -> 3.7428  accuracy: 37.39% -> 42.61%     
client [36] (testset)   loss: 2.8317 -> 3.5634  accuracy: 32.74% -> 33.63%     
client [56] (testset)   loss: 2.2250 -> 2.6827  accuracy: 51.19% -> 51.19%     
client [20] (testset)   loss: 2.2753 -> 2.7950  accuracy: 47.52% -> 54.95%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [60] (testset)   loss: 2.6349 -> 3.5704  accuracy: 39.39% -> 36.36%     
client [4]  (testset)   loss: 2.2603 -> 2.9423  accuracy: 50.68% -> 47.30%     
client [28] (testset)   loss: 2.7212 -> 2.6326  accuracy: 37.10% -> 43.55%     
client [25] (testset)   loss: 3.0833 -> 2.8383  accuracy: 26.04% -> 50.00%     
client [58] (testset)   loss: 2.9325 -> 3.9740  accuracy: 37.69% -> 33.85%     
client [44] (testset)   loss: 2.7812 -> 3.6301  accuracy: 36.60% -> 34.64%     
client [39] (testset)   loss: 2.6078 -> 3.1651  accuracy: 38.92% -> 40.12%     
client [29] (testset)   loss: 2.7637 -> 3.3054  accuracy: 36.67% -> 37.33%     
client [3]  (testset)   loss: 2.3525 -> 2.6391  accuracy: 45.31% -> 49.22%     
client [84] (testset)   loss: 3.0861 -> 3.9563  accuracy: 35.17% -> 37.29%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 2.5956 -> 2.9571  accuracy: 35.37% -> 43.54%     
client [84] (testset)   loss: 3.2457 -> 4.8669  accuracy: 34.75% -> 33.47%     
client [10] (testset)   loss: 3.4414 -> 3.0964  accuracy: 20.19% -> 42.31%     
client [36] (testset)   loss: 2.4881 -> 3.3083  accuracy: 39.82% -> 42.48%     
client [65] (testset)   loss: 2.7836 -> 3.7740  accuracy: 41.82% -> 40.91%     
client [81] (testset)   loss: 2.4396 -> 3.5234  accuracy: 47.68% -> 43.71%     
client [79] (testset)   loss: 2.2373 -> 2.8682  accuracy: 55.31% -> 50.84%     
client [42] (testset)   loss: 2.4937 -> 3.1640  accuracy: 50.68% -> 48.63%     
client [11] (testset)   loss: 2.2130 -> 3.0670  accuracy: 46.89% -> 46.33%     
client [96] (testset)   loss: 2.5369 -> 3.5294  accuracy: 43.35% -> 43.93%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [53] (testset)   loss: 2.8185 -> 3.3209  accuracy: 34.75% -> 43.97%     
client [8]  (testset)   loss: 3.1075 -> 4.8740  accuracy: 46.23% -> 45.73%     
client [52] (testset)   loss: 2.6449 -> 3.7499  accuracy: 41.79% -> 38.81%     
client [42] (testset)   loss: 2.4615 -> 3.2232  accuracy: 45.89% -> 51.37%     
client [69] (testset)   loss: 2.7125 -> 3.0229  accuracy: 51.26% -> 51.62%     
client [59] (testset)   loss: 2.6847 -> 3.5401  accuracy: 39.48% -> 37.77%     
client [26] (testset)   loss: 2.7981 -> 3.1801  accuracy: 41.59% -> 43.36%     
client [7]  (testset)   loss: 3.1295 -> 4.2391  accuracy: 33.33% -> 37.28%     
client [49] (testset)   loss: 2.4934 -> 3.0851  accuracy: 49.38% -> 50.00%     
client [98] (testset)   loss: 3.0790 -> 4.0501  accuracy: 35.92% -> 35.92%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [47] (testset)   loss: 3.3001 -> 3.5591  accuracy: 34.78% -> 43.48%     
client [98] (testset)   loss: 3.2821 -> 4.5824  accuracy: 35.21% -> 34.51%     
client [21] (testset)   loss: 2.7208 -> 3.3418  accuracy: 38.10% -> 39.46%     
client [77] (testset)   loss: 2.8695 -> 3.5960  accuracy: 47.75% -> 46.07%     
client [95] (testset)   loss: 3.4831 -> 4.5000  accuracy: 41.57% -> 37.35%     
client [91] (testset)   loss: 2.7812 -> 3.5780  accuracy: 42.76% -> 30.92%     
client [14] (testset)   loss: 2.7889 -> 3.8349  accuracy: 44.16% -> 40.26%     
client [99] (testset)   loss: 3.7351 -> 5.1014  accuracy: 27.01% -> 28.47%     
client [20] (testset)   loss: 2.7775 -> 3.1671  accuracy: 51.49% -> 56.44%     
client [39] (testset)   loss: 3.2630 -> 3.4713  accuracy: 29.94% -> 40.12%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 2.6351 -> 3.5405  accuracy: 41.04% -> 43.28%     
client [62] (testset)   loss: 3.1159 -> 3.6804  accuracy: 41.26% -> 41.26%     
client [71] (testset)   loss: 3.4490 -> 4.4344  accuracy: 29.77% -> 32.06%     
client [97] (testset)   loss: 3.9883 -> 4.9328  accuracy: 30.48% -> 30.48%     
client [30] (testset)   loss: 3.8300 -> 4.7025  accuracy: 25.97% -> 30.39%     
client [88] (testset)   loss: 2.7821 -> 3.5524  accuracy: 42.46% -> 41.34%     
client [60] (testset)   loss: 3.0036 -> 3.4003  accuracy: 30.30% -> 39.39%     
client [82] (testset)   loss: 3.3356 -> 4.0291  accuracy: 31.40% -> 33.72%     
client [91] (testset)   loss: 2.9023 -> 3.7120  accuracy: 34.21% -> 38.16%     
client [57] (testset)   loss: 2.5358 -> 2.8599  accuracy: 49.69% -> 50.31%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [15] (testset)   loss: 3.1549 -> 4.0075  accuracy: 37.96% -> 40.15%     
client [31] (testset)   loss: 3.0942 -> 3.9352  accuracy: 45.79% -> 41.05%     
client [71] (testset)   loss: 3.9755 -> 5.2361  accuracy: 23.66% -> 30.53%     
client [97] (testset)   loss: 3.3997 -> 4.0441  accuracy: 29.52% -> 35.24%     
client [53] (testset)   loss: 2.8078 -> 4.1651  accuracy: 46.10% -> 40.43%     
client [77] (testset)   loss: 2.8977 -> 3.5692  accuracy: 44.94% -> 48.88%     
client [76] (testset)   loss: 3.6810 -> 4.1136  accuracy: 35.75% -> 35.75%     
client [79] (testset)   loss: 2.7125 -> 3.0451  accuracy: 53.07% -> 54.75%     
client [28] (testset)   loss: 2.5467 -> 2.9283  accuracy: 41.94% -> 49.19%     
client [99] (testset)   loss: 4.2497 -> 5.7652  accuracy: 29.20% -> 24.82%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 3.1878 -> 3.8689  accuracy: 32.38% -> 31.43%     
client [86] (testset)   loss: 3.0570 -> 3.4559  accuracy: 44.07% -> 44.92%     
client [73] (testset)   loss: 3.3474 -> 3.8185  accuracy: 35.97% -> 38.85%     
client [34] (testset)   loss: 3.2068 -> 3.9983  accuracy: 35.36% -> 38.67%     
client [5]  (testset)   loss: 3.1849 -> 3.9597  accuracy: 42.33% -> 42.94%     
client [96] (testset)   loss: 3.2467 -> 3.4094  accuracy: 46.24% -> 49.71%     
client [60] (testset)   loss: 2.6981 -> 3.1993  accuracy: 36.36% -> 45.45%     
client [22] (testset)   loss: 3.4518 -> 4.6948  accuracy: 35.53% -> 26.97%     
client [83] (testset)   loss: 3.3362 -> 3.8819  accuracy: 44.08% -> 40.13%     
client [66] (testset)   loss: 3.0347 -> 4.2617  accuracy: 41.26% -> 40.78%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [65] (testset)   loss: 3.2528 -> 3.7551  accuracy: 39.09% -> 41.82%     
client [76] (testset)   loss: 2.9541 -> 4.0479  accuracy: 43.02% -> 36.31%     
client [95] (testset)   loss: 3.4356 -> 4.0162  accuracy: 39.16% -> 43.37%     
client [17] (testset)   loss: 3.5086 -> 4.3834  accuracy: 34.59% -> 36.09%     
client [8]  (testset)   loss: 3.9997 -> 4.6729  accuracy: 43.22% -> 48.74%     
client [35] (testset)   loss: 3.5724 -> 3.7134  accuracy: 39.80% -> 38.78%     
client [98] (testset)   loss: 3.6835 -> 3.9889  accuracy: 33.10% -> 37.32%     
client [53] (testset)   loss: 3.2333 -> 3.7525  accuracy: 32.62% -> 42.55%     
client [43] (testset)   loss: 3.5879 -> 4.2714  accuracy: 29.63% -> 36.30%     
client [64] (testset)   loss: 3.0438 -> 3.9249  accuracy: 43.92% -> 43.24%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 2.7396 -> 3.5142  accuracy: 41.50% -> 39.46%     
client [88] (testset)   loss: 3.3000 -> 3.9200  accuracy: 44.13% -> 45.25%     
client [3]  (testset)   loss: 2.6058 -> 2.9041  accuracy: 46.09% -> 47.66%     
client [38] (testset)   loss: 2.8815 -> 3.3424  accuracy: 46.37% -> 45.25%     
client [41] (testset)   loss: 3.4525 -> 3.7758  accuracy: 33.06% -> 29.84%     
client [5]  (testset)   loss: 3.3751 -> 4.0443  accuracy: 42.33% -> 36.81%     
client [37] (testset)   loss: 3.4513 -> 4.4391  accuracy: 36.54% -> 39.42%     
client [7]  (testset)   loss: 3.9048 -> 4.8484  accuracy: 33.77% -> 32.02%     
client [47] (testset)   loss: 3.1205 -> 3.6909  accuracy: 34.78% -> 46.09%     
client [45] (testset)   loss: 3.0055 -> 3.6353  accuracy: 41.15% -> 46.46%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 3.6604 -> 3.6947  accuracy: 38.02% -> 38.84%     
client [11] (testset)   loss: 2.9469 -> 3.6676  accuracy: 44.07% -> 47.46%     
client [37] (testset)   loss: 3.0671 -> 3.6802  accuracy: 35.58% -> 34.62%     
client [41] (testset)   loss: 3.6269 -> 4.1147  accuracy: 28.23% -> 29.84%     
client [95] (testset)   loss: 3.8368 -> 4.1959  accuracy: 43.98% -> 42.77%     
client [53] (testset)   loss: 3.0691 -> 3.7368  accuracy: 42.55% -> 46.10%     
client [22] (testset)   loss: 3.2707 -> 3.9602  accuracy: 31.58% -> 34.21%     
client [25] (testset)   loss: 2.7810 -> 3.2083  accuracy: 44.79% -> 52.08%     
client [46] (testset)   loss: 2.7195 -> 3.1987  accuracy: 55.24% -> 56.19%     
client [69] (testset)   loss: 2.8255 -> 3.1514  accuracy: 50.90% -> 52.35%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 3.1975 -> 4.2055  accuracy: 41.74% -> 40.00%     
client [82] (testset)   loss: 3.4154 -> 3.7873  accuracy: 26.74% -> 40.70%     
client [69] (testset)   loss: 3.0078 -> 3.4186  accuracy: 50.18% -> 50.54%     
client [45] (testset)   loss: 4.9805 -> 2.8056  accuracy: 7.96% -> 46.02%      
client [7]  (testset)   loss: 3.7796 -> 4.8383  accuracy: 32.46% -> 29.82%     
client [50] (testset)   loss: 2.9259 -> 3.3031  accuracy: 45.00% -> 49.00%     
client [24] (testset)   loss: 3.6596 -> 3.9318  accuracy: 36.21% -> 41.38%     
client [35] (testset)   loss: 3.5724 -> 3.9109  accuracy: 37.76% -> 42.35%     
client [15] (testset)   loss: 3.8266 -> 4.2338  accuracy: 41.61% -> 42.34%     
client [58] (testset)   loss: 3.8483 -> 4.4171  accuracy: 40.00% -> 39.23%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 3.1880 -> 3.4303  accuracy: 42.42% -> 44.24%     
client [76] (testset)   loss: 3.4806 -> 3.8761  accuracy: 42.46% -> 39.66%     
client [37] (testset)   loss: 3.7273 -> 4.1584  accuracy: 42.31% -> 41.35%     
client [67] (testset)   loss: 3.5672 -> 3.6832  accuracy: 44.51% -> 43.41%     
client [58] (testset)   loss: 4.1676 -> 4.4584  accuracy: 41.54% -> 41.54%     
client [64] (testset)   loss: 3.6375 -> 4.1128  accuracy: 42.57% -> 45.27%     
client [77] (testset)   loss: 3.2023 -> 3.4264  accuracy: 45.51% -> 46.63%     
client [55] (testset)   loss: 2.5974 -> 2.8556  accuracy: 46.38% -> 50.00%     
client [12] (testset)   loss: 2.6788 -> 3.1752  accuracy: 56.06% -> 55.30%     
client [89] (testset)   loss: 3.9421 -> 4.3691  accuracy: 36.31% -> 38.22%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [51] (testset)   loss: 3.6164 -> 4.2470  accuracy: 40.54% -> 39.19%     
client [84] (testset)   loss: 3.9232 -> 4.4881  accuracy: 37.71% -> 37.29%     
client [8]  (testset)   loss: 4.1067 -> 4.5094  accuracy: 47.74% -> 46.23%     
client [18] (testset)   loss: 2.8615 -> 3.2324  accuracy: 52.34% -> 53.12%     
client [94] (testset)   loss: 4.4510 -> 5.0772  accuracy: 31.54% -> 36.15%     
client [81] (testset)   loss: 3.2872 -> 3.9374  accuracy: 37.75% -> 42.38%     
client [3]  (testset)   loss: 2.6582 -> 3.0029  accuracy: 50.00% -> 50.78%     
client [11] (testset)   loss: 2.8992 -> 3.3010  accuracy: 48.59% -> 50.28%     
client [95] (testset)   loss: 3.9541 -> 4.2981  accuracy: 43.37% -> 45.78%     
client [67] (testset)   loss: 3.3232 -> 3.6181  accuracy: 43.41% -> 43.96%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 3.1441 -> 3.5728  accuracy: 38.78% -> 40.82%     
client [79] (testset)   loss: 3.1225 -> 3.3820  accuracy: 55.31% -> 54.19%     
client [58] (testset)   loss: 6.2994 -> 4.7379  accuracy: 28.46% -> 35.38%     
client [88] (testset)   loss: 3.4518 -> 4.0763  accuracy: 39.66% -> 44.13%     
client [46] (testset)   loss: 3.0975 -> 4.0378  accuracy: 50.48% -> 54.29%     
client [11] (testset)   loss: 3.3077 -> 3.3998  accuracy: 41.24% -> 46.33%     
client [55] (testset)   loss: 2.6016 -> 2.7465  accuracy: 50.00% -> 50.72%     
client [13] (testset)   loss: 3.4745 -> 4.0807  accuracy: 39.77% -> 43.86%     
client [31] (testset)   loss: 3.6515 -> 3.7669  accuracy: 42.11% -> 47.37%     
client [75] (testset)   loss: 3.3199 -> 3.7647  accuracy: 41.98% -> 43.87%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 3.3340 -> 3.5878  accuracy: 40.24% -> 40.85%     
client [7]  (testset)   loss: 4.2160 -> 4.6061  accuracy: 38.16% -> 35.96%     
client [57] (testset)   loss: 3.1229 -> 3.2759  accuracy: 52.76% -> 54.60%     
client [13] (testset)   loss: 3.3576 -> 3.7845  accuracy: 36.84% -> 39.77%     
client [43] (testset)   loss: 4.2265 -> 4.3701  accuracy: 29.63% -> 32.59%     
client [91] (testset)   loss: 3.3799 -> 4.5497  accuracy: 36.84% -> 34.87%     
client [10] (testset)   loss: 3.2171 -> 3.4944  accuracy: 44.23% -> 43.27%     
client [82] (testset)   loss: 3.5793 -> 3.8067  accuracy: 39.53% -> 40.70%     
client [64] (testset)   loss: 3.1400 -> 3.8429  accuracy: 45.27% -> 44.59%     
client [22] (testset)   loss: 3.3747 -> 4.0310  accuracy: 34.21% -> 34.87%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [23] (testset)   loss: 3.0234 -> 3.6427  accuracy: 37.27% -> 35.45%     
client [20] (testset)   loss: 2.7243 -> 3.1888  accuracy: 51.49% -> 53.96%     
client [88] (testset)   loss: 3.3244 -> 4.2093  accuracy: 43.02% -> 43.58%     
client [98] (testset)   loss: 3.8309 -> 4.1973  accuracy: 35.21% -> 39.44%     
client [79] (testset)   loss: 2.6480 -> 3.1718  accuracy: 58.10% -> 55.87%     
client [21] (testset)   loss: 2.9660 -> 3.0314  accuracy: 39.46% -> 41.50%     
client [56] (testset)   loss: 2.2625 -> 2.6880  accuracy: 50.00% -> 51.19%     
client [92] (testset)   loss: 3.1095 -> 3.6470  accuracy: 39.80% -> 35.71%     
client [52] (testset)   loss: 3.4286 -> 3.7919  accuracy: 40.30% -> 44.03%     
client [5]  (testset)   loss: 3.8342 -> 4.7199  accuracy: 40.49% -> 35.58%     
FedDpa's average time taken by each global epoch: 0 min 3.48 sec.              
FedDpa's total running time: 0 h 12 m 22 s.                                    
==================== FedDpa Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "3.1437 -> 0.0000",                                    
                "accuracy": "40.01% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "3.4615 -> 0.0000",                                    
                "accuracy": "40.75% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedDpa Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 40.75% at epoch 200                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
