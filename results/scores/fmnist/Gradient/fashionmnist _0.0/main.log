==================== FedDpag ====================                              
Experiment Arguments:                                                          
{
    'method': 'feddpag',
    'dataset': {
        'name': 'fmnist',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'fmnist-100clients-0%IID-Dir(0.1)-seed42',
        'alpha': 0.1,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'serial',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': None,
        'num_gpus': None,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 200,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 0,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'feddpag': {
        'fisher_threshold': 0.0
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 0.1126 -> 0.0861  accuracy: 96.37% -> 95.85%     
client [81] (testset)   loss: 0.3265 -> 0.1216  accuracy: 88.89% -> 96.30%     
client [21] (testset)   loss: 2.3259 -> 0.4278  accuracy: 0.00% -> 86.96%      
client [68] (testset)   loss: 0.3277 -> 0.2453  accuracy: 88.18% -> 91.82%     
client [93] (testset)   loss: 0.0354 -> 0.0247  accuracy: 100.00% -> 100.00%   
client [31] (testset)   loss: 0.5148 -> 0.3845  accuracy: 86.15% -> 86.15%     
client [20] (testset)   loss: 0.0799 -> 0.0866  accuracy: 97.58% -> 97.31%     
client [59] (testset)   loss: 2.2856 -> 0.4818  accuracy: 0.00% -> 85.40%      
client [48] (testset)   loss: 0.1317 -> 0.1282  accuracy: 98.73% -> 98.73%     
client [34] (testset)   loss: 0.5148 -> 0.4430  accuracy: 92.31% -> 92.31%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 0.2449 -> 0.2070  accuracy: 93.21% -> 95.06%     
client [99] (testset)   loss: 0.0996 -> 0.0916  accuracy: 98.42% -> 98.42%     
client [67] (testset)   loss: 0.2849 -> 0.2180  accuracy: 92.10% -> 92.78%     
client [0]  (testset)   loss: 0.5260 -> 0.3558  accuracy: 75.51% -> 83.67%     
client [76] (testset)   loss: 1.2553 -> 1.0281  accuracy: 60.00% -> 60.00%     
client [41] (testset)   loss: 0.3571 -> 0.2936  accuracy: 88.31% -> 89.52%     
client [62] (testset)   loss: 2.3122 -> 0.5054  accuracy: 0.00% -> 90.00%      
client [2]  (testset)   loss: 2.3374 -> 0.0353  accuracy: 0.00% -> 98.69%      
client [14] (testset)   loss: 0.3400 -> 0.3076  accuracy: 87.86% -> 90.00%     
client [46] (testset)   loss: 0.3654 -> 0.3785  accuracy: 90.62% -> 90.62%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 0.5223 -> 0.4947  accuracy: 84.00% -> 85.14%     
client [68] (testset)   loss: 0.2084 -> 0.2013  accuracy: 91.82% -> 91.82%     
client [57] (testset)   loss: 0.0540 -> 0.0501  accuracy: 98.91% -> 99.64%     
client [17] (testset)   loss: 0.2050 -> 0.1960  accuracy: 93.05% -> 93.58%     
client [54] (testset)   loss: 0.2909 -> 0.3106  accuracy: 83.12% -> 84.42%     
client [23] (testset)   loss: 2.2664 -> 0.1935  accuracy: 31.31% -> 91.92%     
client [35] (testset)   loss: 0.0426 -> 0.0381  accuracy: 100.00% -> 100.00%   
client [59] (testset)   loss: 0.4978 -> 0.5343  accuracy: 87.59% -> 87.59%     
client [31] (testset)   loss: 0.2910 -> 0.2812  accuracy: 89.23% -> 89.23%     
client [9]  (testset)   loss: 0.1370 -> 0.1484  accuracy: 96.53% -> 95.83%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 0.2616 -> 0.1454  accuracy: 90.98% -> 95.49%     
client [33] (testset)   loss: 0.1775 -> 0.2283  accuracy: 94.74% -> 94.74%     
client [16] (testset)   loss: 0.0763 -> 0.0554  accuracy: 98.33% -> 98.33%     
client [44] (testset)   loss: 0.1892 -> 0.1522  accuracy: 94.34% -> 96.23%     
client [8]  (testset)   loss: 0.4251 -> 0.4243  accuracy: 90.48% -> 90.48%     
client [31] (testset)   loss: 0.2868 -> 0.3017  accuracy: 92.31% -> 89.23%     
client [47] (testset)   loss: 0.1204 -> 0.1112  accuracy: 95.43% -> 96.30%     
client [36] (testset)   loss: 0.2501 -> 0.2426  accuracy: 92.94% -> 93.27%     
client [20] (testset)   loss: 0.0837 -> 0.0656  accuracy: 97.58% -> 98.12%     
client [56] (testset)   loss: 0.5430 -> 0.5236  accuracy: 79.83% -> 82.35%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 0.1264 -> 0.1029  accuracy: 96.92% -> 97.69%     
client [60] (testset)   loss: 0.2248 -> 0.1881  accuracy: 94.46% -> 95.20%     
client [28] (testset)   loss: 0.1109 -> 0.0967  accuracy: 94.64% -> 94.64%     
client [25] (testset)   loss: 0.1661 -> 0.1779  accuracy: 95.19% -> 97.12%     
client [58] (testset)   loss: 0.1827 -> 0.1923  accuracy: 95.41% -> 93.88%     
client [44] (testset)   loss: 0.1522 -> 0.1233  accuracy: 96.23% -> 96.23%     
client [39] (testset)   loss: 0.1616 -> 0.1212  accuracy: 100.00% -> 100.00%   
client [29] (testset)   loss: 0.2618 -> 0.2657  accuracy: 92.41% -> 92.41%     
client [3]  (testset)   loss: 0.1496 -> 0.1988  accuracy: 93.77% -> 93.77%     
client [84] (testset)   loss: 0.0072 -> 0.0063  accuracy: 100.00% -> 100.00%   
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 0.4399 -> 0.3042  accuracy: 83.85% -> 89.44%     
client [84] (testset)   loss: 0.0048 -> 0.0044  accuracy: 100.00% -> 100.00%   
client [10] (testset)   loss: 0.0574 -> 0.0465  accuracy: 97.06% -> 100.00%    
client [36] (testset)   loss: 0.2477 -> 0.2567  accuracy: 93.27% -> 90.97%     
client [65] (testset)   loss: 0.7799 -> 0.7658  accuracy: 84.38% -> 84.38%     
client [81] (testset)   loss: 0.0799 -> 0.0662  accuracy: 98.15% -> 98.15%     
client [79] (testset)   loss: 0.3168 -> 0.2999  accuracy: 88.67% -> 89.66%     
client [42] (testset)   loss: 0.0761 -> 0.0757  accuracy: 98.30% -> 98.67%     
client [11] (testset)   loss: 0.3289 -> 0.3565  accuracy: 87.00% -> 88.34%     
client [96] (testset)   loss: 0.3415 -> 0.3240  accuracy: 90.51% -> 91.97%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 0.4428 -> 0.4985  accuracy: 91.07% -> 90.48%     
client [53] (testset)   loss: 0.0435 -> 0.0414  accuracy: 98.80% -> 98.80%     
client [52] (testset)   loss: 0.2599 -> 0.2307  accuracy: 89.83% -> 89.83%     
client [42] (testset)   loss: 0.0838 -> 0.0748  accuracy: 98.79% -> 98.55%     
client [69] (testset)   loss: 0.2691 -> 0.2542  accuracy: 95.68% -> 96.30%     
client [59] (testset)   loss: 0.5705 -> 0.6036  accuracy: 88.32% -> 88.32%     
client [7]  (testset)   loss: 0.0813 -> 0.0741  accuracy: 96.94% -> 97.82%     
client [26] (testset)   loss: 0.0778 -> 0.0750  accuracy: 98.09% -> 98.09%     
client [49] (testset)   loss: 0.0402 -> 0.0426  accuracy: 99.57% -> 99.57%     
client [98] (testset)   loss: 0.4162 -> 0.5786  accuracy: 91.49% -> 78.72%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 0.5768 -> 0.5879  accuracy: 78.72% -> 85.11%     
client [47] (testset)   loss: 0.1187 -> 0.1128  accuracy: 96.09% -> 96.09%     
client [21] (testset)   loss: 0.2847 -> 0.2850  accuracy: 89.44% -> 89.44%     
client [77] (testset)   loss: 0.0505 -> 0.0502  accuracy: 97.93% -> 98.45%     
client [95] (testset)   loss: 0.2271 -> 0.2273  accuracy: 90.74% -> 88.89%     
client [91] (testset)   loss: 0.9844 -> 1.0022  accuracy: 92.31% -> 92.31%     
client [14] (testset)   loss: 0.3773 -> 0.3893  accuracy: 90.24% -> 89.29%     
client [99] (testset)   loss: 0.0929 -> 0.1034  accuracy: 98.16% -> 98.16%     
client [20] (testset)   loss: 0.0764 -> 0.0737  accuracy: 98.12% -> 98.39%     
client [39] (testset)   loss: 0.1193 -> 0.1042  accuracy: 100.00% -> 100.00%   
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 0.2307 -> 0.2342  accuracy: 89.83% -> 89.83%     
client [62] (testset)   loss: 0.5454 -> 0.5734  accuracy: 90.00% -> 90.00%     
client [71] (testset)   loss: 0.1214 -> 0.0834  accuracy: 92.93% -> 96.74%     
client [97] (testset)   loss: 0.0789 -> 0.0692  accuracy: 98.27% -> 98.27%     
client [30] (testset)   loss: 0.3068 -> 0.3261  accuracy: 97.12% -> 97.12%     
client [88] (testset)   loss: 0.4614 -> 0.4171  accuracy: 82.93% -> 89.02%     
client [60] (testset)   loss: 0.2214 -> 0.3230  accuracy: 94.83% -> 92.25%     
client [82] (testset)   loss: 0.1497 -> 0.1503  accuracy: 98.63% -> 98.63%     
client [91] (testset)   loss: 1.0134 -> 1.0296  accuracy: 92.31% -> 92.31%     
client [57] (testset)   loss: 0.0488 -> 0.0407  accuracy: 99.27% -> 98.91%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 0.3998 -> 0.4341  accuracy: 84.62% -> 89.23%     
client [15] (testset)   loss: 0.2510 -> 0.2515  accuracy: 91.88% -> 91.88%     
client [71] (testset)   loss: 0.0834 -> 0.1368  accuracy: 96.74% -> 93.48%     
client [97] (testset)   loss: 0.0768 -> 0.0770  accuracy: 98.70% -> 98.70%     
client [53] (testset)   loss: 0.0452 -> 0.0424  accuracy: 98.49% -> 98.80%     
client [77] (testset)   loss: 0.0502 -> 0.0495  accuracy: 98.45% -> 98.96%     
client [76] (testset)   loss: 0.3605 -> 0.4362  accuracy: 86.67% -> 86.67%     
client [79] (testset)   loss: 0.4191 -> 0.3785  accuracy: 88.18% -> 89.16%     
client [28] (testset)   loss: 0.0708 -> 0.0695  accuracy: 94.64% -> 94.64%     
client [99] (testset)   loss: 0.1008 -> 0.1179  accuracy: 98.16% -> 97.89%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 0.0720 -> 0.0775  accuracy: 98.70% -> 98.27%     
client [86] (testset)   loss: 0.3755 -> 0.3610  accuracy: 88.24% -> 88.24%     
client [34] (testset)   loss: 0.3940 -> 0.3781  accuracy: 96.15% -> 96.15%     
client [73] (testset)   loss: 0.0696 -> 0.0643  accuracy: 98.47% -> 98.47%     
client [5]  (testset)   loss: 0.1688 -> 0.1595  accuracy: 95.24% -> 94.29%     
client [96] (testset)   loss: 0.4085 -> 0.4305  accuracy: 89.78% -> 89.78%     
client [22] (testset)   loss: 0.0499 -> 0.0492  accuracy: 97.94% -> 98.97%     
client [60] (testset)   loss: 0.2134 -> 0.2109  accuracy: 91.51% -> 92.25%     
client [66] (testset)   loss: 0.1989 -> 0.1880  accuracy: 93.63% -> 94.02%     
client [83] (testset)   loss: 0.0412 -> 0.0410  accuracy: 98.09% -> 98.09%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 0.3665 -> 0.3865  accuracy: 86.67% -> 86.67%     
client [65] (testset)   loss: 0.7954 -> 0.7861  accuracy: 84.38% -> 87.50%     
client [95] (testset)   loss: 0.4069 -> 0.2495  accuracy: 87.04% -> 88.89%     
client [17] (testset)   loss: 0.1877 -> 0.2085  accuracy: 93.05% -> 93.05%     
client [8]  (testset)   loss: 0.5687 -> 0.5804  accuracy: 91.37% -> 90.18%     
client [35] (testset)   loss: 0.0132 -> 0.0136  accuracy: 100.00% -> 100.00%   
client [98] (testset)   loss: 0.5331 -> 0.5353  accuracy: 89.36% -> 89.36%     
client [53] (testset)   loss: 0.0409 -> 0.0414  accuracy: 99.10% -> 98.80%     
client [43] (testset)   loss: 0.3570 -> 0.1685  accuracy: 83.08% -> 95.38%     
client [64] (testset)   loss: 0.1870 -> 0.1860  accuracy: 93.23% -> 93.23%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 0.2872 -> 0.3033  accuracy: 89.44% -> 89.44%     
client [88] (testset)   loss: 0.4081 -> 0.4029  accuracy: 86.59% -> 89.02%     
client [38] (testset)   loss: 0.7799 -> 0.6666  accuracy: 80.52% -> 84.42%     
client [3]  (testset)   loss: 0.2233 -> 0.2112  accuracy: 94.16% -> 94.16%     
client [5]  (testset)   loss: 0.1742 -> 0.1828  accuracy: 95.24% -> 94.76%     
client [41] (testset)   loss: 0.2689 -> 0.2603  accuracy: 92.34% -> 92.74%     
client [7]  (testset)   loss: 0.0718 -> 0.0731  accuracy: 97.38% -> 97.38%     
client [37] (testset)   loss: 0.1704 -> 0.1722  accuracy: 93.48% -> 93.48%     
client [45] (testset)   loss: 0.4142 -> 0.3854  accuracy: 86.49% -> 86.49%     
client [47] (testset)   loss: 0.1598 -> 0.1165  accuracy: 95.87% -> 96.74%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 0.0548 -> 0.0620  accuracy: 97.50% -> 98.33%     
client [11] (testset)   loss: 0.4660 -> 0.4312  accuracy: 88.34% -> 88.79%     
client [37] (testset)   loss: 0.1913 -> 0.1963  accuracy: 92.39% -> 92.39%     
client [41] (testset)   loss: 0.2605 -> 0.2908  accuracy: 92.74% -> 92.34%     
client [95] (testset)   loss: 0.2452 -> 0.2771  accuracy: 88.89% -> 88.89%     
client [53] (testset)   loss: 0.0415 -> 0.0452  accuracy: 98.80% -> 98.80%     
client [22] (testset)   loss: 0.0478 -> 0.0432  accuracy: 98.97% -> 97.94%     
client [25] (testset)   loss: 0.1908 -> 0.2077  accuracy: 95.19% -> 95.19%     
client [69] (testset)   loss: 0.3111 -> 0.3299  accuracy: 96.30% -> 95.68%     
client [46] (testset)   loss: 0.4269 -> 0.4093  accuracy: 86.46% -> 80.21%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 0.1557 -> 0.1425  accuracy: 96.52% -> 96.52%     
client [69] (testset)   loss: 0.3201 -> 0.3361  accuracy: 96.30% -> 96.30%     
client [82] (testset)   loss: 0.1699 -> 0.1772  accuracy: 98.63% -> 98.63%     
client [45] (testset)   loss: 0.3792 -> 0.3937  accuracy: 86.49% -> 86.49%     
client [7]  (testset)   loss: 0.0732 -> 0.0845  accuracy: 97.38% -> 96.07%     
client [50] (testset)   loss: 0.0481 -> 0.0516  accuracy: 98.58% -> 98.58%     
client [35] (testset)   loss: 0.0125 -> 0.0117  accuracy: 100.00% -> 100.00%   
client [24] (testset)   loss: 0.6877 -> 0.7098  accuracy: 86.29% -> 85.71%     
client [15] (testset)   loss: 0.2975 -> 0.3179  accuracy: 92.50% -> 92.19%     
client [58] (testset)   loss: 0.2350 -> 0.2402  accuracy: 93.37% -> 93.37%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 0.0990 -> 0.1023  accuracy: 98.73% -> 98.73%     
client [76] (testset)   loss: 0.3940 -> 0.4558  accuracy: 86.67% -> 86.67%     
client [67] (testset)   loss: 0.2762 -> 0.2802  accuracy: 95.88% -> 95.88%     
client [37] (testset)   loss: 0.1925 -> 0.1934  accuracy: 94.57% -> 93.48%     
client [58] (testset)   loss: 0.2417 -> 0.2447  accuracy: 93.37% -> 93.37%     
client [64] (testset)   loss: 0.1980 -> 0.1955  accuracy: 93.23% -> 93.23%     
client [77] (testset)   loss: 0.0523 -> 0.0524  accuracy: 97.93% -> 97.93%     
client [55] (testset)   loss: 0.0012 -> 0.0012  accuracy: 100.00% -> 100.00%   
client [12] (testset)   loss: 0.2210 -> 0.2276  accuracy: 95.14% -> 94.91%     
client [89] (testset)   loss: 0.6004 -> 0.5965  accuracy: 78.95% -> 78.95%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 0.0010 -> 0.0010  accuracy: 100.00% -> 100.00%   
client [51] (testset)   loss: 0.0995 -> 0.1003  accuracy: 97.55% -> 97.55%     
client [8]  (testset)   loss: 0.6664 -> 0.6799  accuracy: 91.67% -> 91.67%     
client [18] (testset)   loss: 0.0368 -> 0.0356  accuracy: 99.00% -> 99.00%     
client [94] (testset)   loss: 0.2666 -> 0.2595  accuracy: 93.89% -> 93.89%     
client [81] (testset)   loss: 0.0701 -> 0.0803  accuracy: 98.15% -> 98.15%     
client [3]  (testset)   loss: 0.2273 -> 0.2273  accuracy: 94.55% -> 94.55%     
client [11] (testset)   loss: 0.4761 -> 0.4757  accuracy: 88.79% -> 89.24%     
client [95] (testset)   loss: 0.3105 -> 0.3132  accuracy: 88.89% -> 88.89%     
client [67] (testset)   loss: 0.2799 -> 0.2946  accuracy: 95.88% -> 95.88%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 0.3639 -> 0.4379  accuracy: 89.44% -> 89.44%     
client [79] (testset)   loss: 0.5284 -> 0.5357  accuracy: 91.63% -> 91.13%     
client [58] (testset)   loss: 0.2513 -> 0.2534  accuracy: 93.37% -> 93.37%     
client [88] (testset)   loss: 0.4415 -> 0.4405  accuracy: 86.59% -> 91.46%     
client [46] (testset)   loss: 0.3654 -> 0.4166  accuracy: 92.71% -> 93.75%     
client [11] (testset)   loss: 0.4756 -> 0.4725  accuracy: 89.24% -> 88.79%     
client [55] (testset)   loss: 0.0010 -> 0.0009  accuracy: 100.00% -> 100.00%   
client [13] (testset)   loss: 0.8842 -> 0.9052  accuracy: 86.86% -> 86.86%     
client [31] (testset)   loss: 0.4473 -> 0.4517  accuracy: 86.15% -> 86.15%     
client [75] (testset)   loss: 0.5115 -> 0.5615  accuracy: 89.47% -> 89.95%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 0.5072 -> 0.5313  accuracy: 84.75% -> 84.75%     
client [7]  (testset)   loss: 0.0679 -> 0.0608  accuracy: 98.25% -> 98.25%     
client [57] (testset)   loss: 0.0481 -> 0.0488  accuracy: 98.91% -> 98.54%     
client [13] (testset)   loss: 0.9102 -> 0.9245  accuracy: 86.86% -> 86.86%     
client [43] (testset)   loss: 0.1697 -> 0.1655  accuracy: 96.92% -> 95.38%     
client [91] (testset)   loss: 1.0676 -> 1.0810  accuracy: 92.31% -> 92.31%     
client [10] (testset)   loss: 0.0201 -> 0.0196  accuracy: 100.00% -> 100.00%   
client [64] (testset)   loss: 0.2037 -> 0.2003  accuracy: 93.23% -> 93.23%     
client [82] (testset)   loss: 0.1926 -> 0.1949  accuracy: 98.63% -> 98.63%     
client [22] (testset)   loss: 0.0377 -> 0.0390  accuracy: 97.94% -> 98.97%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 0.0914 -> 0.0974  accuracy: 98.12% -> 98.12%     
client [23] (testset)   loss: 0.1696 -> 0.2202  accuracy: 94.95% -> 94.95%     
client [88] (testset)   loss: 0.4471 -> 0.4536  accuracy: 91.46% -> 89.02%     
client [98] (testset)   loss: 0.6213 -> 0.6555  accuracy: 89.36% -> 87.23%     
client [79] (testset)   loss: 0.5513 -> 0.5575  accuracy: 91.63% -> 91.63%     
client [21] (testset)   loss: 0.3822 -> 0.3842  accuracy: 89.44% -> 88.82%     
client [92] (testset)   loss: 0.2866 -> 0.2931  accuracy: 95.62% -> 95.62%     
client [56] (testset)   loss: 0.7644 -> 0.7733  accuracy: 86.55% -> 85.71%     
client [5]  (testset)   loss: 0.1859 -> 0.1919  accuracy: 95.24% -> 95.24%     
client [52] (testset)   loss: 0.3333 -> 0.3252  accuracy: 91.53% -> 91.53%     
FedDpag's average time taken by each global epoch: 0 min 2.92 sec.             
FedDpag's total running time: 0 h 9 m 50 s.                                    
==================== FedDpag Experiment Results: ====================          
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.2026 -> 0.0000",                                    
                "accuracy": "94.70% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.2547 -> 0.0000",                                    
                "accuracy": "94.99% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedDpag Max Accuracy ====================                 
all_clients:                                                                   
(test) before fine-tuning: 94.99% at epoch 200                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
