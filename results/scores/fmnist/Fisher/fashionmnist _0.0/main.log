==================== FedDpa ====================                               
Experiment Arguments:                                                          
{
    'method': 'feddpa',
    'dataset': {
        'name': 'fmnist',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'fmnist-100clients-0%IID-Dir(0.1)-seed42',
        'alpha': 0.1,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'serial',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': None,
        'num_gpus': None,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 200,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 0,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'feddpa': {
        'fisher_threshold': 0.0
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 0.1711 -> 0.0865  accuracy: 93.26% -> 95.85%     
client [81] (testset)   loss: 0.4317 -> 0.1143  accuracy: 87.04% -> 96.30%     
client [21] (testset)   loss: 2.2809 -> 0.4036  accuracy: 23.60% -> 86.34%     
client [68] (testset)   loss: 0.2970 -> 0.2195  accuracy: 88.18% -> 93.64%     
client [93] (testset)   loss: 0.0523 -> 0.0247  accuracy: 100.00% -> 100.00%   
client [31] (testset)   loss: 0.4823 -> 0.4327  accuracy: 86.15% -> 80.00%     
client [20] (testset)   loss: 0.0852 -> 0.0853  accuracy: 97.31% -> 96.77%     
client [59] (testset)   loss: 2.2421 -> 0.4748  accuracy: 24.09% -> 85.40%     
client [48] (testset)   loss: 0.1524 -> 0.1093  accuracy: 98.73% -> 98.73%     
client [34] (testset)   loss: 0.3759 -> 0.4027  accuracy: 92.31% -> 88.46%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 0.2290 -> 0.2216  accuracy: 93.21% -> 94.44%     
client [99] (testset)   loss: 0.1136 -> 0.0879  accuracy: 98.16% -> 98.42%     
client [67] (testset)   loss: 0.2630 -> 0.1952  accuracy: 93.47% -> 93.47%     
client [0]  (testset)   loss: 0.4939 -> 0.3165  accuracy: 81.63% -> 85.71%     
client [76] (testset)   loss: 0.9357 -> 0.6885  accuracy: 60.00% -> 80.00%     
client [41] (testset)   loss: 0.3591 -> 0.2824  accuracy: 89.11% -> 89.92%     
client [62] (testset)   loss: 2.2060 -> 0.3241  accuracy: 40.00% -> 90.00%     
client [2]  (testset)   loss: 2.2087 -> 0.0314  accuracy: 6.56% -> 98.91%      
client [14] (testset)   loss: 0.4206 -> 0.3150  accuracy: 85.71% -> 90.24%     
client [46] (testset)   loss: 0.3568 -> 0.3823  accuracy: 90.62% -> 90.62%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 0.5170 -> 0.4704  accuracy: 84.57% -> 85.14%     
client [68] (testset)   loss: 0.2132 -> 0.1996  accuracy: 91.82% -> 92.73%     
client [57] (testset)   loss: 0.0561 -> 0.0492  accuracy: 98.54% -> 99.64%     
client [17] (testset)   loss: 0.2563 -> 0.1936  accuracy: 92.51% -> 92.51%     
client [54] (testset)   loss: 0.2757 -> 0.2835  accuracy: 85.71% -> 84.42%     
client [23] (testset)   loss: 2.1918 -> 0.1552  accuracy: 9.09% -> 93.94%      
client [35] (testset)   loss: 0.0715 -> 0.0384  accuracy: 100.00% -> 100.00%   
client [59] (testset)   loss: 0.4464 -> 0.5465  accuracy: 89.05% -> 86.13%     
client [31] (testset)   loss: 0.2968 -> 0.2676  accuracy: 90.77% -> 89.23%     
client [9]  (testset)   loss: 0.1362 -> 0.1603  accuracy: 96.88% -> 95.14%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 0.2435 -> 0.1406  accuracy: 89.47% -> 95.49%     
client [33] (testset)   loss: 0.1798 -> 0.2331  accuracy: 95.32% -> 94.74%     
client [16] (testset)   loss: 0.1393 -> 0.0451  accuracy: 95.83% -> 99.17%     
client [44] (testset)   loss: 0.1815 -> 0.1370  accuracy: 94.34% -> 96.23%     
client [8]  (testset)   loss: 0.4129 -> 0.3792  accuracy: 88.69% -> 89.58%     
client [31] (testset)   loss: 0.3005 -> 0.2945  accuracy: 87.69% -> 89.23%     
client [47] (testset)   loss: 0.1376 -> 0.1106  accuracy: 95.00% -> 96.30%     
client [36] (testset)   loss: 0.2498 -> 0.2362  accuracy: 93.43% -> 93.10%     
client [20] (testset)   loss: 0.0671 -> 0.0538  accuracy: 97.85% -> 98.92%     
client [56] (testset)   loss: 0.4796 -> 0.4667  accuracy: 80.67% -> 82.35%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 0.1184 -> 0.0928  accuracy: 97.69% -> 97.69%     
client [60] (testset)   loss: 0.2471 -> 0.1831  accuracy: 94.46% -> 94.83%     
client [28] (testset)   loss: 0.0577 -> 0.0452  accuracy: 96.43% -> 96.43%     
client [25] (testset)   loss: 0.1539 -> 0.1657  accuracy: 94.23% -> 97.12%     
client [58] (testset)   loss: 0.1860 -> 0.1786  accuracy: 93.88% -> 94.90%     
client [44] (testset)   loss: 0.1342 -> 0.1122  accuracy: 96.23% -> 96.23%     
client [39] (testset)   loss: 0.3519 -> 0.1238  accuracy: 86.67% -> 100.00%    
client [29] (testset)   loss: 0.2790 -> 0.3144  accuracy: 89.87% -> 89.87%     
client [3]  (testset)   loss: 0.2470 -> 0.1630  accuracy: 90.66% -> 93.39%     
client [84] (testset)   loss: 0.0776 -> 0.0098  accuracy: 97.53% -> 100.00%    
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 0.3920 -> 0.2766  accuracy: 86.34% -> 90.06%     
client [84] (testset)   loss: 0.0229 -> 0.0076  accuracy: 100.00% -> 100.00%   
client [10] (testset)   loss: 0.0511 -> 0.0402  accuracy: 98.53% -> 100.00%    
client [36] (testset)   loss: 0.2281 -> 0.2878  accuracy: 92.78% -> 89.33%     
client [65] (testset)   loss: 0.6714 -> 0.6299  accuracy: 84.38% -> 87.50%     
client [81] (testset)   loss: 0.0812 -> 0.0437  accuracy: 98.15% -> 98.15%     
client [79] (testset)   loss: 0.2840 -> 0.2729  accuracy: 88.18% -> 88.67%     
client [42] (testset)   loss: 0.0939 -> 0.0705  accuracy: 97.94% -> 98.67%     
client [11] (testset)   loss: 0.3115 -> 0.3496  accuracy: 87.44% -> 87.89%     
client [96] (testset)   loss: 0.2989 -> 0.2879  accuracy: 89.78% -> 91.97%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 0.3529 -> 0.3773  accuracy: 90.18% -> 90.18%     
client [53] (testset)   loss: 0.0557 -> 0.0321  accuracy: 98.80% -> 98.80%     
client [52] (testset)   loss: 0.2817 -> 0.2274  accuracy: 89.83% -> 89.83%     
client [42] (testset)   loss: 0.0668 -> 0.0677  accuracy: 98.67% -> 98.42%     
client [69] (testset)   loss: 0.1964 -> 0.1951  accuracy: 95.68% -> 96.30%     
client [59] (testset)   loss: 0.5031 -> 0.6092  accuracy: 88.32% -> 88.32%     
client [7]  (testset)   loss: 0.1013 -> 0.0729  accuracy: 95.63% -> 97.82%     
client [26] (testset)   loss: 0.0809 -> 0.0626  accuracy: 98.25% -> 97.93%     
client [49] (testset)   loss: 0.0328 -> 0.0340  accuracy: 99.57% -> 99.57%     
client [98] (testset)   loss: 0.3911 -> 0.5606  accuracy: 93.62% -> 85.11%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 0.4776 -> 0.5096  accuracy: 89.36% -> 89.36%     
client [47] (testset)   loss: 0.1548 -> 0.1100  accuracy: 94.57% -> 96.30%     
client [21] (testset)   loss: 0.2558 -> 0.2743  accuracy: 90.68% -> 91.30%     
client [77] (testset)   loss: 0.0565 -> 0.0552  accuracy: 96.89% -> 98.96%     
client [95] (testset)   loss: 0.2465 -> 0.2371  accuracy: 90.74% -> 88.89%     
client [91] (testset)   loss: 0.4117 -> 0.4500  accuracy: 92.31% -> 92.31%     
client [14] (testset)   loss: 0.3389 -> 0.3555  accuracy: 90.48% -> 89.05%     
client [99] (testset)   loss: 0.0836 -> 0.0937  accuracy: 98.16% -> 98.16%     
client [20] (testset)   loss: 0.0483 -> 0.0560  accuracy: 98.92% -> 98.12%     
client [39] (testset)   loss: 0.2002 -> 0.0682  accuracy: 93.33% -> 100.00%    
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 0.2554 -> 0.2184  accuracy: 89.83% -> 89.83%     
client [62] (testset)   loss: 0.4041 -> 0.4331  accuracy: 90.00% -> 90.00%     
client [71] (testset)   loss: 0.1233 -> 0.0775  accuracy: 94.02% -> 96.74%     
client [97] (testset)   loss: 0.0827 -> 0.0705  accuracy: 98.27% -> 98.27%     
client [30] (testset)   loss: 0.1695 -> 0.1905  accuracy: 97.12% -> 97.12%     
client [88] (testset)   loss: 0.4948 -> 0.4311  accuracy: 84.15% -> 87.80%     
client [60] (testset)   loss: 0.2323 -> 0.3258  accuracy: 93.73% -> 90.41%     
client [82] (testset)   loss: 0.1112 -> 0.1028  accuracy: 98.63% -> 98.63%     
client [91] (testset)   loss: 0.4105 -> 0.4308  accuracy: 92.31% -> 92.31%     
client [57] (testset)   loss: 0.0458 -> 0.0384  accuracy: 99.27% -> 99.27%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 0.2966 -> 0.3076  accuracy: 87.69% -> 87.69%     
client [15] (testset)   loss: 0.2222 -> 0.2294  accuracy: 91.56% -> 92.19%     
client [71] (testset)   loss: 0.0835 -> 0.1793  accuracy: 96.74% -> 91.30%     
client [97] (testset)   loss: 0.0655 -> 0.0678  accuracy: 97.84% -> 98.70%     
client [53] (testset)   loss: 0.0373 -> 0.0291  accuracy: 98.80% -> 99.40%     
client [77] (testset)   loss: 0.0576 -> 0.0549  accuracy: 98.96% -> 98.45%     
client [76] (testset)   loss: 0.3402 -> 0.4069  accuracy: 86.67% -> 86.67%     
client [79] (testset)   loss: 0.4348 -> 0.3560  accuracy: 84.73% -> 88.67%     
client [28] (testset)   loss: 0.0257 -> 0.0219  accuracy: 100.00% -> 100.00%   
client [99] (testset)   loss: 0.0811 -> 0.1020  accuracy: 98.16% -> 98.16%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 0.0691 -> 0.0710  accuracy: 98.27% -> 98.27%     
client [86] (testset)   loss: 0.2592 -> 0.2342  accuracy: 94.12% -> 94.12%     
client [34] (testset)   loss: 0.3227 -> 0.3024  accuracy: 96.15% -> 96.15%     
client [73] (testset)   loss: 0.0559 -> 0.0536  accuracy: 98.47% -> 98.47%     
client [5]  (testset)   loss: 0.1315 -> 0.1326  accuracy: 94.29% -> 95.24%     
client [96] (testset)   loss: 0.2871 -> 0.3048  accuracy: 93.43% -> 91.24%     
client [22] (testset)   loss: 0.0532 -> 0.0545  accuracy: 98.97% -> 98.97%     
client [60] (testset)   loss: 0.1960 -> 0.1879  accuracy: 94.46% -> 93.73%     
client [66] (testset)   loss: 0.1511 -> 0.1722  accuracy: 94.02% -> 94.42%     
client [83] (testset)   loss: 0.0439 -> 0.0352  accuracy: 98.09% -> 98.09%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 0.3844 -> 0.3323  accuracy: 86.67% -> 86.67%     
client [65] (testset)   loss: 0.5565 -> 0.5574  accuracy: 87.50% -> 87.50%     
client [95] (testset)   loss: 0.3103 -> 0.2316  accuracy: 92.59% -> 90.74%     
client [17] (testset)   loss: 0.1663 -> 0.1937  accuracy: 94.12% -> 94.65%     
client [8]  (testset)   loss: 0.4159 -> 0.3948  accuracy: 91.37% -> 90.48%     
client [35] (testset)   loss: 0.0338 -> 0.0255  accuracy: 98.65% -> 98.65%     
client [98] (testset)   loss: 0.4450 -> 0.4742  accuracy: 89.36% -> 89.36%     
client [53] (testset)   loss: 0.0323 -> 0.0297  accuracy: 99.40% -> 98.80%     
client [43] (testset)   loss: 0.2504 -> 0.1591  accuracy: 93.85% -> 95.38%     
client [64] (testset)   loss: 0.1953 -> 0.1652  accuracy: 93.23% -> 94.74%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 0.3233 -> 0.2452  accuracy: 90.06% -> 90.68%     
client [88] (testset)   loss: 0.3724 -> 0.3684  accuracy: 85.37% -> 87.80%     
client [38] (testset)   loss: 0.7635 -> 0.6217  accuracy: 83.12% -> 81.82%     
client [3]  (testset)   loss: 0.4017 -> 0.1579  accuracy: 89.11% -> 95.72%     
client [5]  (testset)   loss: 0.1239 -> 0.1323  accuracy: 94.76% -> 94.76%     
client [41] (testset)   loss: 0.2237 -> 0.2323  accuracy: 93.15% -> 92.34%     
client [7]  (testset)   loss: 0.0708 -> 0.0650  accuracy: 97.82% -> 98.25%     
client [37] (testset)   loss: 0.1497 -> 0.1541  accuracy: 94.57% -> 95.65%     
client [45] (testset)   loss: 0.3152 -> 0.3412  accuracy: 86.49% -> 86.49%     
client [47] (testset)   loss: 0.1073 -> 0.1110  accuracy: 96.30% -> 96.30%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 0.0705 -> 0.0498  accuracy: 98.33% -> 98.33%     
client [11] (testset)   loss: 0.3901 -> 0.3708  accuracy: 89.24% -> 88.34%     
client [37] (testset)   loss: 0.1765 -> 0.1886  accuracy: 93.48% -> 93.48%     
client [41] (testset)   loss: 0.2249 -> 0.2425  accuracy: 92.34% -> 92.74%     
client [95] (testset)   loss: 0.2813 -> 0.2552  accuracy: 88.89% -> 90.74%     
client [53] (testset)   loss: 0.0309 -> 0.0276  accuracy: 99.10% -> 98.80%     
client [22] (testset)   loss: 0.0878 -> 0.0436  accuracy: 96.91% -> 98.97%     
client [25] (testset)   loss: 0.1861 -> 0.1746  accuracy: 93.27% -> 96.15%     
client [69] (testset)   loss: 0.1942 -> 0.2539  accuracy: 96.30% -> 96.30%     
client [46] (testset)   loss: 0.3872 -> 0.4877  accuracy: 85.42% -> 80.21%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 0.1468 -> 0.1289  accuracy: 96.30% -> 96.30%     
client [69] (testset)   loss: 0.2278 -> 0.2647  accuracy: 96.30% -> 96.30%     
client [82] (testset)   loss: 0.1121 -> 0.1211  accuracy: 98.29% -> 98.63%     
client [45] (testset)   loss: 0.3102 -> 0.3641  accuracy: 86.49% -> 86.49%     
client [7]  (testset)   loss: 0.0687 -> 0.0815  accuracy: 98.25% -> 96.51%     
client [50] (testset)   loss: 0.0376 -> 0.0300  accuracy: 98.86% -> 98.86%     
client [35] (testset)   loss: 0.0244 -> 0.0303  accuracy: 100.00% -> 98.65%    
client [24] (testset)   loss: 0.5506 -> 0.5903  accuracy: 85.71% -> 85.71%     
client [15] (testset)   loss: 0.2737 -> 0.2656  accuracy: 91.88% -> 92.19%     
client [58] (testset)   loss: 0.1998 -> 0.1686  accuracy: 93.37% -> 94.90%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 0.0244 -> 0.0229  accuracy: 98.73% -> 98.73%     
client [76] (testset)   loss: 0.3133 -> 0.3789  accuracy: 86.67% -> 86.67%     
client [67] (testset)   loss: 0.1929 -> 0.2103  accuracy: 95.88% -> 95.53%     
client [37] (testset)   loss: 0.1705 -> 0.1661  accuracy: 94.57% -> 94.57%     
client [58] (testset)   loss: 0.1664 -> 0.1691  accuracy: 95.41% -> 94.90%     
client [64] (testset)   loss: 0.1504 -> 0.1764  accuracy: 95.49% -> 93.23%     
client [77] (testset)   loss: 0.0483 -> 0.0484  accuracy: 97.93% -> 97.93%     
client [55] (testset)   loss: 0.0016 -> 0.0015  accuracy: 100.00% -> 100.00%   
client [12] (testset)   loss: 0.1708 -> 0.1826  accuracy: 94.91% -> 94.79%     
client [89] (testset)   loss: 0.4487 -> 0.4484  accuracy: 89.47% -> 94.74%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 0.0039 -> 0.0035  accuracy: 100.00% -> 100.00%   
client [51] (testset)   loss: 0.0617 -> 0.0641  accuracy: 97.55% -> 97.55%     
client [8]  (testset)   loss: 0.4541 -> 0.4491  accuracy: 90.77% -> 91.07%     
client [18] (testset)   loss: 0.0220 -> 0.0217  accuracy: 99.50% -> 99.50%     
client [94] (testset)   loss: 0.1240 -> 0.1359  accuracy: 96.18% -> 94.66%     
client [81] (testset)   loss: 0.0227 -> 0.0249  accuracy: 98.15% -> 98.15%     
client [3]  (testset)   loss: 0.1771 -> 0.1737  accuracy: 95.72% -> 95.33%     
client [11] (testset)   loss: 0.4010 -> 0.4547  accuracy: 87.00% -> 88.79%     
client [95] (testset)   loss: 0.2968 -> 0.2668  accuracy: 90.74% -> 90.74%     
client [67] (testset)   loss: 0.2156 -> 0.2251  accuracy: 95.19% -> 95.53%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 0.2690 -> 0.3247  accuracy: 89.44% -> 88.82%     
client [79] (testset)   loss: 0.3531 -> 0.3671  accuracy: 92.12% -> 91.13%     
client [58] (testset)   loss: 0.1608 -> 0.1640  accuracy: 94.39% -> 94.39%     
client [88] (testset)   loss: 0.4150 -> 0.3805  accuracy: 85.37% -> 89.02%     
client [46] (testset)   loss: 0.3164 -> 0.3693  accuracy: 92.71% -> 92.71%     
client [11] (testset)   loss: 0.3820 -> 0.3864  accuracy: 88.34% -> 88.34%     
client [55] (testset)   loss: 0.0012 -> 0.0011  accuracy: 100.00% -> 100.00%   
client [13] (testset)   loss: 0.5980 -> 0.6026  accuracy: 88.46% -> 87.82%     
client [31] (testset)   loss: 0.2423 -> 0.2556  accuracy: 93.85% -> 90.77%     
client [75] (testset)   loss: 0.3597 -> 0.3722  accuracy: 89.95% -> 90.43%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 0.3950 -> 0.3968  accuracy: 88.14% -> 88.14%     
client [7]  (testset)   loss: 0.0659 -> 0.0485  accuracy: 97.38% -> 98.69%     
client [57] (testset)   loss: 0.0734 -> 0.0413  accuracy: 97.45% -> 98.54%     
client [13] (testset)   loss: 0.5381 -> 0.6812  accuracy: 85.58% -> 88.78%     
client [43] (testset)   loss: 0.1253 -> 0.1323  accuracy: 95.38% -> 95.38%     
client [91] (testset)   loss: 0.4135 -> 0.4348  accuracy: 92.31% -> 92.31%     
client [10] (testset)   loss: 0.0161 -> 0.0151  accuracy: 100.00% -> 100.00%   
client [64] (testset)   loss: 0.1710 -> 0.1668  accuracy: 93.23% -> 95.49%     
client [82] (testset)   loss: 0.1148 -> 0.1201  accuracy: 98.63% -> 98.63%     
client [22] (testset)   loss: 0.0394 -> 0.0409  accuracy: 97.94% -> 97.94%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 0.0569 -> 0.0753  accuracy: 98.12% -> 97.85%     
client [23] (testset)   loss: 0.1067 -> 0.2371  accuracy: 97.98% -> 93.94%     
client [88] (testset)   loss: 0.3817 -> 0.3905  accuracy: 86.59% -> 86.59%     
client [98] (testset)   loss: 0.5057 -> 0.5845  accuracy: 89.36% -> 87.23%     
client [79] (testset)   loss: 0.3754 -> 0.3848  accuracy: 91.13% -> 92.12%     
client [21] (testset)   loss: 0.2454 -> 0.2529  accuracy: 91.93% -> 91.30%     
client [92] (testset)   loss: 0.0976 -> 0.1078  accuracy: 95.62% -> 94.89%     
client [56] (testset)   loss: 0.5176 -> 0.5948  accuracy: 83.19% -> 84.87%     
client [5]  (testset)   loss: 0.1434 -> 0.1447  accuracy: 95.24% -> 96.19%     
client [52] (testset)   loss: 0.2954 -> 0.2485  accuracy: 89.83% -> 91.53%     
FedDpa's average time taken by each global epoch: 0 min 2.89 sec.              
FedDpa's total running time: 0 h 9 m 46 s.                                     
==================== FedDpa Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.1725 -> 0.0000",                                    
                "accuracy": "94.74% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.1871 -> 0.0000",                                    
                "accuracy": "94.78% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedDpa Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 94.78% at epoch 200                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
