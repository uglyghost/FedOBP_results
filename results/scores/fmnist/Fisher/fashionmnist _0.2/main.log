==================== FedDpa ====================                               
Experiment Arguments:                                                          
{
    'method': 'feddpa',
    'dataset': {
        'name': 'fmnist',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'fmnist-100clients-0%IID-Dir(0.1)-seed42',
        'alpha': 0.1,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'serial',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': None,
        'num_gpus': None,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 200,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 0,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'feddpa': {
        'fisher_threshold': 0.2
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 0.1684 -> 0.0857  accuracy: 93.26% -> 95.85%     
client [81] (testset)   loss: 0.4310 -> 0.1095  accuracy: 85.19% -> 96.30%     
client [21] (testset)   loss: 2.3023 -> 0.4047  accuracy: 4.97% -> 86.96%      
client [68] (testset)   loss: 0.2844 -> 0.2148  accuracy: 90.91% -> 93.64%     
client [93] (testset)   loss: 0.0518 -> 0.0239  accuracy: 100.00% -> 100.00%   
client [31] (testset)   loss: 0.4857 -> 0.4422  accuracy: 87.69% -> 76.92%     
client [20] (testset)   loss: 0.0840 -> 0.0821  accuracy: 97.31% -> 97.58%     
client [59] (testset)   loss: 2.2251 -> 0.4767  accuracy: 26.28% -> 85.40%     
client [48] (testset)   loss: 0.1496 -> 0.0924  accuracy: 98.73% -> 98.73%     
client [34] (testset)   loss: 0.3589 -> 0.3783  accuracy: 92.31% -> 96.15%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 0.2266 -> 0.2207  accuracy: 93.21% -> 94.44%     
client [99] (testset)   loss: 0.1326 -> 0.0876  accuracy: 97.89% -> 98.42%     
client [67] (testset)   loss: 0.2560 -> 0.1896  accuracy: 92.78% -> 93.47%     
client [0]  (testset)   loss: 0.4464 -> 0.2965  accuracy: 85.71% -> 85.71%     
client [76] (testset)   loss: 0.7908 -> 0.5960  accuracy: 60.00% -> 86.67%     
client [41] (testset)   loss: 0.3518 -> 0.2840  accuracy: 88.31% -> 90.32%     
client [62] (testset)   loss: 2.1420 -> 0.2861  accuracy: 40.00% -> 90.00%     
client [2]  (testset)   loss: 2.1935 -> 0.0302  accuracy: 10.28% -> 98.91%     
client [14] (testset)   loss: 0.4623 -> 0.3203  accuracy: 83.57% -> 90.00%     
client [46] (testset)   loss: 0.3466 -> 0.3904  accuracy: 90.62% -> 90.62%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 0.4929 -> 0.4610  accuracy: 84.57% -> 85.14%     
client [68] (testset)   loss: 0.2113 -> 0.1925  accuracy: 91.82% -> 93.64%     
client [57] (testset)   loss: 0.0555 -> 0.0476  accuracy: 98.91% -> 99.64%     
client [17] (testset)   loss: 0.2714 -> 0.1963  accuracy: 92.51% -> 91.98%     
client [54] (testset)   loss: 0.2814 -> 0.2809  accuracy: 85.71% -> 84.42%     
client [23] (testset)   loss: 2.1099 -> 0.1510  accuracy: 16.16% -> 93.94%     
client [35] (testset)   loss: 0.0723 -> 0.0376  accuracy: 100.00% -> 100.00%   
client [59] (testset)   loss: 0.4318 -> 0.5320  accuracy: 89.05% -> 86.86%     
client [31] (testset)   loss: 0.2937 -> 0.2639  accuracy: 87.69% -> 90.77%     
client [9]  (testset)   loss: 0.1331 -> 0.1581  accuracy: 96.53% -> 95.49%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 0.2417 -> 0.1410  accuracy: 90.23% -> 95.49%     
client [33] (testset)   loss: 0.1791 -> 0.2219  accuracy: 95.32% -> 94.74%     
client [16] (testset)   loss: 0.1047 -> 0.0411  accuracy: 96.67% -> 99.17%     
client [44] (testset)   loss: 0.1682 -> 0.1231  accuracy: 95.28% -> 96.23%     
client [8]  (testset)   loss: 0.4069 -> 0.3885  accuracy: 88.99% -> 89.29%     
client [31] (testset)   loss: 0.2876 -> 0.2873  accuracy: 87.69% -> 89.23%     
client [47] (testset)   loss: 0.1484 -> 0.1106  accuracy: 94.13% -> 96.09%     
client [36] (testset)   loss: 0.2552 -> 0.2317  accuracy: 92.78% -> 93.27%     
client [20] (testset)   loss: 0.0739 -> 0.0508  accuracy: 97.31% -> 98.66%     
client [56] (testset)   loss: 0.4685 -> 0.4472  accuracy: 83.19% -> 84.03%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 0.1213 -> 0.0900  accuracy: 97.69% -> 97.69%     
client [60] (testset)   loss: 0.2241 -> 0.1787  accuracy: 94.83% -> 94.83%     
client [28] (testset)   loss: 0.0335 -> 0.0301  accuracy: 100.00% -> 100.00%   
client [25] (testset)   loss: 0.1488 -> 0.1621  accuracy: 95.19% -> 97.12%     
client [58] (testset)   loss: 0.1724 -> 0.1725  accuracy: 94.39% -> 94.90%     
client [44] (testset)   loss: 0.1282 -> 0.1023  accuracy: 96.23% -> 96.23%     
client [39] (testset)   loss: 0.3009 -> 0.0928  accuracy: 93.33% -> 100.00%    
client [29] (testset)   loss: 0.2877 -> 0.3168  accuracy: 87.34% -> 89.87%     
client [3]  (testset)   loss: 0.2901 -> 0.1505  accuracy: 89.49% -> 93.39%     
client [84] (testset)   loss: 0.0741 -> 0.0089  accuracy: 97.53% -> 100.00%    
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 0.3776 -> 0.2726  accuracy: 87.58% -> 90.06%     
client [84] (testset)   loss: 0.0260 -> 0.0069  accuracy: 100.00% -> 100.00%   
client [10] (testset)   loss: 0.0489 -> 0.0381  accuracy: 100.00% -> 100.00%   
client [36] (testset)   loss: 0.2067 -> 0.3174  accuracy: 92.94% -> 88.67%     
client [65] (testset)   loss: 0.5922 -> 0.5709  accuracy: 87.50% -> 87.50%     
client [81] (testset)   loss: 0.0868 -> 0.0398  accuracy: 96.30% -> 98.15%     
client [79] (testset)   loss: 0.2817 -> 0.2693  accuracy: 88.18% -> 89.16%     
client [42] (testset)   loss: 0.0860 -> 0.0667  accuracy: 98.06% -> 98.67%     
client [11] (testset)   loss: 0.3053 -> 0.3326  accuracy: 87.89% -> 87.44%     
client [96] (testset)   loss: 0.2748 -> 0.2708  accuracy: 91.97% -> 91.97%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 0.3485 -> 0.3503  accuracy: 89.88% -> 90.77%     
client [53] (testset)   loss: 0.0529 -> 0.0274  accuracy: 98.80% -> 99.10%     
client [52] (testset)   loss: 0.2806 -> 0.2238  accuracy: 89.83% -> 89.83%     
client [42] (testset)   loss: 0.0648 -> 0.0630  accuracy: 98.67% -> 98.42%     
client [69] (testset)   loss: 0.1934 -> 0.1917  accuracy: 95.68% -> 96.30%     
client [59] (testset)   loss: 0.4662 -> 0.5850  accuracy: 88.32% -> 88.32%     
client [7]  (testset)   loss: 0.0858 -> 0.0688  accuracy: 96.51% -> 97.82%     
client [26] (testset)   loss: 0.0795 -> 0.0664  accuracy: 98.25% -> 98.09%     
client [49] (testset)   loss: 0.0297 -> 0.0296  accuracy: 99.57% -> 99.57%     
client [98] (testset)   loss: 0.4263 -> 0.6442  accuracy: 93.62% -> 78.72%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 0.5307 -> 0.5570  accuracy: 87.23% -> 87.23%     
client [47] (testset)   loss: 0.1557 -> 0.1151  accuracy: 94.13% -> 96.30%     
client [21] (testset)   loss: 0.2561 -> 0.2648  accuracy: 90.68% -> 91.93%     
client [77] (testset)   loss: 0.0659 -> 0.0561  accuracy: 97.93% -> 98.45%     
client [95] (testset)   loss: 0.2723 -> 0.2342  accuracy: 90.74% -> 88.89%     
client [91] (testset)   loss: 0.3659 -> 0.4036  accuracy: 92.31% -> 92.31%     
client [14] (testset)   loss: 0.3609 -> 0.3833  accuracy: 89.52% -> 86.90%     
client [99] (testset)   loss: 0.0873 -> 0.0928  accuracy: 98.16% -> 98.16%     
client [20] (testset)   loss: 0.0423 -> 0.0497  accuracy: 98.92% -> 98.39%     
client [39] (testset)   loss: 0.1340 -> 0.0398  accuracy: 93.33% -> 100.00%    
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 0.2518 -> 0.2150  accuracy: 89.83% -> 89.83%     
client [62] (testset)   loss: 0.3753 -> 0.3980  accuracy: 90.00% -> 90.00%     
client [71] (testset)   loss: 0.1140 -> 0.0755  accuracy: 94.57% -> 96.74%     
client [97] (testset)   loss: 0.0683 -> 0.0685  accuracy: 98.27% -> 98.27%     
client [30] (testset)   loss: 0.1498 -> 0.1692  accuracy: 97.12% -> 97.12%     
client [88] (testset)   loss: 0.4722 -> 0.4104  accuracy: 85.37% -> 89.02%     
client [60] (testset)   loss: 0.2169 -> 0.3365  accuracy: 94.46% -> 90.41%     
client [82] (testset)   loss: 0.1251 -> 0.0973  accuracy: 98.63% -> 98.63%     
client [91] (testset)   loss: 0.3283 -> 0.3546  accuracy: 92.31% -> 92.31%     
client [57] (testset)   loss: 0.0432 -> 0.0381  accuracy: 99.64% -> 99.64%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 0.2646 -> 0.3041  accuracy: 87.69% -> 84.62%     
client [15] (testset)   loss: 0.2275 -> 0.2229  accuracy: 91.88% -> 92.50%     
client [71] (testset)   loss: 0.0835 -> 0.1672  accuracy: 95.65% -> 92.39%     
client [97] (testset)   loss: 0.0604 -> 0.0650  accuracy: 98.27% -> 97.84%     
client [53] (testset)   loss: 0.0303 -> 0.0218  accuracy: 98.80% -> 99.40%     
client [77] (testset)   loss: 0.0582 -> 0.0505  accuracy: 98.45% -> 98.96%     
client [76] (testset)   loss: 0.3492 -> 0.4492  accuracy: 86.67% -> 86.67%     
client [79] (testset)   loss: 0.5562 -> 0.3300  accuracy: 78.82% -> 88.67%     
client [28] (testset)   loss: 0.0181 -> 0.0093  accuracy: 100.00% -> 100.00%   
client [99] (testset)   loss: 0.0837 -> 0.1042  accuracy: 98.16% -> 98.16%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 0.0655 -> 0.0634  accuracy: 98.27% -> 98.27%     
client [86] (testset)   loss: 0.2110 -> 0.2124  accuracy: 94.12% -> 94.12%     
client [34] (testset)   loss: 0.3288 -> 0.3174  accuracy: 96.15% -> 96.15%     
client [73] (testset)   loss: 0.0469 -> 0.0448  accuracy: 98.47% -> 98.47%     
client [5]  (testset)   loss: 0.1277 -> 0.1279  accuracy: 94.76% -> 95.71%     
client [96] (testset)   loss: 0.2667 -> 0.2709  accuracy: 91.97% -> 91.97%     
client [22] (testset)   loss: 0.0510 -> 0.0518  accuracy: 98.97% -> 98.97%     
client [60] (testset)   loss: 0.1773 -> 0.1921  accuracy: 95.20% -> 94.46%     
client [66] (testset)   loss: 0.1456 -> 0.1619  accuracy: 94.42% -> 94.02%     
client [83] (testset)   loss: 0.0364 -> 0.0293  accuracy: 98.09% -> 98.73%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 0.5329 -> 0.3990  accuracy: 86.67% -> 86.67%     
client [65] (testset)   loss: 0.4181 -> 0.4407  accuracy: 87.50% -> 87.50%     
client [95] (testset)   loss: 0.2652 -> 0.2220  accuracy: 92.59% -> 90.74%     
client [17] (testset)   loss: 0.1712 -> 0.1884  accuracy: 94.12% -> 94.12%     
client [8]  (testset)   loss: 0.3515 -> 0.3260  accuracy: 91.37% -> 91.67%     
client [35] (testset)   loss: 0.0286 -> 0.0239  accuracy: 100.00% -> 100.00%   
client [98] (testset)   loss: 0.4731 -> 0.6401  accuracy: 89.36% -> 87.23%     
client [53] (testset)   loss: 0.0253 -> 0.0195  accuracy: 99.10% -> 99.10%     
client [43] (testset)   loss: 0.2982 -> 0.1440  accuracy: 89.23% -> 95.38%     
client [64] (testset)   loss: 0.1550 -> 0.1693  accuracy: 94.74% -> 93.23%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 0.3521 -> 0.2444  accuracy: 87.58% -> 90.68%     
client [88] (testset)   loss: 0.3453 -> 0.3686  accuracy: 86.59% -> 86.59%     
client [38] (testset)   loss: 0.8602 -> 0.6412  accuracy: 83.12% -> 81.82%     
client [3]  (testset)   loss: 0.7094 -> 0.1391  accuracy: 78.21% -> 95.33%     
client [5]  (testset)   loss: 0.1223 -> 0.1248  accuracy: 94.76% -> 95.24%     
client [41] (testset)   loss: 0.2291 -> 0.2318  accuracy: 93.55% -> 92.34%     
client [7]  (testset)   loss: 0.0658 -> 0.0544  accuracy: 97.82% -> 98.25%     
client [37] (testset)   loss: 0.1387 -> 0.1471  accuracy: 92.39% -> 94.57%     
client [45] (testset)   loss: 0.3213 -> 0.3312  accuracy: 86.49% -> 86.49%     
client [47] (testset)   loss: 0.1161 -> 0.1147  accuracy: 95.43% -> 95.43%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 0.0546 -> 0.0419  accuracy: 98.33% -> 98.33%     
client [11] (testset)   loss: 0.3048 -> 0.8094  accuracy: 89.24% -> 73.54%     
client [37] (testset)   loss: 0.1523 -> 0.1712  accuracy: 94.57% -> 94.57%     
client [41] (testset)   loss: 0.2310 -> 0.2373  accuracy: 91.53% -> 94.35%     
client [95] (testset)   loss: 0.2783 -> 0.2357  accuracy: 88.89% -> 90.74%     
client [53] (testset)   loss: 0.0254 -> 0.0165  accuracy: 98.80% -> 99.10%     
client [22] (testset)   loss: 0.0960 -> 0.0521  accuracy: 96.91% -> 98.97%     
client [25] (testset)   loss: 0.1693 -> 0.1331  accuracy: 94.23% -> 96.15%     
client [69] (testset)   loss: 0.1739 -> 0.2403  accuracy: 96.30% -> 96.30%     
client [46] (testset)   loss: 0.4030 -> 0.5690  accuracy: 87.50% -> 76.04%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 0.1248 -> 0.1170  accuracy: 96.09% -> 97.17%     
client [69] (testset)   loss: 0.2152 -> 0.2288  accuracy: 95.06% -> 96.30%     
client [82] (testset)   loss: 0.0988 -> 0.1133  accuracy: 98.63% -> 98.63%     
client [45] (testset)   loss: 0.3007 -> 0.3573  accuracy: 86.49% -> 86.49%     
client [7]  (testset)   loss: 0.0561 -> 0.0634  accuracy: 98.25% -> 97.38%     
client [50] (testset)   loss: 0.0431 -> 0.0274  accuracy: 98.86% -> 98.86%     
client [35] (testset)   loss: 0.0301 -> 0.0255  accuracy: 100.00% -> 98.65%    
client [24] (testset)   loss: 0.4716 -> 0.5460  accuracy: 85.71% -> 86.86%     
client [15] (testset)   loss: 0.3084 -> 0.2356  accuracy: 88.75% -> 92.81%     
client [58] (testset)   loss: 0.1441 -> 0.1304  accuracy: 94.90% -> 95.41%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 0.0069 -> 0.0068  accuracy: 100.00% -> 100.00%   
client [76] (testset)   loss: 0.3673 -> 0.5026  accuracy: 86.67% -> 86.67%     
client [67] (testset)   loss: 0.1787 -> 0.1895  accuracy: 95.88% -> 95.88%     
client [37] (testset)   loss: 0.1456 -> 0.1555  accuracy: 96.74% -> 94.57%     
client [58] (testset)   loss: 0.1435 -> 0.1432  accuracy: 95.92% -> 95.41%     
client [64] (testset)   loss: 0.1395 -> 0.1775  accuracy: 96.24% -> 93.23%     
client [77] (testset)   loss: 0.0432 -> 0.0424  accuracy: 97.93% -> 98.45%     
client [55] (testset)   loss: 0.0021 -> 0.0014  accuracy: 100.00% -> 100.00%   
client [12] (testset)   loss: 0.1665 -> 0.1708  accuracy: 95.14% -> 95.38%     
client [89] (testset)   loss: 0.4432 -> 0.4505  accuracy: 94.74% -> 94.74%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 0.0065 -> 0.0047  accuracy: 100.00% -> 100.00%   
client [51] (testset)   loss: 0.0505 -> 0.0494  accuracy: 99.02% -> 97.55%     
client [8]  (testset)   loss: 0.3351 -> 0.3654  accuracy: 91.07% -> 90.48%     
client [18] (testset)   loss: 0.0189 -> 0.0198  accuracy: 99.50% -> 99.50%     
client [94] (testset)   loss: 0.1432 -> 0.1168  accuracy: 95.42% -> 95.42%     
client [81] (testset)   loss: 0.0157 -> 0.0176  accuracy: 100.00% -> 100.00%   
client [3]  (testset)   loss: 0.1385 -> 0.1414  accuracy: 94.94% -> 94.94%     
client [11] (testset)   loss: 0.4187 -> 0.3628  accuracy: 84.75% -> 88.34%     
client [95] (testset)   loss: 0.2342 -> 0.2114  accuracy: 92.59% -> 90.74%     
client [67] (testset)   loss: 0.1860 -> 0.2050  accuracy: 95.53% -> 95.19%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 0.2635 -> 0.2898  accuracy: 90.68% -> 89.44%     
client [79] (testset)   loss: 0.3102 -> 0.3849  accuracy: 92.12% -> 89.16%     
client [58] (testset)   loss: 0.1479 -> 0.1354  accuracy: 94.39% -> 95.41%     
client [88] (testset)   loss: 0.3898 -> 0.3822  accuracy: 84.15% -> 87.80%     
client [46] (testset)   loss: 0.3297 -> 0.3459  accuracy: 92.71% -> 92.71%     
client [11] (testset)   loss: 0.3644 -> 0.3517  accuracy: 88.34% -> 88.79%     
client [55] (testset)   loss: 0.0022 -> 0.0011  accuracy: 100.00% -> 100.00%   
client [13] (testset)   loss: 0.4885 -> 0.5215  accuracy: 85.58% -> 87.82%     
client [31] (testset)   loss: 0.2170 -> 0.2552  accuracy: 90.77% -> 89.23%     
client [75] (testset)   loss: 0.3832 -> 0.4481  accuracy: 89.95% -> 89.00%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 0.3376 -> 0.3465  accuracy: 89.83% -> 89.83%     
client [7]  (testset)   loss: 0.0532 -> 0.0362  accuracy: 97.38% -> 98.69%     
client [57] (testset)   loss: 0.0455 -> 0.0380  accuracy: 98.54% -> 98.54%     
client [13] (testset)   loss: 0.5168 -> 0.6604  accuracy: 84.94% -> 88.14%     
client [43] (testset)   loss: 0.1127 -> 0.1103  accuracy: 96.92% -> 96.92%     
client [91] (testset)   loss: 0.3446 -> 0.3664  accuracy: 92.31% -> 92.31%     
client [10] (testset)   loss: 0.0173 -> 0.0170  accuracy: 100.00% -> 100.00%   
client [64] (testset)   loss: 0.1134 -> 0.1480  accuracy: 95.49% -> 94.74%     
client [82] (testset)   loss: 0.0938 -> 0.1070  accuracy: 98.63% -> 98.63%     
client [22] (testset)   loss: 0.0420 -> 0.0506  accuracy: 98.97% -> 97.94%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 0.0479 -> 0.0594  accuracy: 98.12% -> 98.12%     
client [23] (testset)   loss: 0.1004 -> 0.2361  accuracy: 97.98% -> 93.94%     
client [88] (testset)   loss: 0.3817 -> 0.4010  accuracy: 86.59% -> 87.80%     
client [98] (testset)   loss: 0.8180 -> 0.5874  accuracy: 80.85% -> 89.36%     
client [79] (testset)   loss: 0.3316 -> 0.5067  accuracy: 91.13% -> 89.16%     
client [21] (testset)   loss: 0.2210 -> 0.2285  accuracy: 91.93% -> 91.93%     
client [92] (testset)   loss: 0.0890 -> 0.1078  accuracy: 96.35% -> 97.08%     
client [56] (testset)   loss: 0.4665 -> 0.5918  accuracy: 87.39% -> 85.71%     
client [5]  (testset)   loss: 0.1266 -> 0.1331  accuracy: 95.71% -> 95.24%     
client [52] (testset)   loss: 0.2310 -> 0.2182  accuracy: 91.53% -> 91.53%     
FedDpa's average time taken by each global epoch: 0 min 2.89 sec.              
FedDpa's total running time: 0 h 9 m 45 s.                                     
==================== FedDpa Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.1661 -> 0.0000",                                    
                "accuracy": "94.89% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.1751 -> 0.0000",                                    
                "accuracy": "95.05% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedDpa Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 95.05% at epoch 200                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
