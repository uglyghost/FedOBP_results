==================== FedDpa ====================                               
Experiment Arguments:                                                          
{
    'method': 'feddpa',
    'dataset': {
        'name': 'fmnist',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'fmnist-100clients-0%IID-Dir(0.1)-seed42',
        'alpha': 0.1,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'serial',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': None,
        'num_gpus': None,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 200,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 0,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'feddpa': {
        'fisher_threshold': 0.991
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 0.1718 -> 0.0469  accuracy: 93.26% -> 97.41%     
client [81] (testset)   loss: 0.1506 -> 0.0143  accuracy: 96.30% -> 100.00%    
client [21] (testset)   loss: 0.8102 -> 0.2492  accuracy: 72.67% -> 92.55%     
client [68] (testset)   loss: 0.2916 -> 0.1419  accuracy: 87.27% -> 94.55%     
client [93] (testset)   loss: 0.2385 -> 0.0300  accuracy: 98.31% -> 100.00%    
client [31] (testset)   loss: 0.4752 -> 0.5786  accuracy: 86.15% -> 70.77%     
client [20] (testset)   loss: 0.2231 -> 0.0604  accuracy: 93.01% -> 97.85%     
client [59] (testset)   loss: 0.7831 -> 0.4203  accuracy: 77.37% -> 88.32%     
client [48] (testset)   loss: 0.5190 -> 0.0131  accuracy: 86.08% -> 100.00%    
client [34] (testset)   loss: 0.2986 -> 0.3279  accuracy: 80.77% -> 92.31%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 0.3016 -> 0.1440  accuracy: 87.04% -> 95.68%     
client [99] (testset)   loss: 0.7369 -> 0.0502  accuracy: 71.58% -> 98.42%     
client [67] (testset)   loss: 2.1156 -> 0.1320  accuracy: 19.59% -> 95.88%     
client [0]  (testset)   loss: 0.3292 -> 0.1840  accuracy: 85.71% -> 89.80%     
client [76] (testset)   loss: 0.6878 -> 0.3208  accuracy: 80.00% -> 86.67%     
client [41] (testset)   loss: 0.4442 -> 0.1840  accuracy: 89.11% -> 93.15%     
client [62] (testset)   loss: 2.2071 -> 0.2338  accuracy: 40.00% -> 90.00%     
client [2]  (testset)   loss: 1.1307 -> 0.0110  accuracy: 58.21% -> 99.56%     
client [14] (testset)   loss: 1.4600 -> 0.3171  accuracy: 48.33% -> 90.00%     
client [46] (testset)   loss: 2.3371 -> 0.3686  accuracy: 10.42% -> 90.62%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 0.6930 -> 0.3314  accuracy: 70.29% -> 89.14%     
client [68] (testset)   loss: 0.2078 -> 0.1014  accuracy: 94.55% -> 95.45%     
client [57] (testset)   loss: 0.1072 -> 0.0210  accuracy: 97.81% -> 99.64%     
client [17] (testset)   loss: 0.5419 -> 0.1148  accuracy: 76.47% -> 96.26%     
client [54] (testset)   loss: 0.4997 -> 0.2305  accuracy: 76.62% -> 89.61%     
client [23] (testset)   loss: 0.4084 -> 0.1579  accuracy: 81.82% -> 94.95%     
client [35] (testset)   loss: 1.2119 -> 0.0094  accuracy: 52.70% -> 100.00%    
client [59] (testset)   loss: 0.8190 -> 0.3900  accuracy: 70.80% -> 88.32%     
client [31] (testset)   loss: 0.3883 -> 0.2129  accuracy: 84.62% -> 92.31%     
client [9]  (testset)   loss: 0.2669 -> 0.1272  accuracy: 93.06% -> 95.49%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 0.5393 -> 0.1477  accuracy: 77.44% -> 94.74%     
client [33] (testset)   loss: 0.3252 -> 0.0838  accuracy: 85.96% -> 97.66%     
client [16] (testset)   loss: 0.2098 -> 0.0133  accuracy: 91.67% -> 100.00%    
client [44] (testset)   loss: 0.2481 -> 0.0170  accuracy: 87.74% -> 99.06%     
client [8]  (testset)   loss: 0.5958 -> 0.1954  accuracy: 77.98% -> 93.15%     
client [31] (testset)   loss: 0.5852 -> 0.1942  accuracy: 73.85% -> 92.31%     
client [47] (testset)   loss: 0.2540 -> 0.1023  accuracy: 90.65% -> 96.74%     
client [36] (testset)   loss: 0.2489 -> 0.1538  accuracy: 92.28% -> 95.07%     
client [20] (testset)   loss: 0.6517 -> 0.0299  accuracy: 71.24% -> 99.19%     
client [56] (testset)   loss: 0.9263 -> 0.3222  accuracy: 60.50% -> 85.71%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 0.1512 -> 0.1126  accuracy: 96.15% -> 98.46%     
client [60] (testset)   loss: 1.1219 -> 0.1150  accuracy: 62.36% -> 97.05%     
client [28] (testset)   loss: 0.0084 -> 0.0077  accuracy: 100.00% -> 100.00%   
client [25] (testset)   loss: 0.1026 -> 0.0165  accuracy: 94.23% -> 99.04%     
client [58] (testset)   loss: 0.2595 -> 0.0673  accuracy: 91.84% -> 97.45%     
client [44] (testset)   loss: 0.6236 -> 0.0351  accuracy: 79.25% -> 99.06%     
client [39] (testset)   loss: 0.0168 -> 0.0015  accuracy: 100.00% -> 100.00%   
client [29] (testset)   loss: 0.6681 -> 0.2499  accuracy: 83.54% -> 91.14%     
client [3]  (testset)   loss: 0.2239 -> 0.1209  accuracy: 93.00% -> 95.72%     
client [84] (testset)   loss: 0.6968 -> 0.0057  accuracy: 77.78% -> 100.00%    
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 0.2368 -> 0.2066  accuracy: 93.79% -> 91.93%     
client [84] (testset)   loss: 0.7010 -> 0.0065  accuracy: 74.07% -> 100.00%    
client [10] (testset)   loss: 0.2834 -> 0.0191  accuracy: 92.65% -> 100.00%    
client [36] (testset)   loss: 0.4250 -> 0.1620  accuracy: 86.86% -> 94.25%     
client [65] (testset)   loss: 0.5531 -> 0.2270  accuracy: 81.25% -> 90.62%     
client [81] (testset)   loss: 0.4758 -> 0.0028  accuracy: 79.63% -> 100.00%    
client [79] (testset)   loss: 0.9226 -> 0.1651  accuracy: 67.00% -> 93.10%     
client [42] (testset)   loss: 0.1912 -> 0.0570  accuracy: 92.97% -> 98.67%     
client [11] (testset)   loss: 0.7455 -> 0.3312  accuracy: 71.75% -> 88.34%     
client [96] (testset)   loss: 0.2955 -> 0.1776  accuracy: 91.24% -> 93.43%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 0.2601 -> 0.1763  accuracy: 91.07% -> 95.54%     
client [53] (testset)   loss: 0.1030 -> 0.0069  accuracy: 96.08% -> 99.70%     
client [52] (testset)   loss: 0.2948 -> 0.0989  accuracy: 88.14% -> 98.31%     
client [42] (testset)   loss: 0.1351 -> 0.0580  accuracy: 95.88% -> 98.67%     
client [69] (testset)   loss: 0.2471 -> 0.1011  accuracy: 90.12% -> 96.30%     
client [59] (testset)   loss: 0.7065 -> 0.3238  accuracy: 70.07% -> 90.51%     
client [7]  (testset)   loss: 0.1383 -> 0.0203  accuracy: 95.63% -> 99.13%     
client [26] (testset)   loss: 0.3254 -> 0.0521  accuracy: 88.55% -> 98.25%     
client [49] (testset)   loss: 0.0612 -> 0.0289  accuracy: 97.84% -> 99.57%     
client [98] (testset)   loss: 0.6495 -> 0.5386  accuracy: 80.85% -> 87.23%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 0.6262 -> 0.5579  accuracy: 87.23% -> 87.23%     
client [47] (testset)   loss: 0.1646 -> 0.1213  accuracy: 95.00% -> 95.43%     
client [21] (testset)   loss: 0.2421 -> 0.1815  accuracy: 94.41% -> 95.03%     
client [77] (testset)   loss: 0.1191 -> 0.0096  accuracy: 96.89% -> 100.00%    
client [95] (testset)   loss: 0.3664 -> 0.1961  accuracy: 87.04% -> 94.44%     
client [91] (testset)   loss: 0.3559 -> 0.0068  accuracy: 84.62% -> 100.00%    
client [14] (testset)   loss: 0.4088 -> 0.3905  accuracy: 87.38% -> 85.24%     
client [99] (testset)   loss: 0.0437 -> 0.0318  accuracy: 98.95% -> 99.21%     
client [20] (testset)   loss: 0.6008 -> 0.0307  accuracy: 76.34% -> 99.46%     
client [39] (testset)   loss: 0.0418 -> 0.0037  accuracy: 100.00% -> 100.00%   
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 0.1760 -> 0.0989  accuracy: 91.53% -> 98.31%     
client [62] (testset)   loss: 0.2661 -> 0.2073  accuracy: 95.00% -> 90.00%     
client [71] (testset)   loss: 0.1011 -> 0.0537  accuracy: 97.28% -> 97.83%     
client [97] (testset)   loss: 0.1195 -> 0.0457  accuracy: 96.10% -> 98.70%     
client [30] (testset)   loss: 0.3673 -> 0.2200  accuracy: 85.58% -> 96.15%     
client [88] (testset)   loss: 0.7296 -> 0.3226  accuracy: 79.27% -> 91.46%     
client [60] (testset)   loss: 0.3843 -> 0.1232  accuracy: 87.82% -> 96.31%     
client [82] (testset)   loss: 1.0636 -> 0.0771  accuracy: 62.33% -> 98.97%     
client [91] (testset)   loss: 0.1431 -> 0.9997  accuracy: 92.31% -> 92.31%     
client [57] (testset)   loss: 1.0159 -> 0.0247  accuracy: 63.14% -> 99.27%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 0.6416 -> 0.1491  accuracy: 84.62% -> 92.31%     
client [15] (testset)   loss: 0.3267 -> 0.1555  accuracy: 90.62% -> 94.69%     
client [71] (testset)   loss: 0.1834 -> 0.0567  accuracy: 93.48% -> 98.37%     
client [97] (testset)   loss: 0.2937 -> 0.0415  accuracy: 91.34% -> 98.27%     
client [53] (testset)   loss: 0.1595 -> 0.0075  accuracy: 94.88% -> 99.70%     
client [77] (testset)   loss: 0.0467 -> 0.0086  accuracy: 97.93% -> 100.00%    
client [76] (testset)   loss: 0.3918 -> 0.3133  accuracy: 73.33% -> 93.33%     
client [79] (testset)   loss: 0.6748 -> 0.1771  accuracy: 74.88% -> 92.61%     
client [28] (testset)   loss: 0.0219 -> 0.0007  accuracy: 100.00% -> 100.00%   
client [99] (testset)   loss: 0.3296 -> 0.0283  accuracy: 89.21% -> 99.21%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 0.1509 -> 0.0399  accuracy: 94.37% -> 98.70%     
client [86] (testset)   loss: 0.0062 -> 0.0102  accuracy: 100.00% -> 100.00%   
client [34] (testset)   loss: 0.0911 -> 0.1048  accuracy: 100.00% -> 96.15%    
client [73] (testset)   loss: 0.4483 -> 0.0080  accuracy: 85.50% -> 100.00%    
client [5]  (testset)   loss: 0.5787 -> 0.0876  accuracy: 80.48% -> 97.62%     
client [96] (testset)   loss: 0.2977 -> 0.1636  accuracy: 89.78% -> 94.16%     
client [22] (testset)   loss: 0.1646 -> 0.0258  accuracy: 96.91% -> 98.97%     
client [60] (testset)   loss: 0.3075 -> 0.1113  accuracy: 87.82% -> 96.68%     
client [66] (testset)   loss: 0.5005 -> 0.0922  accuracy: 85.26% -> 96.02%     
client [83] (testset)   loss: 0.1294 -> 0.0044  accuracy: 96.18% -> 100.00%    
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 0.3065 -> 0.4020  accuracy: 93.33% -> 93.33%     
client [65] (testset)   loss: 0.4269 -> 0.3149  accuracy: 84.38% -> 90.62%     
client [95] (testset)   loss: 0.3389 -> 0.2063  accuracy: 88.89% -> 94.44%     
client [17] (testset)   loss: 0.2644 -> 0.0952  accuracy: 90.91% -> 96.26%     
client [8]  (testset)   loss: 0.2801 -> 0.1563  accuracy: 91.67% -> 95.83%     
client [35] (testset)   loss: 0.2895 -> 0.0026  accuracy: 93.24% -> 100.00%    
client [98] (testset)   loss: 0.4396 -> 0.4665  accuracy: 89.36% -> 89.36%     
client [53] (testset)   loss: 0.0245 -> 0.0069  accuracy: 99.40% -> 99.70%     
client [43] (testset)   loss: 0.4621 -> 0.0552  accuracy: 81.54% -> 96.92%     
client [64] (testset)   loss: 0.1863 -> 0.1156  accuracy: 92.48% -> 96.24%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 0.3898 -> 0.1504  accuracy: 88.82% -> 95.65%     
client [88] (testset)   loss: 0.4715 -> 0.4056  accuracy: 90.24% -> 91.46%     
client [38] (testset)   loss: 0.4419 -> 0.3362  accuracy: 85.71% -> 93.51%     
client [3]  (testset)   loss: 0.3660 -> 0.1212  accuracy: 88.33% -> 96.50%     
client [5]  (testset)   loss: 0.1986 -> 0.0772  accuracy: 93.81% -> 98.10%     
client [41] (testset)   loss: 0.3193 -> 0.1598  accuracy: 91.94% -> 95.97%     
client [7]  (testset)   loss: 0.1146 -> 0.0176  accuracy: 95.63% -> 99.13%     
client [37] (testset)   loss: 0.4889 -> 0.1967  accuracy: 85.87% -> 95.65%     
client [45] (testset)   loss: 0.5874 -> 0.5939  accuracy: 86.49% -> 91.89%     
client [47] (testset)   loss: 0.1436 -> 0.1023  accuracy: 95.43% -> 96.52%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 0.9884 -> 0.0105  accuracy: 70.00% -> 99.17%     
client [11] (testset)   loss: 2.8071 -> 0.2611  accuracy: 35.87% -> 90.13%     
client [37] (testset)   loss: 1.3999 -> 0.2056  accuracy: 52.17% -> 95.65%     
client [41] (testset)   loss: 0.8308 -> 0.1602  accuracy: 81.85% -> 95.56%     
client [95] (testset)   loss: 0.6623 -> 0.1724  accuracy: 81.48% -> 96.30%     
client [53] (testset)   loss: 0.0970 -> 0.0106  accuracy: 98.49% -> 99.40%     
client [22] (testset)   loss: 1.6882 -> 0.0015  accuracy: 60.82% -> 100.00%    
client [25] (testset)   loss: 0.1413 -> 0.0048  accuracy: 95.19% -> 100.00%    
client [69] (testset)   loss: 0.4549 -> 0.1200  accuracy: 87.65% -> 96.30%     
client [46] (testset)   loss: 0.2300 -> 0.1808  accuracy: 93.75% -> 91.67%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 0.1706 -> 0.0989  accuracy: 94.13% -> 97.17%     
client [69] (testset)   loss: 0.3330 -> 0.1275  accuracy: 91.36% -> 96.30%     
client [82] (testset)   loss: 0.1515 -> 0.1053  accuracy: 94.18% -> 98.97%     
client [45] (testset)   loss: 0.5605 -> 0.5768  accuracy: 86.49% -> 91.89%     
client [7]  (testset)   loss: 0.1686 -> 0.0150  accuracy: 93.45% -> 99.13%     
client [50] (testset)   loss: 0.8828 -> 0.0130  accuracy: 69.80% -> 99.15%     
client [35] (testset)   loss: 0.8890 -> 0.0012  accuracy: 70.27% -> 100.00%    
client [24] (testset)   loss: 0.6189 -> 0.3184  accuracy: 78.29% -> 92.00%     
client [15] (testset)   loss: 0.4465 -> 0.1620  accuracy: 86.88% -> 95.94%     
client [58] (testset)   loss: 0.1391 -> 0.0334  accuracy: 96.43% -> 98.47%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 0.1096 -> 0.0061  accuracy: 96.20% -> 100.00%    
client [76] (testset)   loss: 0.1124 -> 0.4289  accuracy: 93.33% -> 93.33%     
client [67] (testset)   loss: 0.8920 -> 0.2106  accuracy: 72.85% -> 95.88%     
client [37] (testset)   loss: 0.1856 -> 0.1593  accuracy: 93.48% -> 95.65%     
client [58] (testset)   loss: 0.1345 -> 0.0406  accuracy: 96.43% -> 98.98%     
client [64] (testset)   loss: 0.1720 -> 0.0847  accuracy: 93.23% -> 96.99%     
client [77] (testset)   loss: 0.0846 -> 0.0090  accuracy: 98.45% -> 100.00%    
client [55] (testset)   loss: 0.0503 -> 0.0002  accuracy: 98.34% -> 100.00%    
client [12] (testset)   loss: 0.4849 -> 0.1330  accuracy: 87.32% -> 96.80%     
client [89] (testset)   loss: 0.3978 -> 0.3689  accuracy: 89.47% -> 94.74%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 0.7772 -> 0.0137  accuracy: 72.84% -> 98.77%     
client [51] (testset)   loss: 0.1934 -> 0.0043  accuracy: 94.61% -> 100.00%    
client [8]  (testset)   loss: 0.5029 -> 0.1698  accuracy: 85.12% -> 95.24%     
client [18] (testset)   loss: 0.0906 -> 0.0160  accuracy: 97.01% -> 99.50%     
client [94] (testset)   loss: 0.3469 -> 0.0527  accuracy: 90.08% -> 98.47%     
client [81] (testset)   loss: 0.0742 -> 0.0008  accuracy: 98.15% -> 100.00%    
client [3]  (testset)   loss: 0.5504 -> 0.1408  accuracy: 86.38% -> 96.50%     
client [11] (testset)   loss: 0.5394 -> 0.2825  accuracy: 82.51% -> 90.58%     
client [95] (testset)   loss: 0.4915 -> 0.1717  accuracy: 85.19% -> 96.30%     
client [67] (testset)   loss: 1.1586 -> 0.2009  accuracy: 66.67% -> 95.53%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 0.2560 -> 0.1740  accuracy: 93.79% -> 95.03%     
client [79] (testset)   loss: 0.4054 -> 0.1544  accuracy: 88.18% -> 94.58%     
client [58] (testset)   loss: 0.1477 -> 0.0321  accuracy: 95.92% -> 98.98%     
client [88] (testset)   loss: 0.4386 -> 0.3744  accuracy: 84.15% -> 91.46%     
client [46] (testset)   loss: 0.4717 -> 0.2426  accuracy: 83.33% -> 92.71%     
client [11] (testset)   loss: 0.4020 -> 0.2915  accuracy: 84.75% -> 89.69%     
client [55] (testset)   loss: 0.0774 -> 0.0001  accuracy: 97.02% -> 100.00%    
client [13] (testset)   loss: 0.4699 -> 0.3721  accuracy: 83.65% -> 89.42%     
client [31] (testset)   loss: 0.5144 -> 0.1396  accuracy: 83.08% -> 90.77%     
client [75] (testset)   loss: 0.4211 -> 0.2574  accuracy: 87.08% -> 90.43%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 0.3619 -> 0.1696  accuracy: 89.83% -> 93.22%     
client [7]  (testset)   loss: 0.1716 -> 0.0098  accuracy: 94.76% -> 99.56%     
client [57] (testset)   loss: 0.2448 -> 0.0509  accuracy: 91.24% -> 98.91%     
client [13] (testset)   loss: 0.5877 -> 0.3324  accuracy: 80.13% -> 90.06%     
client [43] (testset)   loss: 0.5438 -> 0.0546  accuracy: 80.00% -> 98.46%     
client [91] (testset)   loss: 0.1658 -> 0.0471  accuracy: 92.31% -> 100.00%    
client [10] (testset)   loss: 0.2044 -> 0.0300  accuracy: 94.12% -> 98.53%     
client [64] (testset)   loss: 0.3130 -> 0.0878  accuracy: 87.22% -> 96.99%     
client [82] (testset)   loss: 0.1229 -> 0.0761  accuracy: 95.55% -> 98.97%     
client [22] (testset)   loss: 0.2704 -> 0.0210  accuracy: 89.69% -> 98.97%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 0.2687 -> 0.0234  accuracy: 89.78% -> 99.46%     
client [23] (testset)   loss: 0.4374 -> 0.1454  accuracy: 84.85% -> 95.96%     
client [88] (testset)   loss: 0.4501 -> 0.3781  accuracy: 90.24% -> 89.02%     
client [98] (testset)   loss: 1.2816 -> 0.5467  accuracy: 61.70% -> 87.23%     
client [79] (testset)   loss: 0.4831 -> 0.3056  accuracy: 84.73% -> 93.10%     
client [21] (testset)   loss: 0.3989 -> 0.1665  accuracy: 91.30% -> 95.65%     
client [92] (testset)   loss: 0.1858 -> 0.0591  accuracy: 94.89% -> 97.81%     
client [56] (testset)   loss: 1.0976 -> 0.3044  accuracy: 63.03% -> 89.08%     
client [5]  (testset)   loss: 0.3034 -> 0.0632  accuracy: 90.48% -> 98.57%     
client [52] (testset)   loss: 0.1919 -> 0.1171  accuracy: 94.92% -> 98.31%     
FedDpa's average time taken by each global epoch: 0 min 2.63 sec.              
FedDpa's total running time: 0 h 8 m 51 s.                                     
==================== FedDpa Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.3318 -> 0.0000",                                    
                "accuracy": "88.40% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.4230 -> 0.0000",                                    
                "accuracy": "87.67% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedDpa Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 88.40% at epoch 100                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
