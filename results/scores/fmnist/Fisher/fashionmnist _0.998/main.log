==================== FedDpa ====================                               
Experiment Arguments:                                                          
{
    'method': 'feddpa',
    'dataset': {
        'name': 'fmnist',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'fmnist-100clients-0%IID-Dir(0.1)-seed42',
        'alpha': 0.1,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'serial',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': None,
        'num_gpus': None,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 200,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 0,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'feddpa': {
        'fisher_threshold': 0.998
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 0.2215 -> 0.0460  accuracy: 92.23% -> 97.93%     
client [81] (testset)   loss: 0.1830 -> 0.0170  accuracy: 96.30% -> 100.00%    
client [21] (testset)   loss: 0.5479 -> 0.2396  accuracy: 80.12% -> 92.55%     
client [68] (testset)   loss: 0.3547 -> 0.1420  accuracy: 87.27% -> 94.55%     
client [93] (testset)   loss: 0.4387 -> 0.0300  accuracy: 81.36% -> 100.00%    
client [31] (testset)   loss: 0.4451 -> 0.5555  accuracy: 81.54% -> 70.77%     
client [20] (testset)   loss: 0.2009 -> 0.0607  accuracy: 93.55% -> 97.85%     
client [59] (testset)   loss: 0.5855 -> 0.4178  accuracy: 83.94% -> 89.05%     
client [48] (testset)   loss: 0.7492 -> 0.0134  accuracy: 77.22% -> 100.00%    
client [34] (testset)   loss: 0.3750 -> 0.3249  accuracy: 80.77% -> 92.31%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 0.3406 -> 0.1404  accuracy: 85.80% -> 95.68%     
client [99] (testset)   loss: 0.9444 -> 0.0500  accuracy: 68.42% -> 98.42%     
client [67] (testset)   loss: 2.3809 -> 0.1304  accuracy: 16.15% -> 96.22%     
client [0]  (testset)   loss: 0.3088 -> 0.1814  accuracy: 87.76% -> 89.80%     
client [76] (testset)   loss: 0.6902 -> 0.2972  accuracy: 80.00% -> 86.67%     
client [41] (testset)   loss: 0.4498 -> 0.1836  accuracy: 89.52% -> 93.55%     
client [62] (testset)   loss: 1.6967 -> 0.2544  accuracy: 45.00% -> 90.00%     
client [2]  (testset)   loss: 0.7379 -> 0.0100  accuracy: 71.77% -> 99.56%     
client [14] (testset)   loss: 1.9174 -> 0.3149  accuracy: 35.48% -> 90.24%     
client [46] (testset)   loss: 2.5867 -> 0.3676  accuracy: 10.42% -> 90.62%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 0.7715 -> 0.3261  accuracy: 66.29% -> 88.57%     
client [68] (testset)   loss: 0.2492 -> 0.1014  accuracy: 91.82% -> 96.36%     
client [57] (testset)   loss: 0.1537 -> 0.0208  accuracy: 96.72% -> 99.64%     
client [17] (testset)   loss: 0.6588 -> 0.1141  accuracy: 70.05% -> 95.72%     
client [54] (testset)   loss: 0.6119 -> 0.2363  accuracy: 75.32% -> 89.61%     
client [23] (testset)   loss: 0.3344 -> 0.1616  accuracy: 85.86% -> 94.95%     
client [35] (testset)   loss: 1.1896 -> 0.0090  accuracy: 52.70% -> 100.00%    
client [59] (testset)   loss: 0.8940 -> 0.3872  accuracy: 65.69% -> 89.05%     
client [31] (testset)   loss: 0.4866 -> 0.2092  accuracy: 76.92% -> 92.31%     
client [9]  (testset)   loss: 0.2578 -> 0.1219  accuracy: 93.06% -> 95.49%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 0.5370 -> 0.1465  accuracy: 76.69% -> 94.74%     
client [33] (testset)   loss: 0.3717 -> 0.0788  accuracy: 85.96% -> 97.66%     
client [16] (testset)   loss: 0.3252 -> 0.0138  accuracy: 86.67% -> 100.00%    
client [44] (testset)   loss: 0.2697 -> 0.0159  accuracy: 86.79% -> 100.00%    
client [8]  (testset)   loss: 0.6864 -> 0.1888  accuracy: 73.51% -> 93.45%     
client [31] (testset)   loss: 0.7591 -> 0.2023  accuracy: 70.77% -> 92.31%     
client [47] (testset)   loss: 0.2461 -> 0.1033  accuracy: 90.22% -> 96.52%     
client [36] (testset)   loss: 0.2636 -> 0.1562  accuracy: 91.95% -> 95.07%     
client [20] (testset)   loss: 1.1021 -> 0.0319  accuracy: 57.26% -> 99.19%     
client [56] (testset)   loss: 0.9469 -> 0.3151  accuracy: 59.66% -> 86.55%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 0.1856 -> 0.1055  accuracy: 95.38% -> 97.69%     
client [60] (testset)   loss: 1.2670 -> 0.1153  accuracy: 57.93% -> 96.68%     
client [28] (testset)   loss: 0.0095 -> 0.0070  accuracy: 100.00% -> 100.00%   
client [25] (testset)   loss: 0.1106 -> 0.0118  accuracy: 94.23% -> 99.04%     
client [58] (testset)   loss: 0.2688 -> 0.0600  accuracy: 91.33% -> 97.96%     
client [44] (testset)   loss: 0.6445 -> 0.0426  accuracy: 76.42% -> 99.06%     
client [39] (testset)   loss: 0.0284 -> 0.0013  accuracy: 100.00% -> 100.00%   
client [29] (testset)   loss: 0.6729 -> 0.2633  accuracy: 83.54% -> 91.14%     
client [3]  (testset)   loss: 0.2612 -> 0.1197  accuracy: 91.83% -> 95.72%     
client [84] (testset)   loss: 0.8926 -> 0.0048  accuracy: 67.90% -> 100.00%    
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 0.2408 -> 0.2164  accuracy: 93.17% -> 91.93%     
client [84] (testset)   loss: 0.7695 -> 0.0056  accuracy: 71.60% -> 100.00%    
client [10] (testset)   loss: 0.2999 -> 0.0208  accuracy: 89.71% -> 100.00%    
client [36] (testset)   loss: 0.4615 -> 0.1616  accuracy: 85.39% -> 94.25%     
client [65] (testset)   loss: 0.7507 -> 0.2437  accuracy: 71.88% -> 90.62%     
client [81] (testset)   loss: 0.7525 -> 0.0022  accuracy: 61.11% -> 100.00%    
client [79] (testset)   loss: 1.1668 -> 0.1684  accuracy: 60.59% -> 93.10%     
client [42] (testset)   loss: 0.2031 -> 0.0557  accuracy: 92.48% -> 98.79%     
client [11] (testset)   loss: 0.9071 -> 0.3091  accuracy: 65.92% -> 88.79%     
client [96] (testset)   loss: 0.3132 -> 0.1711  accuracy: 90.51% -> 93.43%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 0.2628 -> 0.1807  accuracy: 91.37% -> 95.54%     
client [53] (testset)   loss: 0.1362 -> 0.0073  accuracy: 94.58% -> 99.70%     
client [52] (testset)   loss: 0.3421 -> 0.1063  accuracy: 86.44% -> 98.31%     
client [42] (testset)   loss: 0.1999 -> 0.0573  accuracy: 92.61% -> 98.79%     
client [69] (testset)   loss: 0.2880 -> 0.0977  accuracy: 88.89% -> 96.30%     
client [59] (testset)   loss: 0.7058 -> 0.3224  accuracy: 70.07% -> 89.78%     
client [7]  (testset)   loss: 0.1451 -> 0.0200  accuracy: 95.20% -> 99.56%     
client [26] (testset)   loss: 0.4582 -> 0.0493  accuracy: 85.69% -> 98.09%     
client [49] (testset)   loss: 0.1182 -> 0.0311  accuracy: 96.12% -> 99.57%     
client [98] (testset)   loss: 0.6333 -> 0.5642  accuracy: 82.98% -> 87.23%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 0.7353 -> 0.5297  accuracy: 82.98% -> 87.23%     
client [47] (testset)   loss: 0.1655 -> 0.1211  accuracy: 95.00% -> 95.00%     
client [21] (testset)   loss: 0.2348 -> 0.1881  accuracy: 94.41% -> 93.79%     
client [77] (testset)   loss: 0.1214 -> 0.0089  accuracy: 96.37% -> 100.00%    
client [95] (testset)   loss: 0.3913 -> 0.1866  accuracy: 85.19% -> 96.30%     
client [91] (testset)   loss: 0.4086 -> 0.0101  accuracy: 84.62% -> 100.00%    
client [14] (testset)   loss: 0.4265 -> 0.3911  accuracy: 87.62% -> 85.00%     
client [99] (testset)   loss: 0.0539 -> 0.0310  accuracy: 98.68% -> 99.21%     
client [20] (testset)   loss: 0.9481 -> 0.0303  accuracy: 66.94% -> 99.19%     
client [39] (testset)   loss: 0.0484 -> 0.0046  accuracy: 93.33% -> 100.00%    
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 0.1862 -> 0.0994  accuracy: 91.53% -> 98.31%     
client [62] (testset)   loss: 0.3249 -> 0.2527  accuracy: 90.00% -> 90.00%     
client [71] (testset)   loss: 0.1115 -> 0.0513  accuracy: 96.20% -> 97.83%     
client [97] (testset)   loss: 0.1479 -> 0.0441  accuracy: 94.81% -> 98.70%     
client [30] (testset)   loss: 0.3694 -> 0.2204  accuracy: 85.58% -> 96.15%     
client [88] (testset)   loss: 0.7971 -> 0.3419  accuracy: 73.17% -> 91.46%     
client [60] (testset)   loss: 0.4515 -> 0.1155  accuracy: 85.61% -> 95.94%     
client [82] (testset)   loss: 1.0921 -> 0.0782  accuracy: 61.99% -> 98.97%     
client [91] (testset)   loss: 0.1449 -> 0.9813  accuracy: 92.31% -> 92.31%     
client [57] (testset)   loss: 1.0463 -> 0.0250  accuracy: 63.14% -> 98.91%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 0.7301 -> 0.1259  accuracy: 76.92% -> 92.31%     
client [15] (testset)   loss: 0.3411 -> 0.1539  accuracy: 90.31% -> 94.38%     
client [71] (testset)   loss: 0.2147 -> 0.0550  accuracy: 92.39% -> 98.37%     
client [97] (testset)   loss: 0.2717 -> 0.0395  accuracy: 92.64% -> 98.70%     
client [53] (testset)   loss: 0.1666 -> 0.0086  accuracy: 95.18% -> 99.70%     
client [77] (testset)   loss: 0.0500 -> 0.0089  accuracy: 97.93% -> 100.00%    
client [76] (testset)   loss: 0.3893 -> 0.3147  accuracy: 80.00% -> 93.33%     
client [79] (testset)   loss: 0.6909 -> 0.1461  accuracy: 74.38% -> 93.60%     
client [28] (testset)   loss: 0.1158 -> 0.0007  accuracy: 92.86% -> 100.00%    
client [99] (testset)   loss: 0.3575 -> 0.0289  accuracy: 86.84% -> 99.21%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 0.1572 -> 0.0372  accuracy: 94.37% -> 98.70%     
client [86] (testset)   loss: 0.0078 -> 0.0085  accuracy: 100.00% -> 100.00%   
client [34] (testset)   loss: 0.0957 -> 0.0969  accuracy: 96.15% -> 96.15%     
client [73] (testset)   loss: 0.5389 -> 0.0073  accuracy: 81.68% -> 100.00%    
client [5]  (testset)   loss: 0.5806 -> 0.0907  accuracy: 80.48% -> 97.62%     
client [96] (testset)   loss: 0.3039 -> 0.1679  accuracy: 89.78% -> 93.43%     
client [22] (testset)   loss: 0.1900 -> 0.0152  accuracy: 94.85% -> 100.00%    
client [60] (testset)   loss: 0.4074 -> 0.1130  accuracy: 86.72% -> 96.68%     
client [66] (testset)   loss: 0.5206 -> 0.0881  accuracy: 84.46% -> 96.41%     
client [83] (testset)   loss: 0.1668 -> 0.0050  accuracy: 94.27% -> 100.00%    
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 0.3161 -> 0.4140  accuracy: 93.33% -> 93.33%     
client [65] (testset)   loss: 0.6928 -> 0.3590  accuracy: 71.88% -> 90.62%     
client [95] (testset)   loss: 0.4097 -> 0.1940  accuracy: 88.89% -> 94.44%     
client [17] (testset)   loss: 0.3002 -> 0.0862  accuracy: 90.91% -> 97.86%     
client [8]  (testset)   loss: 0.3010 -> 0.1583  accuracy: 90.77% -> 95.24%     
client [35] (testset)   loss: 0.3421 -> 0.0017  accuracy: 89.19% -> 100.00%    
client [98] (testset)   loss: 0.5561 -> 0.4687  accuracy: 78.72% -> 85.11%     
client [53] (testset)   loss: 0.0298 -> 0.0073  accuracy: 99.10% -> 99.70%     
client [43] (testset)   loss: 0.7509 -> 0.0483  accuracy: 69.23% -> 98.46%     
client [64] (testset)   loss: 0.2025 -> 0.1085  accuracy: 91.73% -> 95.49%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 0.3831 -> 0.1459  accuracy: 89.44% -> 95.03%     
client [88] (testset)   loss: 0.6290 -> 0.4210  accuracy: 84.15% -> 91.46%     
client [38] (testset)   loss: 0.5093 -> 0.3437  accuracy: 81.82% -> 92.21%     
client [3]  (testset)   loss: 0.3558 -> 0.1235  accuracy: 89.11% -> 96.89%     
client [5]  (testset)   loss: 0.2124 -> 0.0843  accuracy: 93.33% -> 97.62%     
client [41] (testset)   loss: 0.3259 -> 0.1743  accuracy: 91.53% -> 95.16%     
client [7]  (testset)   loss: 0.1496 -> 0.0188  accuracy: 94.76% -> 99.13%     
client [37] (testset)   loss: 0.6976 -> 0.2133  accuracy: 73.91% -> 95.65%     
client [45] (testset)   loss: 0.5634 -> 0.5724  accuracy: 89.19% -> 89.19%     
client [47] (testset)   loss: 0.1481 -> 0.0997  accuracy: 95.22% -> 96.74%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 1.3309 -> 0.0121  accuracy: 65.00% -> 99.17%     
client [11] (testset)   loss: 3.1189 -> 0.2412  accuracy: 31.39% -> 90.13%     
client [37] (testset)   loss: 1.9401 -> 0.2015  accuracy: 40.22% -> 95.65%     
client [41] (testset)   loss: 0.8596 -> 0.1708  accuracy: 80.24% -> 94.76%     
client [95] (testset)   loss: 0.7274 -> 0.1648  accuracy: 77.78% -> 96.30%     
client [53] (testset)   loss: 0.1030 -> 0.0107  accuracy: 98.49% -> 99.40%     
client [22] (testset)   loss: 1.7720 -> 0.0021  accuracy: 61.86% -> 100.00%    
client [25] (testset)   loss: 0.1484 -> 0.0071  accuracy: 96.15% -> 100.00%    
client [69] (testset)   loss: 0.4833 -> 0.1156  accuracy: 87.04% -> 96.30%     
client [46] (testset)   loss: 0.2185 -> 0.1326  accuracy: 93.75% -> 92.71%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 0.1969 -> 0.1024  accuracy: 93.04% -> 97.17%     
client [69] (testset)   loss: 0.3494 -> 0.1264  accuracy: 90.74% -> 96.30%     
client [82] (testset)   loss: 0.1999 -> 0.1013  accuracy: 92.47% -> 98.97%     
client [45] (testset)   loss: 0.5566 -> 0.5620  accuracy: 86.49% -> 89.19%     
client [7]  (testset)   loss: 0.2776 -> 0.0141  accuracy: 88.21% -> 99.13%     
client [50] (testset)   loss: 0.9193 -> 0.0157  accuracy: 71.79% -> 99.15%     
client [35] (testset)   loss: 1.0725 -> 0.0006  accuracy: 66.22% -> 100.00%    
client [24] (testset)   loss: 0.6681 -> 0.3277  accuracy: 74.86% -> 91.43%     
client [15] (testset)   loss: 0.4691 -> 0.1722  accuracy: 87.19% -> 95.00%     
client [58] (testset)   loss: 0.1437 -> 0.0302  accuracy: 96.43% -> 98.47%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 0.2283 -> 0.0084  accuracy: 92.41% -> 100.00%    
client [76] (testset)   loss: 0.1318 -> 0.4590  accuracy: 93.33% -> 93.33%     
client [67] (testset)   loss: 1.3499 -> 0.1986  accuracy: 60.48% -> 95.88%     
client [37] (testset)   loss: 0.2336 -> 0.1522  accuracy: 92.39% -> 95.65%     
client [58] (testset)   loss: 0.1515 -> 0.0448  accuracy: 95.41% -> 97.96%     
client [64] (testset)   loss: 0.1822 -> 0.0809  accuracy: 92.48% -> 96.99%     
client [77] (testset)   loss: 0.0933 -> 0.0114  accuracy: 98.45% -> 100.00%    
client [55] (testset)   loss: 0.0451 -> 0.0002  accuracy: 98.34% -> 100.00%    
client [12] (testset)   loss: 0.5387 -> 0.1365  accuracy: 86.14% -> 96.45%     
client [89] (testset)   loss: 0.4513 -> 0.3767  accuracy: 89.47% -> 94.74%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 0.9392 -> 0.0116  accuracy: 71.60% -> 98.77%     
client [51] (testset)   loss: 0.2219 -> 0.0064  accuracy: 93.63% -> 99.51%     
client [8]  (testset)   loss: 0.5756 -> 0.1674  accuracy: 84.23% -> 94.94%     
client [18] (testset)   loss: 0.0954 -> 0.0126  accuracy: 97.01% -> 99.50%     
client [94] (testset)   loss: 0.3562 -> 0.0663  accuracy: 90.08% -> 98.47%     
client [81] (testset)   loss: 0.1187 -> 0.0010  accuracy: 94.44% -> 100.00%    
client [3]  (testset)   loss: 0.5792 -> 0.1394  accuracy: 84.82% -> 96.11%     
client [11] (testset)   loss: 0.5656 -> 0.2702  accuracy: 81.17% -> 90.13%     
client [95] (testset)   loss: 0.6381 -> 0.1567  accuracy: 83.33% -> 96.30%     
client [67] (testset)   loss: 1.5774 -> 0.1839  accuracy: 57.39% -> 95.88%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 0.2428 -> 0.1756  accuracy: 93.79% -> 95.03%     
client [79] (testset)   loss: 0.4278 -> 0.1411  accuracy: 86.70% -> 96.55%     
client [58] (testset)   loss: 0.1597 -> 0.0378  accuracy: 94.90% -> 98.47%     
client [88] (testset)   loss: 0.4840 -> 0.4000  accuracy: 84.15% -> 90.24%     
client [46] (testset)   loss: 0.6123 -> 0.2274  accuracy: 79.17% -> 92.71%     
client [11] (testset)   loss: 0.4506 -> 0.2635  accuracy: 83.86% -> 88.79%     
client [55] (testset)   loss: 0.0732 -> 0.0001  accuracy: 98.01% -> 100.00%    
client [13] (testset)   loss: 0.4798 -> 0.4062  accuracy: 82.05% -> 90.06%     
client [31] (testset)   loss: 0.5355 -> 0.1103  accuracy: 83.08% -> 93.85%     
client [75] (testset)   loss: 0.4954 -> 0.2969  accuracy: 84.69% -> 90.91%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 0.3300 -> 0.1733  accuracy: 91.53% -> 93.22%     
client [7]  (testset)   loss: 0.2279 -> 0.0119  accuracy: 93.01% -> 99.56%     
client [57] (testset)   loss: 0.2566 -> 0.0432  accuracy: 89.78% -> 98.54%     
client [13] (testset)   loss: 0.5964 -> 0.3399  accuracy: 79.81% -> 89.42%     
client [43] (testset)   loss: 0.6048 -> 0.0663  accuracy: 76.92% -> 98.46%     
client [91] (testset)   loss: 0.2279 -> 0.0711  accuracy: 92.31% -> 92.31%     
client [10] (testset)   loss: 0.1863 -> 0.0243  accuracy: 94.12% -> 98.53%     
client [64] (testset)   loss: 0.4488 -> 0.0894  accuracy: 84.96% -> 96.99%     
client [82] (testset)   loss: 0.1637 -> 0.0724  accuracy: 94.86% -> 98.97%     
client [22] (testset)   loss: 0.3195 -> 0.0145  accuracy: 88.66% -> 98.97%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 0.4461 -> 0.0224  accuracy: 85.75% -> 99.46%     
client [23] (testset)   loss: 0.3942 -> 0.1381  accuracy: 86.87% -> 95.96%     
client [88] (testset)   loss: 0.4868 -> 0.4015  accuracy: 87.80% -> 89.02%     
client [98] (testset)   loss: 1.2773 -> 0.6075  accuracy: 59.57% -> 87.23%     
client [79] (testset)   loss: 0.5184 -> 0.1887  accuracy: 82.27% -> 94.58%     
client [21] (testset)   loss: 0.3659 -> 0.1703  accuracy: 91.93% -> 95.65%     
client [92] (testset)   loss: 0.1798 -> 0.0648  accuracy: 93.43% -> 97.81%     
client [56] (testset)   loss: 1.2515 -> 0.3167  accuracy: 58.82% -> 84.87%     
client [5]  (testset)   loss: 0.3141 -> 0.0696  accuracy: 90.95% -> 98.10%     
client [52] (testset)   loss: 0.1681 -> 0.1088  accuracy: 94.92% -> 98.31%     
FedDpa's average time taken by each global epoch: 0 min 2.60 sec.              
FedDpa's total running time: 0 h 8 m 46 s.                                     
==================== FedDpa Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.3940 -> 0.0000",                                    
                "accuracy": "86.26% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.4783 -> 0.0000",                                    
                "accuracy": "85.96% -> 0.00%"                                  
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedDpa Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 86.26% at epoch 100                                 
(test) after fine-tuning: 0.00% at epoch 100                                   
