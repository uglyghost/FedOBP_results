==================== FedRep ====================                               
Experiment Arguments:                                                          
{
    'method': 'fedrep',
    'dataset': {
        'name': 'emnist',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'emnist-100clients-0%IID-Dir(0.1)-seed42',
        'emnist_split': 'byclass',
        'alpha': 0.1,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'parallel',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': 24.0,
        'num_gpus': 1.0,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 400,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 5,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'fedrep': {
        'train_body_epoch': 1
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 0.2105 -> 0.2060  accuracy: 94.43% -> 94.56%     
client [81] (testset)   loss: 0.3212 -> 0.3300  accuracy: 87.88% -> 87.15%     
client [68] (testset)   loss: 0.2414 -> 0.2225  accuracy: 92.91% -> 93.65%     
client [21] (testset)   loss: 0.9078 -> 0.2019  accuracy: 77.73% -> 94.04%     
client [93] (testset)   loss: 0.1752 -> 0.1611  accuracy: 94.45% -> 94.81%     
client [31] (testset)   loss: 1.3722 -> 0.2152  accuracy: 72.56% -> 94.02%     
client [59] (testset)   loss: 0.6591 -> 0.2573  accuracy: 81.43% -> 89.92%     
client [20] (testset)   loss: 0.2472 -> 0.2320  accuracy: 92.63% -> 92.91%     
client [48] (testset)   loss: 0.4397 -> 0.5354  accuracy: 81.78% -> 77.91%     
client [34] (testset)   loss: 0.1318 -> 0.1319  accuracy: 95.98% -> 95.98%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 0.5303 -> 0.2693  accuracy: 89.65% -> 92.13%     
client [67] (testset)   loss: 0.1710 -> 0.1610  accuracy: 94.12% -> 95.04%     
client [0]  (testset)   loss: 0.1762 -> 0.1768  accuracy: 95.78% -> 95.38%     
client [99] (testset)   loss: 0.1442 -> 0.1405  accuracy: 95.70% -> 95.96%     
client [76] (testset)   loss: 0.1440 -> 0.1496  accuracy: 95.01% -> 94.87%     
client [41] (testset)   loss: 0.2629 -> 0.3155  accuracy: 90.34% -> 90.09%     
client [62] (testset)   loss: 0.9206 -> 0.1995  accuracy: 79.54% -> 94.30%     
client [2]  (testset)   loss: 0.9703 -> 0.1150  accuracy: 72.58% -> 96.50%     
client [14] (testset)   loss: 0.2064 -> 0.2329  accuracy: 94.02% -> 93.29%     
client [46] (testset)   loss: 0.0744 -> 0.0700  accuracy: 98.09% -> 98.05%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [68] (testset)   loss: 0.1788 -> 0.2043  accuracy: 95.03% -> 94.29%     
client [24] (testset)   loss: 0.1293 -> 0.1403  accuracy: 95.68% -> 95.35%     
client [57] (testset)   loss: 0.0815 -> 0.0777  accuracy: 98.07% -> 97.96%     
client [54] (testset)   loss: 0.1852 -> 0.2007  accuracy: 94.28% -> 94.78%     
client [17] (testset)   loss: 0.2810 -> 0.2945  accuracy: 92.88% -> 93.00%     
client [23] (testset)   loss: 0.8447 -> 0.3577  accuracy: 72.60% -> 84.67%     
client [35] (testset)   loss: 0.1021 -> 0.1060  accuracy: 97.44% -> 97.24%     
client [59] (testset)   loss: 0.2080 -> 0.2752  accuracy: 92.48% -> 89.49%     
client [9]  (testset)   loss: 0.1240 -> 0.1471  accuracy: 96.44% -> 95.73%     
client [31] (testset)   loss: 0.1844 -> 0.2021  accuracy: 93.28% -> 93.73%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 0.3968 -> 0.3530  accuracy: 91.27% -> 91.84%     
client [16] (testset)   loss: 0.2159 -> 0.2321  accuracy: 93.67% -> 93.27%     
client [33] (testset)   loss: 0.0875 -> 0.1018  accuracy: 97.86% -> 97.18%     
client [44] (testset)   loss: 0.3603 -> 0.2227  accuracy: 92.02% -> 93.19%     
client [8]  (testset)   loss: 0.2365 -> 0.2468  accuracy: 93.01% -> 92.25%     
client [31] (testset)   loss: 0.1863 -> 0.1930  accuracy: 94.02% -> 93.48%     
client [47] (testset)   loss: 0.1982 -> 0.2019  accuracy: 93.76% -> 94.19%     
client [36] (testset)   loss: 0.1317 -> 0.1255  accuracy: 96.62% -> 96.67%     
client [20] (testset)   loss: 0.2171 -> 0.2503  accuracy: 93.54% -> 93.36%     
client [56] (testset)   loss: 0.0893 -> 0.0984  accuracy: 97.92% -> 97.75%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [60] (testset)   loss: 0.0728 -> 0.0650  accuracy: 97.76% -> 98.22%     
client [4]  (testset)   loss: 0.3233 -> 0.3522  accuracy: 88.32% -> 86.93%     
client [25] (testset)   loss: 0.1340 -> 0.1033  accuracy: 95.06% -> 96.82%     
client [28] (testset)   loss: 0.1365 -> 0.1208  accuracy: 94.90% -> 95.18%     
client [58] (testset)   loss: 0.0699 -> 0.0831  accuracy: 98.38% -> 98.33%     
client [44] (testset)   loss: 0.3771 -> 0.2289  accuracy: 88.09% -> 93.62%     
client [39] (testset)   loss: 0.1270 -> 0.1280  accuracy: 96.31% -> 96.61%     
client [29] (testset)   loss: 0.1831 -> 0.1777  accuracy: 94.09% -> 94.45%     
client [84] (testset)   loss: 0.1191 -> 0.1096  accuracy: 96.03% -> 96.31%     
client [3]  (testset)   loss: 0.1229 -> 0.1175  accuracy: 96.58% -> 96.64%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [84] (testset)   loss: 0.1109 -> 0.1153  accuracy: 96.31% -> 96.17%     
client [10] (testset)   loss: 0.2595 -> 0.2339  accuracy: 88.11% -> 91.61%     
client [21] (testset)   loss: 0.2812 -> 0.1704  accuracy: 92.70% -> 95.02%     
client [36] (testset)   loss: 0.1214 -> 0.1290  accuracy: 96.67% -> 96.39%     
client [65] (testset)   loss: 0.2737 -> 0.2865  accuracy: 90.98% -> 89.94%     
client [79] (testset)   loss: 0.2691 -> 0.3016  accuracy: 91.26% -> 91.47%     
client [81] (testset)   loss: 0.3250 -> 0.3130  accuracy: 89.70% -> 88.02%     
client [42] (testset)   loss: 0.1970 -> 0.2087  accuracy: 94.19% -> 94.37%     
client [11] (testset)   loss: 0.1882 -> 0.1911  accuracy: 95.03% -> 95.31%     
client [96] (testset)   loss: 0.1641 -> 0.1670  accuracy: 95.97% -> 96.02%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 0.2295 -> 0.3403  accuracy: 93.95% -> 90.96%     
client [53] (testset)   loss: 0.1666 -> 0.1664  accuracy: 96.68% -> 96.53%     
client [52] (testset)   loss: 0.3097 -> 0.3532  accuracy: 89.50% -> 90.95%     
client [69] (testset)   loss: 0.2430 -> 0.2808  accuracy: 93.14% -> 91.79%     
client [42] (testset)   loss: 0.2094 -> 0.2046  accuracy: 94.19% -> 94.49%     
client [7]  (testset)   loss: 0.1807 -> 0.1779  accuracy: 96.09% -> 96.15%     
client [59] (testset)   loss: 0.2013 -> 0.2347  accuracy: 93.41% -> 91.45%     
client [26] (testset)   loss: 0.2027 -> 0.2758  accuracy: 94.20% -> 93.94%     
client [49] (testset)   loss: 0.0784 -> 0.0817  accuracy: 97.90% -> 97.81%     
client [98] (testset)   loss: 0.1158 -> 0.1366  accuracy: 96.35% -> 96.50%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [47] (testset)   loss: 0.2339 -> 0.2597  accuracy: 92.22% -> 90.68%     
client [98] (testset)   loss: 0.1104 -> 0.1328  accuracy: 96.45% -> 96.55%     
client [77] (testset)   loss: 0.1378 -> 0.1580  accuracy: 96.11% -> 95.92%     
client [21] (testset)   loss: 0.1657 -> 0.1700  accuracy: 95.20% -> 95.17%     
client [91] (testset)   loss: 0.0848 -> 0.0931  accuracy: 97.99% -> 97.88%     
client [95] (testset)   loss: 0.1254 -> 0.1416  accuracy: 95.94% -> 95.79%     
client [14] (testset)   loss: 0.1981 -> 0.2392  accuracy: 94.62% -> 94.08%     
client [99] (testset)   loss: 0.1348 -> 0.1436  accuracy: 96.22% -> 96.16%     
client [20] (testset)   loss: 0.2201 -> 0.2456  accuracy: 94.13% -> 94.08%     
client [39] (testset)   loss: 0.1226 -> 0.1347  accuracy: 96.91% -> 96.55%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 0.2819 -> 0.3247  accuracy: 91.28% -> 88.83%     
client [62] (testset)   loss: 0.1755 -> 0.2265  accuracy: 96.13% -> 95.19%     
client [97] (testset)   loss: 0.1031 -> 0.1147  accuracy: 97.65% -> 97.76%     
client [71] (testset)   loss: 0.0868 -> 0.1032  accuracy: 97.67% -> 97.65%     
client [88] (testset)   loss: 0.2161 -> 0.2342  accuracy: 92.81% -> 92.37%     
client [30] (testset)   loss: 0.2096 -> 0.2338  accuracy: 94.10% -> 94.04%     
client [60] (testset)   loss: 0.0608 -> 0.0559  accuracy: 98.61% -> 98.76%     
client [82] (testset)   loss: 0.3999 -> 0.4057  accuracy: 82.23% -> 81.75%     
client [91] (testset)   loss: 0.0884 -> 0.0904  accuracy: 97.93% -> 97.99%     
client [57] (testset)   loss: 0.0634 -> 0.0645  accuracy: 98.28% -> 98.39%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 0.2494 -> 0.2305  accuracy: 92.98% -> 93.98%     
client [15] (testset)   loss: 0.1824 -> 0.1699  accuracy: 93.44% -> 93.29%     
client [97] (testset)   loss: 0.1137 -> 0.1211  accuracy: 97.86% -> 97.43%     
client [71] (testset)   loss: 0.0994 -> 0.1060  accuracy: 97.67% -> 96.80%     
client [53] (testset)   loss: 0.1704 -> 0.1788  accuracy: 96.82% -> 96.87%     
client [77] (testset)   loss: 0.1539 -> 0.1820  accuracy: 96.18% -> 95.79%     
client [76] (testset)   loss: 0.1430 -> 0.1346  accuracy: 96.11% -> 95.75%     
client [79] (testset)   loss: 0.3155 -> 0.3359  accuracy: 92.11% -> 89.26%     
client [99] (testset)   loss: 0.1504 -> 0.1546  accuracy: 96.27% -> 96.30%     
client [28] (testset)   loss: 0.1732 -> 0.1300  accuracy: 95.08% -> 94.69%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [86] (testset)   loss: 0.3390 -> 0.3872  accuracy: 89.84% -> 89.63%     
client [34] (testset)   loss: 0.1073 -> 0.1181  accuracy: 97.40% -> 97.35%     
client [97] (testset)   loss: 0.1066 -> 0.1193  accuracy: 97.78% -> 97.59%     
client [73] (testset)   loss: 0.2314 -> 0.2774  accuracy: 93.87% -> 92.70%     
client [5]  (testset)   loss: 0.1419 -> 0.1899  accuracy: 95.38% -> 94.42%     
client [96] (testset)   loss: 0.1761 -> 0.1904  accuracy: 96.30% -> 95.88%     
client [60] (testset)   loss: 0.0560 -> 0.0587  accuracy: 98.76% -> 98.69%     
client [22] (testset)   loss: 0.1797 -> 0.1839  accuracy: 94.47% -> 94.51%     
client [66] (testset)   loss: 0.1677 -> 0.1909  accuracy: 96.00% -> 95.68%     
client [83] (testset)   loss: 0.1807 -> 0.1914  accuracy: 95.63% -> 95.45%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 0.1242 -> 0.1323  accuracy: 95.82% -> 95.89%     
client [65] (testset)   loss: 0.4271 -> 0.2885  accuracy: 90.57% -> 91.40%     
client [95] (testset)   loss: 0.1379 -> 0.1528  accuracy: 96.08% -> 95.94%     
client [17] (testset)   loss: 0.2993 -> 0.2812  accuracy: 93.64% -> 92.46%     
client [8]  (testset)   loss: 0.2657 -> 0.2502  accuracy: 92.43% -> 92.54%     
client [98] (testset)   loss: 0.1233 -> 0.1392  accuracy: 96.25% -> 96.55%     
client [35] (testset)   loss: 0.1141 -> 0.1220  accuracy: 97.77% -> 97.38%     
client [43] (testset)   loss: 0.3046 -> 0.2798  accuracy: 90.65% -> 92.50%     
client [64] (testset)   loss: 0.3674 -> 0.4211  accuracy: 91.46% -> 91.27%     
client [53] (testset)   loss: 0.1656 -> 0.1777  accuracy: 96.72% -> 96.77%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [88] (testset)   loss: 0.2375 -> 0.2342  accuracy: 92.66% -> 92.81%     
client [38] (testset)   loss: 0.1267 -> 0.1404  accuracy: 96.31% -> 96.21%     
client [21] (testset)   loss: 0.1741 -> 0.1686  accuracy: 95.42% -> 95.53%     
client [5]  (testset)   loss: 0.1702 -> 0.1890  accuracy: 95.27% -> 95.49%     
client [41] (testset)   loss: 0.2507 -> 0.2675  accuracy: 92.16% -> 91.54%     
client [3]  (testset)   loss: 0.1409 -> 0.1492  accuracy: 96.68% -> 96.50%     
client [7]  (testset)   loss: 0.1697 -> 0.1857  accuracy: 95.96% -> 96.02%     
client [37] (testset)   loss: 0.2395 -> 0.2475  accuracy: 90.80% -> 92.74%     
client [45] (testset)   loss: 0.3340 -> 0.3334  accuracy: 89.73% -> 88.59%     
client [47] (testset)   loss: 0.2796 -> 0.2923  accuracy: 90.51% -> 91.11%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 0.2507 -> 0.2458  accuracy: 93.92% -> 94.24%     
client [11] (testset)   loss: 0.1960 -> 0.1966  accuracy: 96.21% -> 96.21%     
client [41] (testset)   loss: 0.2904 -> 0.2740  accuracy: 91.16% -> 90.85%     
client [37] (testset)   loss: 0.2394 -> 0.2451  accuracy: 92.49% -> 92.06%     
client [95] (testset)   loss: 0.1444 -> 0.1607  accuracy: 96.27% -> 95.89%     
client [53] (testset)   loss: 0.1671 -> 0.1805  accuracy: 96.97% -> 96.92%     
client [25] (testset)   loss: 0.0965 -> 0.1036  accuracy: 97.15% -> 96.60%     
client [22] (testset)   loss: 0.2050 -> 0.2762  accuracy: 94.32% -> 94.75%     
client [69] (testset)   loss: 0.2709 -> 0.3073  accuracy: 93.14% -> 93.59%     
client [46] (testset)   loss: 0.0892 -> 0.0988  accuracy: 98.37% -> 98.29%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [69] (testset)   loss: 0.2608 -> 0.2859  accuracy: 93.25% -> 93.25%     
client [47] (testset)   loss: 0.2737 -> 0.3175  accuracy: 91.45% -> 90.68%     
client [45] (testset)   loss: 0.3473 -> 0.3491  accuracy: 88.95% -> 88.89%     
client [82] (testset)   loss: 0.4170 -> 0.4631  accuracy: 82.41% -> 81.16%     
client [7]  (testset)   loss: 0.1697 -> 0.1769  accuracy: 96.09% -> 95.69%     
client [50] (testset)   loss: 0.0650 -> 0.0635  accuracy: 98.84% -> 98.78%     
client [24] (testset)   loss: 0.1251 -> 0.1320  accuracy: 95.60% -> 95.93%     
client [35] (testset)   loss: 0.1065 -> 0.1166  accuracy: 97.56% -> 97.09%     
client [15] (testset)   loss: 0.2584 -> 0.2269  accuracy: 93.68% -> 93.33%     
client [58] (testset)   loss: 0.0808 -> 0.0890  accuracy: 98.58% -> 98.51%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 0.4809 -> 0.6069  accuracy: 83.91% -> 79.84%     
client [67] (testset)   loss: 0.1659 -> 0.1634  accuracy: 95.22% -> 95.77%     
client [76] (testset)   loss: 0.1194 -> 0.1274  accuracy: 95.97% -> 96.19%     
client [37] (testset)   loss: 0.2370 -> 0.2565  accuracy: 90.87% -> 90.37%     
client [64] (testset)   loss: 0.3528 -> 0.3820  accuracy: 91.08% -> 90.32%     
client [58] (testset)   loss: 0.0762 -> 0.0838  accuracy: 98.61% -> 98.58%     
client [77] (testset)   loss: 0.1450 -> 0.1733  accuracy: 96.37% -> 96.24%     
client [12] (testset)   loss: 0.2189 -> 0.2389  accuracy: 94.40% -> 95.02%     
client [55] (testset)   loss: 0.3200 -> 0.3072  accuracy: 91.99% -> 92.30%     
client [89] (testset)   loss: 0.3312 -> 0.3578  accuracy: 90.26% -> 89.56%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 0.1272 -> 0.1346  accuracy: 96.03% -> 95.76%     
client [51] (testset)   loss: 0.2263 -> 0.2997  accuracy: 95.17% -> 90.16%     
client [8]  (testset)   loss: 0.2576 -> 0.2510  accuracy: 93.01% -> 92.54%     
client [18] (testset)   loss: 0.1504 -> 0.1758  accuracy: 95.83% -> 95.26%     
client [81] (testset)   loss: 0.3528 -> 0.3694  accuracy: 88.83% -> 86.70%     
client [94] (testset)   loss: 0.1491 -> 0.1449  accuracy: 96.25% -> 96.11%     
client [11] (testset)   loss: 0.1973 -> 0.2421  accuracy: 96.41% -> 94.90%     
client [95] (testset)   loss: 0.1548 -> 0.1685  accuracy: 96.03% -> 95.98%     
client [3]  (testset)   loss: 0.1497 -> 0.1408  accuracy: 96.68% -> 96.21%     
client [67] (testset)   loss: 0.1633 -> 0.1663  accuracy: 95.59% -> 95.22%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [79] (testset)   loss: 0.3525 -> 0.3582  accuracy: 92.00% -> 91.05%     
client [21] (testset)   loss: 0.1636 -> 0.1772  accuracy: 95.35% -> 94.80%     
client [88] (testset)   loss: 0.2273 -> 0.2806  accuracy: 93.17% -> 92.73%     
client [58] (testset)   loss: 0.0789 -> 0.0875  accuracy: 98.68% -> 98.58%     
client [11] (testset)   loss: 0.1921 -> 0.2207  accuracy: 95.72% -> 95.45%     
client [46] (testset)   loss: 0.0830 -> 0.0916  accuracy: 98.25% -> 98.25%     
client [13] (testset)   loss: 0.1304 -> 0.1356  accuracy: 97.78% -> 97.78%     
client [55] (testset)   loss: 0.2932 -> 0.3074  accuracy: 92.37% -> 91.12%     
client [75] (testset)   loss: 0.2381 -> 0.2594  accuracy: 93.18% -> 93.41%     
client [31] (testset)   loss: 0.2135 -> 0.2224  accuracy: 94.11% -> 93.36%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [7]  (testset)   loss: 0.1734 -> 0.1934  accuracy: 96.09% -> 96.02%     
client [57] (testset)   loss: 0.0622 -> 0.0643  accuracy: 98.39% -> 98.39%     
client [19] (testset)   loss: 0.1764 -> 0.2243  accuracy: 95.62% -> 94.26%     
client [43] (testset)   loss: 0.2884 -> 0.3141  accuracy: 91.02% -> 91.88%     
client [13] (testset)   loss: 0.1300 -> 0.1389  accuracy: 97.71% -> 97.71%     
client [10] (testset)   loss: 0.4302 -> 0.2459  accuracy: 85.17% -> 91.33%     
client [91] (testset)   loss: 0.0926 -> 0.0987  accuracy: 98.04% -> 98.15%     
client [64] (testset)   loss: 0.3712 -> 0.3941  accuracy: 91.84% -> 90.70%     
client [22] (testset)   loss: 0.2044 -> 0.2480  accuracy: 94.32% -> 94.23%     
client [82] (testset)   loss: 0.4261 -> 0.4310  accuracy: 80.98% -> 81.53%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 0.2433 -> 0.2640  accuracy: 94.04% -> 94.17%     
client [23] (testset)   loss: 0.3760 -> 0.3709  accuracy: 84.90% -> 84.09%     
client [88] (testset)   loss: 0.2409 -> 0.2653  accuracy: 91.94% -> 92.45%     
client [79] (testset)   loss: 0.3594 -> 0.3858  accuracy: 92.21% -> 91.89%     
client [98] (testset)   loss: 0.1277 -> 0.1423  accuracy: 96.65% -> 96.45%     
client [21] (testset)   loss: 0.1744 -> 0.1924  accuracy: 95.57% -> 94.48%     
client [92] (testset)   loss: 0.2485 -> 0.2682  accuracy: 93.76% -> 93.16%     
client [56] (testset)   loss: 0.1120 -> 0.1274  accuracy: 97.95% -> 97.92%     
client [52] (testset)   loss: 0.3585 -> 0.4566  accuracy: 90.28% -> 90.39%     
client [5]  (testset)   loss: 0.1720 -> 0.1860  accuracy: 95.34% -> 94.90%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 0.1727 -> 0.1760  accuracy: 95.59% -> 95.59%     
client [54] (testset)   loss: 0.2081 -> 0.2172  accuracy: 94.65% -> 94.65%     
client [14] (testset)   loss: 0.2628 -> 0.2907  accuracy: 94.80% -> 94.32%     
client [36] (testset)   loss: 0.1643 -> 0.1811  accuracy: 96.67% -> 95.76%     
client [99] (testset)   loss: 0.1589 -> 0.1688  accuracy: 95.90% -> 95.99%     
client [38] (testset)   loss: 0.1331 -> 0.1475  accuracy: 96.10% -> 96.10%     
client [30] (testset)   loss: 0.2596 -> 0.2923  accuracy: 93.85% -> 93.37%     
client [6]  (testset)   loss: 0.2521 -> 0.2512  accuracy: 95.32% -> 95.17%     
client [15] (testset)   loss: 0.2266 -> 0.2069  accuracy: 92.49% -> 91.86%     
client [53] (testset)   loss: 0.1815 -> 0.1938  accuracy: 97.06% -> 97.01%     
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [6]  (testset)   loss: 0.2258 -> 0.2983  accuracy: 95.10% -> 95.17%     
client [99] (testset)   loss: 0.1583 -> 0.1681  accuracy: 95.64% -> 96.02%     
client [83] (testset)   loss: 0.2035 -> 0.2646  accuracy: 95.49% -> 94.94%     
client [42] (testset)   loss: 0.2231 -> 0.2296  accuracy: 94.12% -> 94.00%     
client [34] (testset)   loss: 0.1189 -> 0.1361  accuracy: 97.06% -> 96.91%     
client [47] (testset)   loss: 0.2564 -> 0.3001  accuracy: 93.59% -> 92.31%     
client [15] (testset)   loss: 0.2325 -> 0.1901  accuracy: 91.93% -> 92.77%     
client [51] (testset)   loss: 0.2144 -> 0.2515  accuracy: 94.75% -> 94.08%     
client [55] (testset)   loss: 0.2810 -> 0.3172  accuracy: 91.85% -> 91.78%     
client [95] (testset)   loss: 0.1552 -> 0.1814  accuracy: 95.94% -> 95.51%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [15] (testset)   loss: 0.2231 -> 0.2164  accuracy: 93.13% -> 92.05%     
client [33] (testset)   loss: 0.0900 -> 0.1059  accuracy: 97.95% -> 97.72%     
client [71] (testset)   loss: 0.0998 -> 0.1182  accuracy: 97.49% -> 97.23%     
client [90] (testset)   loss: 0.2435 -> 0.2515  accuracy: 93.04% -> 93.37%     
client [57] (testset)   loss: 0.0617 -> 0.0631  accuracy: 98.50% -> 98.50%     
client [99] (testset)   loss: 0.1547 -> 0.1670  accuracy: 95.73% -> 95.96%     
client [78] (testset)   loss: 0.2273 -> 0.2347  accuracy: 93.33% -> 92.94%     
client [27] (testset)   loss: 0.1139 -> 0.1229  accuracy: 96.86% -> 96.95%     
client [36] (testset)   loss: 0.1453 -> 0.1720  accuracy: 96.56% -> 96.39%     
client [88] (testset)   loss: 0.2393 -> 0.2503  accuracy: 92.52% -> 92.73%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 0.2750 -> 0.4150  accuracy: 93.07% -> 92.17%     
client [16] (testset)   loss: 0.2304 -> 0.2679  accuracy: 93.92% -> 94.00%     
client [35] (testset)   loss: 0.0979 -> 0.1012  accuracy: 97.62% -> 97.47%     
client [80] (testset)   loss: 0.1136 -> 0.1294  accuracy: 97.41% -> 97.18%     
client [38] (testset)   loss: 0.1290 -> 0.1394  accuracy: 96.10% -> 96.31%     
client [68] (testset)   loss: 0.1888 -> 0.2051  accuracy: 95.24% -> 95.45%     
client [78] (testset)   loss: 0.2175 -> 0.2442  accuracy: 93.17% -> 92.55%     
client [64] (testset)   loss: 0.3677 -> 0.4093  accuracy: 91.08% -> 90.89%     
client [11] (testset)   loss: 0.1821 -> 0.2117  accuracy: 95.72% -> 95.79%     
client [82] (testset)   loss: 0.4526 -> 0.4250  accuracy: 81.97% -> 81.89%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 0.2591 -> 0.3003  accuracy: 94.28% -> 93.85%     
client [27] (testset)   loss: 0.1220 -> 0.1323  accuracy: 96.95% -> 96.77%     
client [74] (testset)   loss: 0.1641 -> 0.1853  accuracy: 96.58% -> 96.42%     
client [45] (testset)   loss: 0.3658 -> 0.3892  accuracy: 89.79% -> 89.01%     
client [6]  (testset)   loss: 0.2418 -> 0.2681  accuracy: 95.17% -> 95.03%     
client [36] (testset)   loss: 0.1610 -> 0.1809  accuracy: 96.79% -> 96.04%     
client [76] (testset)   loss: 0.1282 -> 0.1330  accuracy: 96.04% -> 96.04%     
client [63] (testset)   loss: 0.1525 -> 0.1457  accuracy: 97.20% -> 95.98%     
client [83] (testset)   loss: 0.2193 -> 0.2225  accuracy: 95.17% -> 95.45%     
client [86] (testset)   loss: 0.4096 -> 0.4715  accuracy: 90.16% -> 90.26%     
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 0.2160 -> 0.2246  accuracy: 95.40% -> 95.03%     
client [99] (testset)   loss: 0.1686 -> 0.1701  accuracy: 95.84% -> 95.41%     
client [74] (testset)   loss: 0.1660 -> 0.1916  accuracy: 96.31% -> 96.14%     
client [73] (testset)   loss: 0.2853 -> 0.3044  accuracy: 93.56% -> 92.95%     
client [29] (testset)   loss: 0.1864 -> 0.1975  accuracy: 93.83% -> 94.29%     
client [6]  (testset)   loss: 0.2422 -> 0.2720  accuracy: 95.10% -> 95.17%     
client [92] (testset)   loss: 0.2656 -> 0.2574  accuracy: 94.52% -> 93.96%     
client [61] (testset)   loss: 0.3789 -> 0.3556  accuracy: 88.30% -> 88.57%     
client [67] (testset)   loss: 0.1799 -> 0.2051  accuracy: 95.40% -> 95.77%     
client [21] (testset)   loss: 0.1837 -> 0.2192  accuracy: 95.57% -> 94.55%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [32] (testset)   loss: 0.2016 -> 0.2188  accuracy: 94.93% -> 94.85%     
client [83] (testset)   loss: 0.2176 -> 0.2413  accuracy: 95.40% -> 94.53%     
client [95] (testset)   loss: 0.1654 -> 0.1786  accuracy: 96.13% -> 95.84%     
client [61] (testset)   loss: 0.3904 -> 0.3899  accuracy: 88.84% -> 89.37%     
client [27] (testset)   loss: 0.1237 -> 0.1334  accuracy: 96.68% -> 96.64%     
client [25] (testset)   loss: 0.1035 -> 0.1110  accuracy: 96.05% -> 96.38%     
client [68] (testset)   loss: 0.2109 -> 0.2275  accuracy: 94.29% -> 94.07%     
client [34] (testset)   loss: 0.1208 -> 0.1377  accuracy: 97.06% -> 97.25%     
client [89] (testset)   loss: 0.3533 -> 0.3477  accuracy: 90.04% -> 89.67%     
client [71] (testset)   loss: 0.1169 -> 0.1410  accuracy: 97.53% -> 96.84%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 0.2425 -> 0.2684  accuracy: 93.10% -> 92.47%     
client [81] (testset)   loss: 0.3967 -> 0.4031  accuracy: 88.51% -> 87.95%     
client [51] (testset)   loss: 0.2272 -> 0.2729  accuracy: 94.75% -> 94.38%     
client [54] (testset)   loss: 0.1999 -> 0.2086  accuracy: 94.65% -> 94.53%     
client [65] (testset)   loss: 0.3067 -> 0.4101  accuracy: 91.33% -> 89.74%     
client [41] (testset)   loss: 0.2912 -> 0.2813  accuracy: 91.66% -> 91.54%     
client [11] (testset)   loss: 0.1985 -> 0.2149  accuracy: 95.66% -> 95.66%     
client [12] (testset)   loss: 0.2344 -> 0.2596  accuracy: 94.52% -> 94.27%     
client [85] (testset)   loss: 0.2292 -> 0.2561  accuracy: 94.94% -> 94.32%     
client [23] (testset)   loss: 0.3669 -> 0.3943  accuracy: 85.05% -> 83.52%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 0.2592 -> 0.2451  accuracy: 93.59% -> 94.16%     
client [65] (testset)   loss: 0.3378 -> 0.3123  accuracy: 91.47% -> 90.92%     
client [53] (testset)   loss: 0.1826 -> 0.1956  accuracy: 96.97% -> 96.97%     
client [72] (testset)   loss: 0.3411 -> 0.3569  accuracy: 93.39% -> 93.09%     
client [58] (testset)   loss: 0.0855 -> 0.0934  accuracy: 98.66% -> 98.58%     
client [7]  (testset)   loss: 0.2008 -> 0.2119  accuracy: 96.02% -> 96.02%     
client [59] (testset)   loss: 0.2514 -> 0.2744  accuracy: 92.43% -> 91.78%     
client [86] (testset)   loss: 0.4388 -> 0.4960  accuracy: 89.84% -> 90.26%     
client [39] (testset)   loss: 0.1673 -> 0.1778  accuracy: 96.79% -> 96.79%     
client [71] (testset)   loss: 0.1181 -> 0.1422  accuracy: 97.61% -> 97.53%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [7]  (testset)   loss: 0.1928 -> 0.2159  accuracy: 95.96% -> 95.89%     
client [99] (testset)   loss: 0.1617 -> 0.1851  accuracy: 95.96% -> 95.87%     
client [64] (testset)   loss: 0.4277 -> 0.4689  accuracy: 88.99% -> 88.43%     
client [17] (testset)   loss: 0.3327 -> 0.3323  accuracy: 93.34% -> 92.84%     
client [29] (testset)   loss: 0.1908 -> 0.2083  accuracy: 94.35% -> 93.83%     
client [37] (testset)   loss: 0.2603 -> 0.2828  accuracy: 92.67% -> 92.16%     
client [73] (testset)   loss: 0.2962 -> 0.3398  accuracy: 93.25% -> 92.82%     
client [93] (testset)   loss: 0.1921 -> 0.2048  accuracy: 95.27% -> 94.77%     
client [40] (testset)   loss: 0.1643 -> 0.1798  accuracy: 96.54% -> 96.34%     
client [76] (testset)   loss: 0.1266 -> 0.1363  accuracy: 95.97% -> 95.82%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 0.2192 -> 0.2437  accuracy: 94.02% -> 93.03%     
client [89] (testset)   loss: 0.3403 -> 0.3729  accuracy: 90.15% -> 89.23%     
client [77] (testset)   loss: 0.1635 -> 0.1798  accuracy: 96.24% -> 95.98%     
client [90] (testset)   loss: 0.2674 -> 0.3103  accuracy: 93.42% -> 91.18%     
client [26] (testset)   loss: 0.2336 -> 0.2404  accuracy: 92.18% -> 92.84%     
client [50] (testset)   loss: 0.0776 -> 0.0777  accuracy: 98.60% -> 98.72%     
client [70] (testset)   loss: 0.2782 -> 0.3201  accuracy: 92.68% -> 91.53%     
client [30] (testset)   loss: 0.2789 -> 0.3040  accuracy: 93.91% -> 93.85%     
client [41] (testset)   loss: 0.3137 -> 0.3327  accuracy: 91.35% -> 91.10%     
client [99] (testset)   loss: 0.1601 -> 0.1725  accuracy: 95.87% -> 95.84%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [70] (testset)   loss: 0.2821 -> 0.3552  accuracy: 92.30% -> 91.53%     
client [68] (testset)   loss: 0.2092 -> 0.2195  accuracy: 94.92% -> 95.34%     
client [52] (testset)   loss: 0.3756 -> 0.4047  accuracy: 90.50% -> 90.06%     
client [1]  (testset)   loss: 0.1952 -> 0.2308  accuracy: 94.71% -> 94.62%     
client [67] (testset)   loss: 0.1742 -> 0.1842  accuracy: 94.85% -> 94.49%     
client [2]  (testset)   loss: 0.1338 -> 0.1478  accuracy: 96.70% -> 96.70%     
client [35] (testset)   loss: 0.1040 -> 0.1147  accuracy: 97.71% -> 97.56%     
client [92] (testset)   loss: 0.2819 -> 0.3176  accuracy: 94.16% -> 94.06%     
client [64] (testset)   loss: 0.4059 -> 0.4763  accuracy: 90.13% -> 90.13%     
client [36] (testset)   loss: 0.1564 -> 0.1841  accuracy: 96.44% -> 96.39%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 0.3121 -> 0.3560  accuracy: 92.34% -> 92.55%     
client [6]  (testset)   loss: 0.2560 -> 0.2834  accuracy: 94.96% -> 94.54%     
client [12] (testset)   loss: 0.2376 -> 0.2595  accuracy: 95.14% -> 94.89%     
client [29] (testset)   loss: 0.1876 -> 0.2059  accuracy: 94.14% -> 93.88%     
client [55] (testset)   loss: 0.2954 -> 0.3047  accuracy: 91.01% -> 91.95%     
client [43] (testset)   loss: 0.2952 -> 0.3747  accuracy: 91.39% -> 90.65%     
client [9]  (testset)   loss: 0.1281 -> 0.1400  accuracy: 96.70% -> 96.96%     
client [77] (testset)   loss: 0.1699 -> 0.1891  accuracy: 95.73% -> 96.05%     
client [98] (testset)   loss: 0.1429 -> 0.1627  accuracy: 96.60% -> 96.86%     
client [78] (testset)   loss: 0.2612 -> 0.3086  accuracy: 93.33% -> 91.23%     
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [80] (testset)   loss: 0.1249 -> 0.1368  accuracy: 97.14% -> 96.96%     
client [92] (testset)   loss: 0.3136 -> 0.4197  accuracy: 94.16% -> 91.85%     
client [76] (testset)   loss: 0.1334 -> 0.1371  accuracy: 95.60% -> 96.19%     
client [63] (testset)   loss: 0.1551 -> 0.1705  accuracy: 96.61% -> 95.45%     
client [78] (testset)   loss: 0.2776 -> 0.3061  accuracy: 92.55% -> 91.00%     
client [25] (testset)   loss: 0.1098 -> 0.1107  accuracy: 96.27% -> 96.38%     
client [13] (testset)   loss: 0.1426 -> 0.1476  accuracy: 97.65% -> 97.65%     
client [58] (testset)   loss: 0.0862 -> 0.0998  accuracy: 98.58% -> 98.58%     
client [17] (testset)   loss: 0.3507 -> 0.3362  accuracy: 93.26% -> 93.26%     
client [38] (testset)   loss: 0.1542 -> 0.1626  accuracy: 96.21% -> 96.51%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 0.3179 -> 0.3517  accuracy: 93.54% -> 93.09%     
client [86] (testset)   loss: 0.4338 -> 0.4842  accuracy: 89.42% -> 89.95%     
client [82] (testset)   loss: 0.4460 -> 0.4740  accuracy: 82.19% -> 80.94%     
client [51] (testset)   loss: 0.2394 -> 0.2588  accuracy: 93.36% -> 94.32%     
client [96] (testset)   loss: 0.2165 -> 0.2478  accuracy: 96.35% -> 95.74%     
client [42] (testset)   loss: 0.2373 -> 0.2615  accuracy: 93.94% -> 93.58%     
client [13] (testset)   loss: 0.1342 -> 0.1438  accuracy: 97.65% -> 97.71%     
client [55] (testset)   loss: 0.2978 -> 0.3573  accuracy: 91.50% -> 92.06%     
client [12] (testset)   loss: 0.2425 -> 0.2640  accuracy: 94.02% -> 94.52%     
client [1]  (testset)   loss: 0.2014 -> 0.2231  accuracy: 94.81% -> 94.67%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 0.2252 -> 0.2456  accuracy: 94.81% -> 94.71%     
client [46] (testset)   loss: 0.1019 -> 0.1113  accuracy: 98.17% -> 97.40%     
client [23] (testset)   loss: 0.4243 -> 0.4327  accuracy: 84.67% -> 83.55%     
client [25] (testset)   loss: 0.1130 -> 0.1177  accuracy: 96.27% -> 96.27%     
client [41] (testset)   loss: 0.3512 -> 0.3156  accuracy: 90.85% -> 91.97%     
client [14] (testset)   loss: 0.2645 -> 0.2922  accuracy: 94.98% -> 94.62%     
client [58] (testset)   loss: 0.0848 -> 0.0953  accuracy: 98.61% -> 98.58%     
client [33] (testset)   loss: 0.1011 -> 0.1108  accuracy: 97.72% -> 97.54%     
client [62] (testset)   loss: 0.2156 -> 0.2415  accuracy: 96.13% -> 96.09%     
client [85] (testset)   loss: 0.2616 -> 0.2910  accuracy: 95.08% -> 94.49%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 0.1542 -> 0.1690  accuracy: 96.55% -> 96.81%     
client [70] (testset)   loss: 0.3226 -> 0.3569  accuracy: 92.68% -> 91.01%     
client [63] (testset)   loss: 0.1635 -> 0.1690  accuracy: 96.52% -> 96.78%     
client [65] (testset)   loss: 0.3538 -> 0.3411  accuracy: 91.75% -> 90.50%     
client [14] (testset)   loss: 0.2664 -> 0.3056  accuracy: 94.80% -> 94.80%     
client [73] (testset)   loss: 0.3174 -> 0.3487  accuracy: 93.19% -> 93.07%     
client [34] (testset)   loss: 0.1430 -> 0.1532  accuracy: 96.96% -> 97.11%     
client [69] (testset)   loss: 0.2975 -> 0.3137  accuracy: 93.59% -> 92.91%     
client [99] (testset)   loss: 0.1742 -> 0.1893  accuracy: 95.81% -> 95.67%     
client [46] (testset)   loss: 0.1037 -> 0.1143  accuracy: 98.09% -> 98.29%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [93] (testset)   loss: 0.2118 -> 0.2468  accuracy: 95.31% -> 95.34%     
client [99] (testset)   loss: 0.1784 -> 0.1893  accuracy: 95.84% -> 95.81%     
client [11] (testset)   loss: 0.2156 -> 0.2471  accuracy: 95.66% -> 95.59%     
client [81] (testset)   loss: 0.4554 -> 0.4769  accuracy: 88.09% -> 87.05%     
client [58] (testset)   loss: 0.0900 -> 0.0958  accuracy: 98.63% -> 98.56%     
client [89] (testset)   loss: 0.3887 -> 0.3965  accuracy: 89.12% -> 89.05%     
client [85] (testset)   loss: 0.2705 -> 0.2701  accuracy: 94.96% -> 94.77%     
client [45] (testset)   loss: 0.4086 -> 0.4335  accuracy: 88.71% -> 88.59%     
client [68] (testset)   loss: 0.2280 -> 0.2462  accuracy: 95.34% -> 94.50%     
client [8]  (testset)   loss: 0.3323 -> 0.3614  accuracy: 92.25% -> 91.02%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 0.1824 -> 0.2030  accuracy: 94.85% -> 94.30%     
client [72] (testset)   loss: 0.3385 -> 0.3644  accuracy: 93.09% -> 92.79%     
client [78] (testset)   loss: 0.2912 -> 0.3014  accuracy: 92.79% -> 92.63%     
client [1]  (testset)   loss: 0.2100 -> 0.2490  accuracy: 94.38% -> 94.10%     
client [83] (testset)   loss: 0.2365 -> 0.2870  accuracy: 95.17% -> 95.17%     
client [21] (testset)   loss: 0.2095 -> 0.2735  accuracy: 94.95% -> 93.68%     
client [44] (testset)   loss: 0.3349 -> 0.3653  accuracy: 92.98% -> 92.34%     
client [56] (testset)   loss: 0.1241 -> 0.1369  accuracy: 97.85% -> 97.78%     
client [27] (testset)   loss: 0.1246 -> 0.1394  accuracy: 96.77% -> 96.68%     
client [92] (testset)   loss: 0.3139 -> 0.3731  accuracy: 93.99% -> 94.34%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 0.2724 -> 0.3816  accuracy: 90.77% -> 86.15%     
client [39] (testset)   loss: 0.1648 -> 0.1783  accuracy: 96.55% -> 96.67%     
client [65] (testset)   loss: 0.3461 -> 0.3717  accuracy: 91.75% -> 91.26%     
client [26] (testset)   loss: 0.2650 -> 0.2910  accuracy: 93.54% -> 90.16%     
client [19] (testset)   loss: 0.2298 -> 0.3041  accuracy: 95.03% -> 94.64%     
client [68] (testset)   loss: 0.2295 -> 0.2541  accuracy: 94.71% -> 94.18%     
client [41] (testset)   loss: 0.3504 -> 0.4522  accuracy: 91.35% -> 89.34%     
client [50] (testset)   loss: 0.0859 -> 0.0921  accuracy: 98.48% -> 98.60%     
client [75] (testset)   loss: 0.2799 -> 0.3015  accuracy: 92.94% -> 92.94%     
client [81] (testset)   loss: 0.4665 -> 0.4705  accuracy: 87.99% -> 87.47%     
FedRep's average time taken by each global epoch: 0 min 15.81 sec.             
FedRep's total running time: 1 h 55 m 23 s.                                    
==================== FedRep Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.1823 -> 0.1816",                                    
                "accuracy": "94.68% -> 94.68%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.1946 -> 0.1952",                                    
                "accuracy": "94.73% -> 94.72%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.2159 -> 0.2142",                                    
                "accuracy": "94.52% -> 94.70%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.2173 -> 0.2168",                                    
                "accuracy": "94.43% -> 94.57%"                                 
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedRep Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 94.73% at epoch 200                                 
(test) after fine-tuning: 94.72% at epoch 200                                  
