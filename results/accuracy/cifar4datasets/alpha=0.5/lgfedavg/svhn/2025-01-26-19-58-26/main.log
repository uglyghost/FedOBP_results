==================== LG-FedAvg ====================                            
Experiment Arguments:                                                          
{
    'method': 'lgfedavg',
    'dataset': {
        'name': 'svhn',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'svhn-100clients-0%IID-Dir(0.5)-seed42',
        'alpha': 0.5,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'serial',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': None,
        'num_gpus': None,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 400,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 5,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'lgfedavg': {
        'num_global_layers': 1
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 0.8187 -> 0.8578  accuracy: 79.31% -> 78.02%     
client [81] (testset)   loss: 0.8252 -> 1.0134  accuracy: 75.38% -> 74.36%     
client [21] (testset)   loss: 0.8677 -> 0.5188  accuracy: 78.91% -> 85.82%     
client [68] (testset)   loss: 0.4847 -> 0.5691  accuracy: 88.32% -> 87.20%     
client [93] (testset)   loss: 0.5993 -> 0.7426  accuracy: 85.40% -> 85.16%     
client [31] (testset)   loss: 0.9145 -> 0.6301  accuracy: 77.27% -> 82.05%     
client [20] (testset)   loss: 0.8274 -> 0.9492  accuracy: 78.35% -> 81.96%     
client [59] (testset)   loss: 0.7124 -> 0.5384  accuracy: 79.90% -> 81.41%     
client [48] (testset)   loss: 0.9055 -> 0.9817  accuracy: 80.08% -> 80.83%     
client [34] (testset)   loss: 1.1052 -> 1.2339  accuracy: 71.93% -> 70.18%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 1.0036 -> 0.8034  accuracy: 69.52% -> 77.14%     
client [99] (testset)   loss: 0.6266 -> 0.7557  accuracy: 87.06% -> 86.67%     
client [67] (testset)   loss: 0.4121 -> 0.3961  accuracy: 87.75% -> 87.25%     
client [0]  (testset)   loss: 0.9632 -> 1.1922  accuracy: 79.79% -> 81.91%     
client [76] (testset)   loss: 0.6756 -> 0.7592  accuracy: 86.20% -> 85.58%     
client [41] (testset)   loss: 0.5575 -> 0.6871  accuracy: 83.58% -> 84.67%     
client [62] (testset)   loss: 0.8448 -> 0.7029  accuracy: 78.26% -> 80.10%     
client [2]  (testset)   loss: 0.8721 -> 0.5493  accuracy: 79.53% -> 86.58%     
client [14] (testset)   loss: 0.7426 -> 0.8725  accuracy: 85.60% -> 84.80%     
client [46] (testset)   loss: 0.8755 -> 0.8976  accuracy: 81.58% -> 80.00%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 0.7087 -> 0.7339  accuracy: 90.00% -> 90.00%     
client [68] (testset)   loss: 0.9151 -> 0.9264  accuracy: 88.04% -> 87.76%     
client [57] (testset)   loss: 1.2472 -> 1.3219  accuracy: 81.53% -> 81.25%     
client [17] (testset)   loss: 1.0146 -> 1.1078  accuracy: 77.18% -> 76.51%     
client [54] (testset)   loss: 1.5915 -> 1.6314  accuracy: 77.72% -> 78.80%     
client [23] (testset)   loss: 1.1592 -> 0.6829  accuracy: 79.57% -> 86.52%     
client [35] (testset)   loss: 1.1526 -> 1.1915  accuracy: 77.16% -> 78.40%     
client [59] (testset)   loss: 0.7601 -> 0.7879  accuracy: 81.91% -> 80.90%     
client [31] (testset)   loss: 0.9426 -> 0.9834  accuracy: 87.05% -> 87.05%     
client [9]  (testset)   loss: 0.8342 -> 0.8559  accuracy: 82.93% -> 83.90%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 1.0697 -> 1.1068  accuracy: 80.34% -> 80.77%     
client [33] (testset)   loss: 1.4431 -> 1.4651  accuracy: 77.50% -> 77.50%     
client [16] (testset)   loss: 0.8001 -> 0.8416  accuracy: 87.08% -> 86.52%     
client [44] (testset)   loss: 0.7473 -> 0.7483  accuracy: 84.60% -> 84.19%     
client [8]  (testset)   loss: 0.5542 -> 0.5554  accuracy: 91.79% -> 91.79%     
client [31] (testset)   loss: 1.0371 -> 1.0609  accuracy: 87.05% -> 86.82%     
client [47] (testset)   loss: 0.6409 -> 0.6754  accuracy: 87.12% -> 87.50%     
client [36] (testset)   loss: 0.8231 -> 0.8261  accuracy: 80.39% -> 82.35%     
client [20] (testset)   loss: 1.4292 -> 1.4210  accuracy: 82.47% -> 82.47%     
client [56] (testset)   loss: 1.0130 -> 1.0472  accuracy: 74.13% -> 75.12%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 1.0397 -> 1.0839  accuracy: 76.71% -> 76.71%     
client [60] (testset)   loss: 0.7851 -> 0.8161  accuracy: 82.51% -> 82.96%     
client [28] (testset)   loss: 2.3056 -> 2.3539  accuracy: 64.18% -> 64.18%     
client [25] (testset)   loss: 1.3181 -> 1.3858  accuracy: 77.78% -> 78.17%     
client [58] (testset)   loss: 1.0836 -> 1.1015  accuracy: 81.21% -> 80.91%     
client [44] (testset)   loss: 0.7704 -> 0.8366  accuracy: 84.19% -> 85.01%     
client [39] (testset)   loss: 0.7808 -> 0.8060  accuracy: 83.87% -> 83.33%     
client [29] (testset)   loss: 1.4779 -> 1.5094  accuracy: 77.14% -> 78.10%     
client [3]  (testset)   loss: 1.6953 -> 2.0257  accuracy: 70.59% -> 71.24%     
client [84] (testset)   loss: 1.2440 -> 1.2622  accuracy: 84.84% -> 84.55%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 0.7631 -> 0.7747  accuracy: 85.82% -> 86.55%     
client [84] (testset)   loss: 1.3138 -> 1.3229  accuracy: 84.55% -> 84.55%     
client [10] (testset)   loss: 1.0521 -> 1.0536  accuracy: 86.01% -> 86.01%     
client [36] (testset)   loss: 0.8890 -> 0.8953  accuracy: 78.43% -> 78.43%     
client [65] (testset)   loss: 0.6999 -> 0.7115  accuracy: 87.22% -> 87.22%     
client [81] (testset)   loss: 1.4352 -> 1.4556  accuracy: 77.95% -> 77.95%     
client [79] (testset)   loss: 1.2106 -> 1.2241  accuracy: 81.03% -> 80.46%     
client [42] (testset)   loss: 0.8732 -> 0.8877  accuracy: 85.40% -> 85.08%     
client [11] (testset)   loss: 1.2437 -> 1.2284  accuracy: 81.31% -> 80.98%     
client [96] (testset)   loss: 0.8060 -> 0.8216  accuracy: 85.89% -> 85.89%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 0.6106 -> 0.6105  accuracy: 91.28% -> 91.28%     
client [53] (testset)   loss: 1.1117 -> 1.1542  accuracy: 88.70% -> 88.70%     
client [52] (testset)   loss: 0.9395 -> 0.9527  accuracy: 86.35% -> 86.35%     
client [42] (testset)   loss: 0.9108 -> 0.9266  accuracy: 85.40% -> 84.76%     
client [69] (testset)   loss: 1.1128 -> 1.1236  accuracy: 77.14% -> 76.19%     
client [59] (testset)   loss: 0.9249 -> 0.9345  accuracy: 80.40% -> 80.40%     
client [7]  (testset)   loss: 1.1540 -> 1.1453  accuracy: 81.50% -> 82.00%     
client [26] (testset)   loss: 0.3848 -> 0.3908  accuracy: 91.58% -> 91.58%     
client [49] (testset)   loss: 0.5278 -> 0.5348  accuracy: 90.75% -> 91.33%     
client [98] (testset)   loss: 1.2108 -> 1.2164  accuracy: 84.68% -> 84.68%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 1.2332 -> 1.2410  accuracy: 84.68% -> 84.68%     
client [47] (testset)   loss: 0.7380 -> 0.7483  accuracy: 87.12% -> 86.93%     
client [21] (testset)   loss: 0.8060 -> 0.8200  accuracy: 86.55% -> 86.18%     
client [77] (testset)   loss: 1.3120 -> 1.3216  accuracy: 77.59% -> 77.59%     
client [95] (testset)   loss: 0.6455 -> 0.6504  accuracy: 89.02% -> 89.02%     
client [91] (testset)   loss: 1.7369 -> 1.7489  accuracy: 74.42% -> 74.42%     
client [14] (testset)   loss: 1.1572 -> 1.1671  accuracy: 85.07% -> 85.33%     
client [99] (testset)   loss: 1.0539 -> 1.0680  accuracy: 86.27% -> 86.27%     
client [20] (testset)   loss: 1.6153 -> 1.6136  accuracy: 82.47% -> 82.47%     
client [39] (testset)   loss: 0.8728 -> 0.8812  accuracy: 83.87% -> 83.87%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 0.9728 -> 0.9822  accuracy: 86.35% -> 86.35%     
client [62] (testset)   loss: 1.1957 -> 1.2023  accuracy: 81.77% -> 82.44%     
client [71] (testset)   loss: 2.5995 -> 2.6209  accuracy: 65.27% -> 65.27%     
client [97] (testset)   loss: 1.4969 -> 1.5052  accuracy: 80.43% -> 80.43%     
client [30] (testset)   loss: 0.8351 -> 0.8432  accuracy: 87.30% -> 87.30%     
client [88] (testset)   loss: 0.7394 -> 0.7484  accuracy: 87.86% -> 87.86%     
client [60] (testset)   loss: 0.9596 -> 0.9702  accuracy: 82.96% -> 82.96%     
client [82] (testset)   loss: 0.9452 -> 0.9507  accuracy: 82.09% -> 82.09%     
client [91] (testset)   loss: 1.7819 -> 1.7944  accuracy: 74.42% -> 74.42%     
client [57] (testset)   loss: 1.6370 -> 1.6632  accuracy: 80.97% -> 81.53%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 1.2726 -> 1.2760  accuracy: 86.82% -> 86.82%     
client [15] (testset)   loss: 1.2548 -> 1.2666  accuracy: 84.37% -> 84.64%     
client [71] (testset)   loss: 2.6403 -> 2.6532  accuracy: 65.27% -> 65.27%     
client [97] (testset)   loss: 1.5286 -> 1.5344  accuracy: 80.43% -> 80.00%     
client [53] (testset)   loss: 1.2587 -> 1.2624  accuracy: 88.70% -> 88.70%     
client [77] (testset)   loss: 1.3443 -> 1.3483  accuracy: 77.16% -> 77.59%     
client [76] (testset)   loss: 1.0349 -> 1.0409  accuracy: 85.89% -> 85.58%     
client [79] (testset)   loss: 1.3116 -> 1.3189  accuracy: 81.03% -> 81.03%     
client [28] (testset)   loss: 2.7571 -> 2.7808  accuracy: 64.18% -> 64.18%     
client [99] (testset)   loss: 1.1034 -> 1.1142  accuracy: 86.27% -> 86.27%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 1.5520 -> 1.5567  accuracy: 80.00% -> 80.00%     
client [86] (testset)   loss: 1.2777 -> 1.2989  accuracy: 80.53% -> 80.53%     
client [34] (testset)   loss: 1.9622 -> 1.9683  accuracy: 71.05% -> 71.05%     
client [73] (testset)   loss: 0.6846 -> 0.6895  accuracy: 88.85% -> 88.85%     
client [5]  (testset)   loss: 1.5477 -> 1.5544  accuracy: 89.19% -> 89.19%     
client [96] (testset)   loss: 0.9234 -> 0.9292  accuracy: 85.89% -> 85.89%     
client [22] (testset)   loss: 1.0214 -> 1.0328  accuracy: 81.36% -> 81.36%     
client [60] (testset)   loss: 1.0096 -> 1.0146  accuracy: 82.96% -> 82.96%     
client [66] (testset)   loss: 0.6672 -> 0.6741  accuracy: 89.30% -> 89.30%     
client [83] (testset)   loss: 1.2103 -> 1.2136  accuracy: 80.50% -> 80.50%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 1.0754 -> 1.0783  accuracy: 85.58% -> 85.28%     
client [65] (testset)   loss: 0.7597 -> 0.7652  accuracy: 87.22% -> 86.84%     
client [95] (testset)   loss: 0.6856 -> 0.6890  accuracy: 89.02% -> 89.02%     
client [17] (testset)   loss: 1.3982 -> 1.4076  accuracy: 76.51% -> 78.52%     
client [8]  (testset)   loss: 0.6493 -> 0.6496  accuracy: 91.28% -> 91.28%     
client [35] (testset)   loss: 1.6269 -> 1.6354  accuracy: 79.01% -> 79.01%     
client [98] (testset)   loss: 1.3032 -> 1.3032  accuracy: 84.68% -> 84.68%     
client [53] (testset)   loss: 1.2982 -> 1.3072  accuracy: 88.70% -> 88.70%     
client [43] (testset)   loss: 2.1001 -> 2.1103  accuracy: 70.95% -> 72.30%     
client [64] (testset)   loss: 1.3325 -> 1.3456  accuracy: 79.49% -> 79.91%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 0.8547 -> 0.8621  accuracy: 86.55% -> 86.55%     
client [88] (testset)   loss: 0.8131 -> 0.8190  accuracy: 87.50% -> 87.50%     
client [38] (testset)   loss: 1.1936 -> 1.2009  accuracy: 82.46% -> 82.46%     
client [3]  (testset)   loss: 2.7007 -> 2.7196  accuracy: 69.28% -> 69.28%     
client [5]  (testset)   loss: 1.5744 -> 1.5881  accuracy: 89.19% -> 89.19%     
client [41] (testset)   loss: 1.0350 -> 1.0450  accuracy: 84.31% -> 84.31%     
client [7]  (testset)   loss: 1.2283 -> 1.2383  accuracy: 81.50% -> 81.50%     
client [37] (testset)   loss: 1.6978 -> 1.7057  accuracy: 76.96% -> 76.96%     
client [45] (testset)   loss: 1.4807 -> 1.4892  accuracy: 81.74% -> 81.33%     
client [47] (testset)   loss: 0.7965 -> 0.8025  accuracy: 86.93% -> 86.93%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 1.0687 -> 1.0743  accuracy: 85.67% -> 85.96%     
client [11] (testset)   loss: 1.4122 -> 1.4144  accuracy: 80.66% -> 80.98%     
client [37] (testset)   loss: 1.7265 -> 1.7337  accuracy: 76.96% -> 76.96%     
client [41] (testset)   loss: 1.0509 -> 1.0572  accuracy: 84.31% -> 84.31%     
client [95] (testset)   loss: 0.7047 -> 0.7066  accuracy: 89.02% -> 89.02%     
client [53] (testset)   loss: 1.3207 -> 1.3321  accuracy: 88.70% -> 88.70%     
client [22] (testset)   loss: 1.0547 -> 1.0630  accuracy: 81.36% -> 81.36%     
client [25] (testset)   loss: 1.6813 -> 1.6936  accuracy: 78.17% -> 78.17%     
client [69] (testset)   loss: 1.2271 -> 1.2307  accuracy: 74.29% -> 74.29%     
client [46] (testset)   loss: 1.2047 -> 1.2098  accuracy: 77.89% -> 77.89%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 0.8258 -> 0.8302  accuracy: 86.93% -> 86.74%     
client [69] (testset)   loss: 1.2410 -> 1.2442  accuracy: 75.24% -> 75.24%     
client [82] (testset)   loss: 0.9985 -> 1.0027  accuracy: 81.34% -> 80.60%     
client [45] (testset)   loss: 1.5212 -> 1.5291  accuracy: 81.33% -> 81.33%     
client [7]  (testset)   loss: 1.2505 -> 1.2549  accuracy: 81.50% -> 81.50%     
client [50] (testset)   loss: 1.2036 -> 1.2170  accuracy: 83.12% -> 83.12%     
client [35] (testset)   loss: 1.6705 -> 1.6801  accuracy: 79.01% -> 79.01%     
client [24] (testset)   loss: 0.9613 -> 0.9626  accuracy: 90.00% -> 90.00%     
client [15] (testset)   loss: 1.3490 -> 1.3583  accuracy: 84.37% -> 84.37%     
client [58] (testset)   loss: 1.2767 -> 1.2804  accuracy: 80.30% -> 80.30%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 1.5680 -> 1.5692  accuracy: 80.45% -> 80.08%     
client [76] (testset)   loss: 1.1127 -> 1.1158  accuracy: 85.28% -> 85.28%     
client [67] (testset)   loss: 0.5452 -> 0.5467  accuracy: 87.75% -> 87.75%     
client [37] (testset)   loss: 1.7624 -> 1.7634  accuracy: 76.96% -> 76.96%     
client [58] (testset)   loss: 1.2886 -> 1.2917  accuracy: 80.30% -> 80.30%     
client [64] (testset)   loss: 1.3953 -> 1.4033  accuracy: 79.49% -> 79.49%     
client [77] (testset)   loss: 1.4103 -> 1.4147  accuracy: 77.59% -> 77.16%     
client [55] (testset)   loss: 0.5294 -> 0.5267  accuracy: 92.20% -> 92.20%     
client [12] (testset)   loss: 0.8653 -> 0.8697  accuracy: 88.57% -> 88.35%     
client [89] (testset)   loss: 1.3333 -> 1.3368  accuracy: 78.01% -> 78.72%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 1.5301 -> 1.5336  accuracy: 83.97% -> 83.97%     
client [51] (testset)   loss: 0.6160 -> 0.6163  accuracy: 82.67% -> 82.67%     
client [8]  (testset)   loss: 0.6754 -> 0.6753  accuracy: 91.28% -> 91.28%     
client [18] (testset)   loss: 1.7397 -> 1.7524  accuracy: 80.20% -> 80.20%     
client [94] (testset)   loss: 1.2118 -> 1.2174  accuracy: 82.04% -> 82.04%     
client [81] (testset)   loss: 1.7074 -> 1.7146  accuracy: 77.95% -> 77.95%     
client [3]  (testset)   loss: 2.8234 -> 2.8334  accuracy: 69.28% -> 69.28%     
client [11] (testset)   loss: 1.4575 -> 1.4635  accuracy: 80.98% -> 80.98%     
client [95] (testset)   loss: 0.7297 -> 0.7316  accuracy: 89.02% -> 89.02%     
client [67] (testset)   loss: 0.5491 -> 0.5501  accuracy: 87.75% -> 87.75%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 0.8901 -> 0.8953  accuracy: 86.55% -> 86.55%     
client [79] (testset)   loss: 1.4470 -> 1.4511  accuracy: 81.03% -> 80.46%     
client [58] (testset)   loss: 1.3094 -> 1.3119  accuracy: 80.30% -> 80.30%     
client [88] (testset)   loss: 0.8520 -> 0.8549  accuracy: 87.14% -> 87.14%     
client [46] (testset)   loss: 1.2369 -> 1.2417  accuracy: 78.42% -> 78.42%     
client [11] (testset)   loss: 1.4695 -> 1.4691  accuracy: 80.98% -> 80.98%     
client [55] (testset)   loss: 0.5399 -> 0.5417  accuracy: 92.20% -> 92.20%     
client [13] (testset)   loss: 1.5325 -> 1.5385  accuracy: 79.58% -> 79.58%     
client [31] (testset)   loss: 1.3441 -> 1.3461  accuracy: 86.82% -> 86.82%     
client [75] (testset)   loss: 1.9458 -> 1.9558  accuracy: 76.25% -> 76.25%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 1.3126 -> 1.3156  accuracy: 83.33% -> 83.33%     
client [7]  (testset)   loss: 1.3035 -> 1.3009  accuracy: 82.00% -> 82.00%     
client [57] (testset)   loss: 1.8773 -> 1.8877  accuracy: 81.53% -> 80.97%     
client [13] (testset)   loss: 1.5492 -> 1.5562  accuracy: 79.58% -> 79.58%     
client [43] (testset)   loss: 2.2278 -> 2.2361  accuracy: 70.95% -> 70.95%     
client [91] (testset)   loss: 1.9313 -> 1.9380  accuracy: 74.42% -> 74.42%     
client [10] (testset)   loss: 1.2251 -> 1.2276  accuracy: 85.49% -> 85.49%     
client [64] (testset)   loss: 1.4453 -> 1.4487  accuracy: 79.06% -> 79.06%     
client [82] (testset)   loss: 1.0337 -> 1.0355  accuracy: 80.60% -> 80.60%     
client [22] (testset)   loss: 1.1129 -> 1.1173  accuracy: 81.36% -> 81.36%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 1.7646 -> 1.7643  accuracy: 82.99% -> 82.99%     
client [23] (testset)   loss: 1.1571 -> 1.1657  accuracy: 86.96% -> 86.96%     
client [88] (testset)   loss: 0.8614 -> 0.8658  accuracy: 87.14% -> 87.14%     
client [98] (testset)   loss: 1.3798 -> 1.3812  accuracy: 84.68% -> 84.68%     
client [79] (testset)   loss: 1.4696 -> 1.4725  accuracy: 80.46% -> 80.46%     
client [21] (testset)   loss: 0.9052 -> 0.9070  accuracy: 86.55% -> 86.55%     
client [92] (testset)   loss: 1.3483 -> 1.3518  accuracy: 79.31% -> 79.31%     
client [56] (testset)   loss: 1.3754 -> 1.3795  accuracy: 75.62% -> 75.62%     
client [5]  (testset)   loss: 1.6641 -> 1.6687  accuracy: 89.19% -> 89.19%     
client [52] (testset)   loss: 1.1153 -> 1.1193  accuracy: 86.67% -> 86.67%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 0.5692 -> 0.5709  accuracy: 87.75% -> 87.75%     
client [54] (testset)   loss: 2.1807 -> 2.1825  accuracy: 78.26% -> 78.26%     
client [14] (testset)   loss: 1.3383 -> 1.3428  accuracy: 85.60% -> 85.33%     
client [99] (testset)   loss: 1.2498 -> 1.2544  accuracy: 85.88% -> 85.88%     
client [36] (testset)   loss: 1.0278 -> 1.0285  accuracy: 76.47% -> 76.47%     
client [30] (testset)   loss: 0.9393 -> 0.9410  accuracy: 87.62% -> 87.62%     
client [38] (testset)   loss: 1.2787 -> 1.2828  accuracy: 82.23% -> 82.23%     
client [15] (testset)   loss: 1.4086 -> 1.4165  accuracy: 84.37% -> 84.10%     
client [6]  (testset)   loss: 2.0452 -> 2.0534  accuracy: 81.31% -> 81.31%     
client [53] (testset)   loss: 1.4335 -> 1.4359  accuracy: 88.14% -> 88.14%     
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 1.2670 -> 1.2724  accuracy: 85.88% -> 85.88%     
client [6]  (testset)   loss: 2.0588 -> 2.0658  accuracy: 81.31% -> 81.31%     
client [83] (testset)   loss: 1.3226 -> 1.3247  accuracy: 80.50% -> 80.50%     
client [42] (testset)   loss: 1.0840 -> 1.0902  accuracy: 84.13% -> 84.44%     
client [34] (testset)   loss: 2.0951 -> 2.0961  accuracy: 70.18% -> 70.18%     
client [15] (testset)   loss: 1.4200 -> 1.4245  accuracy: 84.10% -> 83.83%     
client [47] (testset)   loss: 0.8815 -> 0.8809  accuracy: 86.93% -> 86.93%     
client [55] (testset)   loss: 0.5527 -> 0.5522  accuracy: 91.71% -> 91.71%     
client [51] (testset)   loss: 0.6286 -> 0.6290  accuracy: 82.67% -> 82.67%     
client [95] (testset)   loss: 0.7516 -> 0.7530  accuracy: 89.02% -> 89.02%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 2.8877 -> 2.8936  accuracy: 65.27% -> 65.27%     
client [15] (testset)   loss: 1.4278 -> 1.4353  accuracy: 83.83% -> 83.83%     
client [33] (testset)   loss: 1.7889 -> 1.7903  accuracy: 77.50% -> 77.50%     
client [99] (testset)   loss: 1.2812 -> 1.2846  accuracy: 85.88% -> 85.88%     
client [90] (testset)   loss: 1.5324 -> 1.5373  accuracy: 82.99% -> 82.69%     
client [57] (testset)   loss: 1.9651 -> 1.9734  accuracy: 80.97% -> 80.68%     
client [27] (testset)   loss: 1.9763 -> 1.9779  accuracy: 78.82% -> 78.82%     
client [78] (testset)   loss: 1.0214 -> 1.0253  accuracy: 87.50% -> 87.50%     
client [36] (testset)   loss: 1.0362 -> 1.0372  accuracy: 76.47% -> 76.47%     
client [88] (testset)   loss: 0.8798 -> 0.8826  accuracy: 87.14% -> 87.50%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 1.1276 -> 1.1255  accuracy: 89.71% -> 89.71%     
client [35] (testset)   loss: 1.7622 -> 1.7729  accuracy: 79.01% -> 79.01%     
client [16] (testset)   loss: 1.1688 -> 1.1712  accuracy: 85.96% -> 85.96%     
client [80] (testset)   loss: 1.5546 -> 1.5567  accuracy: 83.51% -> 83.51%     
client [38] (testset)   loss: 1.3021 -> 1.3062  accuracy: 82.23% -> 82.23%     
client [78] (testset)   loss: 1.0331 -> 1.0390  accuracy: 87.50% -> 87.50%     
client [68] (testset)   loss: 1.2256 -> 1.2254  accuracy: 87.48% -> 87.48%     
client [11] (testset)   loss: 1.5222 -> 1.5280  accuracy: 80.66% -> 80.98%     
client [64] (testset)   loss: 1.4913 -> 1.4975  accuracy: 79.06% -> 79.06%     
client [82] (testset)   loss: 1.0656 -> 1.0678  accuracy: 80.60% -> 80.60%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 0.9651 -> 0.9673  accuracy: 87.62% -> 87.62%     
client [27] (testset)   loss: 1.9896 -> 1.9914  accuracy: 78.82% -> 78.82%     
client [74] (testset)   loss: 1.3384 -> 1.3412  accuracy: 84.34% -> 84.34%     
client [45] (testset)   loss: 1.6288 -> 1.6334  accuracy: 82.16% -> 82.16%     
client [6]  (testset)   loss: 2.0900 -> 2.0888  accuracy: 80.84% -> 80.84%     
client [36] (testset)   loss: 1.0440 -> 1.0443  accuracy: 76.47% -> 76.47%     
client [63] (testset)   loss: 1.1476 -> 1.1515  accuracy: 85.66% -> 85.66%     
client [76] (testset)   loss: 1.1788 -> 1.1802  accuracy: 85.28% -> 85.28%     
client [83] (testset)   loss: 1.3440 -> 1.3445  accuracy: 80.50% -> 80.50%     
client [86] (testset)   loss: 1.5081 -> 1.5128  accuracy: 80.53% -> 80.53%     
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 1.3477 -> 1.3511  accuracy: 80.50% -> 80.50%     
client [99] (testset)   loss: 1.3008 -> 1.3031  accuracy: 85.88% -> 85.88%     
client [74] (testset)   loss: 1.3468 -> 1.3485  accuracy: 84.34% -> 84.34%     
client [73] (testset)   loss: 0.7685 -> 0.7707  accuracy: 88.85% -> 88.85%     
client [29] (testset)   loss: 1.8801 -> 1.8854  accuracy: 78.10% -> 78.10%     
client [92] (testset)   loss: 1.3931 -> 1.3976  accuracy: 79.31% -> 79.31%     
client [6]  (testset)   loss: 2.0964 -> 2.1014  accuracy: 81.31% -> 80.84%     
client [61] (testset)   loss: 1.1355 -> 1.1413  accuracy: 83.19% -> 83.19%     
client [21] (testset)   loss: 0.9333 -> 0.9362  accuracy: 86.55% -> 86.55%     
client [67] (testset)   loss: 0.5837 -> 0.5848  accuracy: 87.25% -> 86.76%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 1.3544 -> 1.3573  accuracy: 80.50% -> 80.50%     
client [32] (testset)   loss: 0.9245 -> 0.9237  accuracy: 80.88% -> 80.88%     
client [95] (testset)   loss: 0.7654 -> 0.7662  accuracy: 89.02% -> 89.02%     
client [61] (testset)   loss: 1.1553 -> 1.1603  accuracy: 83.63% -> 83.19%     
client [27] (testset)   loss: 2.0023 -> 2.0050  accuracy: 78.82% -> 78.82%     
client [25] (testset)   loss: 1.8309 -> 1.8369  accuracy: 78.17% -> 78.17%     
client [68] (testset)   loss: 1.2391 -> 1.2409  accuracy: 87.48% -> 87.48%     
client [34] (testset)   loss: 2.1303 -> 2.1331  accuracy: 70.18% -> 70.18%     
client [71] (testset)   loss: 2.9561 -> 2.9604  accuracy: 65.27% -> 65.27%     
client [89] (testset)   loss: 1.3996 -> 1.3968  accuracy: 78.72% -> 78.72%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 1.0706 -> 1.0735  accuracy: 87.50% -> 87.50%     
client [81] (testset)   loss: 1.8265 -> 1.8301  accuracy: 77.95% -> 77.95%     
client [51] (testset)   loss: 0.6373 -> 0.6375  accuracy: 82.67% -> 82.67%     
client [54] (testset)   loss: 2.2356 -> 2.2376  accuracy: 78.26% -> 78.26%     
client [65] (testset)   loss: 0.8524 -> 0.8541  accuracy: 86.84% -> 86.84%     
client [41] (testset)   loss: 1.1775 -> 1.1798  accuracy: 83.94% -> 83.94%     
client [11] (testset)   loss: 1.5500 -> 1.5536  accuracy: 80.98% -> 80.66%     
client [85] (testset)   loss: 0.9302 -> 0.9323  accuracy: 87.97% -> 87.97%     
client [12] (testset)   loss: 0.9178 -> 0.9196  accuracy: 88.35% -> 88.35%     
client [23] (testset)   loss: 1.2364 -> 1.2415  accuracy: 86.96% -> 86.96%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 1.1891 -> 1.1911  accuracy: 86.24% -> 85.96%     
client [65] (testset)   loss: 0.8572 -> 0.8597  accuracy: 86.84% -> 86.84%     
client [53] (testset)   loss: 1.4974 -> 1.5018  accuracy: 88.14% -> 88.14%     
client [58] (testset)   loss: 1.3694 -> 1.3714  accuracy: 80.30% -> 80.30%     
client [72] (testset)   loss: 1.0777 -> 1.0807  accuracy: 83.58% -> 83.58%     
client [7]  (testset)   loss: 1.3705 -> 1.3756  accuracy: 81.50% -> 81.50%     
client [71] (testset)   loss: 2.9724 -> 2.9786  accuracy: 65.27% -> 65.27%     
client [59] (testset)   loss: 1.1305 -> 1.1321  accuracy: 81.41% -> 81.41%     
client [86] (testset)   loss: 1.5446 -> 1.5492  accuracy: 80.53% -> 80.53%     
client [39] (testset)   loss: 1.0393 -> 1.0408  accuracy: 83.33% -> 83.33%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 1.3226 -> 1.3249  accuracy: 85.88% -> 85.88%     
client [7]  (testset)   loss: 1.3791 -> 1.3839  accuracy: 81.50% -> 81.50%     
client [17] (testset)   loss: 1.6285 -> 1.6325  accuracy: 77.85% -> 77.85%     
client [64] (testset)   loss: 1.5414 -> 1.5451  accuracy: 79.06% -> 79.06%     
client [37] (testset)   loss: 1.8897 -> 1.8935  accuracy: 77.49% -> 77.49%     
client [29] (testset)   loss: 1.9192 -> 1.9234  accuracy: 78.10% -> 78.10%     
client [93] (testset)   loss: 1.3837 -> 1.3855  accuracy: 85.40% -> 85.40%     
client [73] (testset)   loss: 0.7838 -> 0.7853  accuracy: 88.51% -> 89.19%     
client [40] (testset)   loss: 1.2706 -> 1.2735  accuracy: 85.79% -> 85.52%     
client [76] (testset)   loss: 1.1998 -> 1.2019  accuracy: 85.28% -> 85.28%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 1.4202 -> 1.4224  accuracy: 86.82% -> 86.82%     
client [89] (testset)   loss: 1.4152 -> 1.4174  accuracy: 78.72% -> 78.72%     
client [77] (testset)   loss: 1.5217 -> 1.5244  accuracy: 77.16% -> 77.16%     
client [90] (testset)   loss: 1.6152 -> 1.6185  accuracy: 82.39% -> 82.69%     
client [26] (testset)   loss: 0.4722 -> 0.4738  accuracy: 91.58% -> 91.58%     
client [50] (testset)   loss: 1.3583 -> 1.3620  accuracy: 82.47% -> 82.47%     
client [30] (testset)   loss: 0.9893 -> 0.9915  accuracy: 87.62% -> 87.62%     
client [70] (testset)   loss: 1.1518 -> 1.1482  accuracy: 89.71% -> 89.71%     
client [41] (testset)   loss: 1.1957 -> 1.1974  accuracy: 83.94% -> 83.94%     
client [99] (testset)   loss: 1.3279 -> 1.3309  accuracy: 85.88% -> 85.88%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 1.2668 -> 1.2687  accuracy: 87.48% -> 87.48%     
client [70] (testset)   loss: 1.1531 -> 1.1532  accuracy: 89.71% -> 89.71%     
client [52] (testset)   loss: 1.1820 -> 1.1846  accuracy: 86.35% -> 86.35%     
client [1]  (testset)   loss: 1.6123 -> 1.6198  accuracy: 79.86% -> 79.86%     
client [2]  (testset)   loss: 1.0855 -> 1.0897  accuracy: 87.25% -> 87.25%     
client [67] (testset)   loss: 0.6005 -> 0.6018  accuracy: 86.27% -> 86.76%     
client [92] (testset)   loss: 1.4501 -> 1.4524  accuracy: 80.00% -> 80.00%     
client [35] (testset)   loss: 1.8178 -> 1.8224  accuracy: 79.01% -> 79.01%     
client [36] (testset)   loss: 1.0677 -> 1.0685  accuracy: 76.47% -> 74.51%     
client [64] (testset)   loss: 1.5521 -> 1.5544  accuracy: 79.06% -> 79.06%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 1.2001 -> 1.2028  accuracy: 85.01% -> 85.01%     
client [6]  (testset)   loss: 2.1517 -> 2.1553  accuracy: 81.31% -> 81.31%     
client [12] (testset)   loss: 0.9339 -> 0.9350  accuracy: 88.35% -> 88.35%     
client [55] (testset)   loss: 0.5753 -> 0.5772  accuracy: 92.20% -> 92.20%     
client [29] (testset)   loss: 1.9456 -> 1.9498  accuracy: 78.10% -> 78.10%     
client [9]  (testset)   loss: 1.2550 -> 1.2534  accuracy: 83.90% -> 83.90%     
client [43] (testset)   loss: 2.3783 -> 2.3820  accuracy: 70.95% -> 70.95%     
client [77] (testset)   loss: 1.5291 -> 1.5308  accuracy: 77.16% -> 77.16%     
client [98] (testset)   loss: 1.4644 -> 1.4635  accuracy: 84.68% -> 84.68%     
client [78] (testset)   loss: 1.0910 -> 1.0938  accuracy: 87.50% -> 87.50%     
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 1.4606 -> 1.4634  accuracy: 80.00% -> 80.00%     
client [80] (testset)   loss: 1.5981 -> 1.6006  accuracy: 83.51% -> 83.51%     
client [63] (testset)   loss: 1.1955 -> 1.1980  accuracy: 85.66% -> 85.66%     
client [76] (testset)   loss: 1.2144 -> 1.2168  accuracy: 85.28% -> 85.28%     
client [78] (testset)   loss: 1.0955 -> 1.0988  accuracy: 87.50% -> 87.22%     
client [25] (testset)   loss: 1.8805 -> 1.8850  accuracy: 78.17% -> 78.17%     
client [58] (testset)   loss: 1.3897 -> 1.3911  accuracy: 80.61% -> 80.61%     
client [13] (testset)   loss: 1.6494 -> 1.6533  accuracy: 79.58% -> 79.58%     
client [17] (testset)   loss: 1.6591 -> 1.6622  accuracy: 77.85% -> 77.85%     
client [38] (testset)   loss: 1.3847 -> 1.3875  accuracy: 82.23% -> 82.23%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 1.1050 -> 1.1071  accuracy: 83.58% -> 83.58%     
client [82] (testset)   loss: 1.1094 -> 1.1112  accuracy: 80.60% -> 80.60%     
client [86] (testset)   loss: 1.5950 -> 1.5983  accuracy: 80.53% -> 80.53%     
client [51] (testset)   loss: 0.6485 -> 0.6480  accuracy: 82.67% -> 82.67%     
client [96] (testset)   loss: 1.0517 -> 1.0527  accuracy: 86.29% -> 86.29%     
client [42] (testset)   loss: 1.1494 -> 1.1510  accuracy: 84.44% -> 84.44%     
client [55] (testset)   loss: 0.5832 -> 0.5846  accuracy: 91.71% -> 91.71%     
client [13] (testset)   loss: 1.6593 -> 1.6631  accuracy: 79.58% -> 79.58%     
client [1]  (testset)   loss: 1.6370 -> 1.6422  accuracy: 79.86% -> 79.17%     
client [12] (testset)   loss: 0.9378 -> 0.9396  accuracy: 88.13% -> 88.13%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 1.2800 -> 1.2813  accuracy: 87.48% -> 87.48%     
client [23] (testset)   loss: 1.2858 -> 1.2888  accuracy: 86.96% -> 86.96%     
client [46] (testset)   loss: 1.3352 -> 1.3367  accuracy: 78.95% -> 78.95%     
client [41] (testset)   loss: 1.2172 -> 1.2191  accuracy: 83.94% -> 83.94%     
client [25] (testset)   loss: 1.9067 -> 1.9107  accuracy: 78.17% -> 78.17%     
client [58] (testset)   loss: 1.3964 -> 1.3982  accuracy: 80.61% -> 80.61%     
client [14] (testset)   loss: 1.4187 -> 1.4204  accuracy: 85.60% -> 85.87%     
client [33] (testset)   loss: 1.8523 -> 1.8551  accuracy: 77.50% -> 77.50%     
client [85] (testset)   loss: 0.9586 -> 0.9601  accuracy: 87.97% -> 87.97%     
client [62] (testset)   loss: 1.3825 -> 1.3854  accuracy: 82.27% -> 82.27%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 1.4858 -> 1.4872  accuracy: 84.68% -> 84.68%     
client [63] (testset)   loss: 1.2088 -> 1.2117  accuracy: 85.26% -> 85.66%     
client [70] (testset)   loss: 1.1684 -> 1.1690  accuracy: 89.71% -> 89.71%     
client [65] (testset)   loss: 0.8773 -> 0.8795  accuracy: 86.84% -> 86.84%     
client [14] (testset)   loss: 1.4273 -> 1.4299  accuracy: 85.87% -> 85.87%     
client [73] (testset)   loss: 0.7996 -> 0.8009  accuracy: 88.85% -> 88.85%     
client [34] (testset)   loss: 2.1943 -> 2.1953  accuracy: 70.18% -> 70.18%     
client [99] (testset)   loss: 1.3530 -> 1.3561  accuracy: 85.88% -> 85.88%     
client [69] (testset)   loss: 1.3646 -> 1.3654  accuracy: 75.24% -> 74.29%     
client [46] (testset)   loss: 1.3386 -> 1.3401  accuracy: 78.95% -> 78.95%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 1.3607 -> 1.3625  accuracy: 85.49% -> 85.49%     
client [93] (testset)   loss: 1.4085 -> 1.4097  accuracy: 85.40% -> 85.40%     
client [11] (testset)   loss: 1.6035 -> 1.6067  accuracy: 80.33% -> 80.33%     
client [58] (testset)   loss: 1.4063 -> 1.4077  accuracy: 80.61% -> 80.61%     
client [81] (testset)   loss: 1.9011 -> 1.9040  accuracy: 77.95% -> 77.95%     
client [85] (testset)   loss: 0.9638 -> 0.9646  accuracy: 87.97% -> 87.97%     
client [89] (testset)   loss: 1.4424 -> 1.4405  accuracy: 78.72% -> 78.72%     
client [45] (testset)   loss: 1.7000 -> 1.7028  accuracy: 82.16% -> 82.16%     
client [8]  (testset)   loss: 0.7251 -> 0.7253  accuracy: 91.28% -> 91.28%     
client [68] (testset)   loss: 1.2902 -> 1.2918  accuracy: 87.48% -> 87.48%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 0.6116 -> 0.6123  accuracy: 86.76% -> 86.27%     
client [72] (testset)   loss: 1.1204 -> 1.1210  accuracy: 83.58% -> 83.58%     
client [1]  (testset)   loss: 1.6600 -> 1.6660  accuracy: 79.17% -> 79.17%     
client [78] (testset)   loss: 1.1202 -> 1.1226  accuracy: 87.50% -> 87.50%     
client [83] (testset)   loss: 1.4194 -> 1.4225  accuracy: 80.50% -> 80.50%     
client [21] (testset)   loss: 0.9855 -> 0.9873  accuracy: 86.55% -> 86.55%     
client [56] (testset)   loss: 1.4766 -> 1.4785  accuracy: 75.12% -> 75.62%     
client [44] (testset)   loss: 1.2312 -> 1.2329  accuracy: 85.01% -> 85.01%     
client [92] (testset)   loss: 1.4812 -> 1.4832  accuracy: 80.00% -> 80.00%     
client [27] (testset)   loss: 2.0766 -> 2.0790  accuracy: 78.82% -> 78.82%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 1.3340 -> 1.3347  accuracy: 85.49% -> 85.49%     
client [39] (testset)   loss: 1.0663 -> 1.0676  accuracy: 83.33% -> 83.33%     
client [65] (testset)   loss: 0.8873 -> 0.8886  accuracy: 86.84% -> 86.84%     
client [26] (testset)   loss: 0.4917 -> 0.4927  accuracy: 91.58% -> 91.58%     
client [19] (testset)   loss: 1.4287 -> 1.4314  accuracy: 83.33% -> 83.33%     
client [68] (testset)   loss: 1.2961 -> 1.2976  accuracy: 87.48% -> 87.48%     
client [41] (testset)   loss: 1.2344 -> 1.2359  accuracy: 83.94% -> 83.94%     
client [50] (testset)   loss: 1.4208 -> 1.4231  accuracy: 82.47% -> 82.47%     
client [75] (testset)   loss: 2.1457 -> 2.1496  accuracy: 76.25% -> 76.25%     
client [81] (testset)   loss: 1.9153 -> 1.9184  accuracy: 77.95% -> 77.95%     
LG-FedAvg's average time taken by each global epoch: 0 min 5.11 sec.           
LG-FedAvg's total running time: 0 h 37 m 17 s.                                 
==================== LG-FedAvg Experiment Results: ====================        
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.1666 -> 1.1755",                                    
                "accuracy": "83.54% -> 83.56%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.2823 -> 1.2861",                                    
                "accuracy": "83.53% -> 83.51%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.3474 -> 1.3501",                                    
                "accuracy": "83.48% -> 83.48%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.3919 -> 1.3940",                                    
                "accuracy": "83.46% -> 83.43%"                                 
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== LG-FedAvg Max Accuracy ====================               
all_clients:                                                                   
(test) before fine-tuning: 83.54% at epoch 100                                 
(test) after fine-tuning: 83.56% at epoch 100                                  
