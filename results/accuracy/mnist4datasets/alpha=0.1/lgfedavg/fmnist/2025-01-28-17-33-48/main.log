==================== LG-FedAvg ====================                            
Experiment Arguments:                                                          
{
    'method': 'lgfedavg',
    'dataset': {
        'name': 'fmnist',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'fmnist-100clients-0%IID-Dir(0.1)-seed42',
        'alpha': 0.1,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'parallel',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': 24.0,
        'num_gpus': 1.0,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 400,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 5,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'lgfedavg': {
        'num_global_layers': 1
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [81] (testset)   loss: 0.1725 -> 0.0871  accuracy: 94.44% -> 98.15%     
client [77] (testset)   loss: 0.0618 -> 0.0557  accuracy: 96.89% -> 97.93%     
client [21] (testset)   loss: 0.7330 -> 0.2668  accuracy: 72.05% -> 90.68%     
client [68] (testset)   loss: 0.1704 -> 0.1605  accuracy: 94.55% -> 94.55%     
client [93] (testset)   loss: 0.0144 -> 0.0186  accuracy: 100.00% -> 100.00%   
client [31] (testset)   loss: 0.4134 -> 0.3903  accuracy: 84.62% -> 86.15%     
client [59] (testset)   loss: 0.6122 -> 0.4522  accuracy: 82.48% -> 87.59%     
client [48] (testset)   loss: 0.0186 -> 0.0176  accuracy: 100.00% -> 100.00%   
client [20] (testset)   loss: 0.0775 -> 0.0544  accuracy: 97.58% -> 98.92%     
client [34] (testset)   loss: 0.3537 -> 0.3787  accuracy: 92.31% -> 92.31%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 0.2232 -> 0.2150  accuracy: 95.06% -> 95.68%     
client [99] (testset)   loss: 0.0894 -> 0.0767  accuracy: 98.16% -> 98.42%     
client [0]  (testset)   loss: 0.3912 -> 0.3174  accuracy: 85.71% -> 89.80%     
client [67] (testset)   loss: 0.2102 -> 0.1645  accuracy: 95.19% -> 95.53%     
client [76] (testset)   loss: 0.3512 -> 0.3460  accuracy: 86.67% -> 86.67%     
client [62] (testset)   loss: 2.3993 -> 0.2914  accuracy: 40.00% -> 90.00%     
client [41] (testset)   loss: 0.2542 -> 0.2179  accuracy: 93.15% -> 92.34%     
client [2]  (testset)   loss: 1.6075 -> 0.0159  accuracy: 12.04% -> 99.34%     
client [46] (testset)   loss: 0.3297 -> 0.3222  accuracy: 88.54% -> 88.54%     
client [14] (testset)   loss: 0.4208 -> 0.3244  accuracy: 86.19% -> 87.14%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [68] (testset)   loss: 0.1694 -> 0.1863  accuracy: 94.55% -> 94.55%     
client [24] (testset)   loss: 0.3891 -> 0.3800  accuracy: 86.29% -> 87.43%     
client [17] (testset)   loss: 0.2067 -> 0.2053  accuracy: 91.98% -> 91.98%     
client [57] (testset)   loss: 0.0526 -> 0.0432  accuracy: 98.91% -> 98.91%     
client [54] (testset)   loss: 0.3328 -> 0.4439  accuracy: 89.61% -> 87.01%     
client [23] (testset)   loss: 0.3587 -> 0.1422  accuracy: 80.81% -> 95.96%     
client [35] (testset)   loss: 0.0380 -> 0.0421  accuracy: 100.00% -> 100.00%   
client [31] (testset)   loss: 0.5333 -> 0.3158  accuracy: 73.85% -> 83.08%     
client [59] (testset)   loss: 0.4729 -> 0.5617  accuracy: 89.05% -> 86.86%     
client [9]  (testset)   loss: 0.1498 -> 0.1471  accuracy: 94.44% -> 94.44%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 0.1439 -> 0.1811  accuracy: 95.49% -> 93.23%     
client [33] (testset)   loss: 0.1288 -> 0.1187  accuracy: 95.32% -> 95.32%     
client [16] (testset)   loss: 0.0279 -> 0.0254  accuracy: 98.33% -> 98.33%     
client [44] (testset)   loss: 0.1973 -> 0.0959  accuracy: 92.45% -> 94.34%     
client [31] (testset)   loss: 0.3578 -> 0.3018  accuracy: 76.92% -> 87.69%     
client [8]  (testset)   loss: 0.3225 -> 0.3440  accuracy: 91.96% -> 91.96%     
client [47] (testset)   loss: 0.1489 -> 0.1039  accuracy: 94.35% -> 97.17%     
client [36] (testset)   loss: 0.2316 -> 0.1857  accuracy: 91.79% -> 94.42%     
client [20] (testset)   loss: 0.0652 -> 0.0656  accuracy: 98.39% -> 98.39%     
client [56] (testset)   loss: 0.7458 -> 0.4755  accuracy: 66.39% -> 81.51%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 0.1086 -> 0.1447  accuracy: 97.69% -> 95.38%     
client [28] (testset)   loss: 0.0985 -> 0.0870  accuracy: 94.64% -> 94.64%     
client [60] (testset)   loss: 0.2275 -> 0.1770  accuracy: 93.73% -> 94.83%     
client [25] (testset)   loss: 0.1622 -> 0.1845  accuracy: 95.19% -> 95.19%     
client [58] (testset)   loss: 0.1624 -> 0.1698  accuracy: 94.90% -> 94.90%     
client [44] (testset)   loss: 0.1021 -> 0.0842  accuracy: 94.34% -> 95.28%     
client [39] (testset)   loss: 0.0119 -> 0.0086  accuracy: 100.00% -> 100.00%   
client [29] (testset)   loss: 0.3704 -> 0.3521  accuracy: 89.87% -> 89.87%     
client [84] (testset)   loss: 0.0015 -> 0.0016  accuracy: 100.00% -> 100.00%   
client [3]  (testset)   loss: 0.1489 -> 0.1347  accuracy: 93.77% -> 95.72%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [84] (testset)   loss: 0.0013 -> 0.0012  accuracy: 100.00% -> 100.00%   
client [21] (testset)   loss: 0.2195 -> 0.2012  accuracy: 92.55% -> 91.30%     
client [10] (testset)   loss: 0.0141 -> 0.0137  accuracy: 100.00% -> 100.00%   
client [65] (testset)   loss: 0.6052 -> 0.6357  accuracy: 87.50% -> 87.50%     
client [81] (testset)   loss: 0.0575 -> 0.0569  accuracy: 98.15% -> 98.15%     
client [79] (testset)   loss: 0.5662 -> 0.3908  accuracy: 87.68% -> 89.66%     
client [36] (testset)   loss: 0.2413 -> 0.2055  accuracy: 93.60% -> 94.75%     
client [11] (testset)   loss: 0.3190 -> 0.3147  accuracy: 88.34% -> 89.24%     
client [96] (testset)   loss: 0.2638 -> 0.2662  accuracy: 91.97% -> 92.70%     
client [42] (testset)   loss: 0.0678 -> 0.0768  accuracy: 98.67% -> 98.55%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 0.3691 -> 0.3808  accuracy: 91.96% -> 91.67%     
client [52] (testset)   loss: 0.2967 -> 0.2982  accuracy: 89.83% -> 89.83%     
client [53] (testset)   loss: 0.0300 -> 0.0169  accuracy: 98.80% -> 99.10%     
client [69] (testset)   loss: 0.3250 -> 0.3153  accuracy: 95.06% -> 95.68%     
client [59] (testset)   loss: 0.5796 -> 0.6001  accuracy: 86.86% -> 86.86%     
client [7]  (testset)   loss: 0.0432 -> 0.0392  accuracy: 98.69% -> 98.69%     
client [42] (testset)   loss: 0.0779 -> 0.0848  accuracy: 98.67% -> 98.79%     
client [49] (testset)   loss: 0.0279 -> 0.0295  accuracy: 99.57% -> 99.57%     
client [98] (testset)   loss: 0.7661 -> 0.7717  accuracy: 87.23% -> 89.36%     
client [26] (testset)   loss: 0.0871 -> 0.0884  accuracy: 97.93% -> 97.93%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 0.7836 -> 0.8538  accuracy: 89.36% -> 87.23%     
client [21] (testset)   loss: 0.2539 -> 0.3275  accuracy: 91.30% -> 89.44%     
client [47] (testset)   loss: 0.1276 -> 0.1530  accuracy: 96.52% -> 95.65%     
client [77] (testset)   loss: 0.0516 -> 0.0521  accuracy: 98.45% -> 98.45%     
client [91] (testset)   loss: 0.9423 -> 0.9421  accuracy: 92.31% -> 92.31%     
client [95] (testset)   loss: 0.2971 -> 0.3265  accuracy: 88.89% -> 92.59%     
client [14] (testset)   loss: 0.4358 -> 0.4642  accuracy: 89.29% -> 89.05%     
client [99] (testset)   loss: 0.0870 -> 0.1079  accuracy: 98.42% -> 98.42%     
client [39] (testset)   loss: 0.0038 -> 0.0035  accuracy: 100.00% -> 100.00%   
client [20] (testset)   loss: 0.0825 -> 0.0858  accuracy: 98.39% -> 98.12%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [62] (testset)   loss: 0.4986 -> 0.5097  accuracy: 90.00% -> 90.00%     
client [52] (testset)   loss: 0.3077 -> 0.3031  accuracy: 89.83% -> 89.83%     
client [71] (testset)   loss: 0.0980 -> 0.0937  accuracy: 97.28% -> 96.74%     
client [97] (testset)   loss: 0.0720 -> 0.0854  accuracy: 98.70% -> 98.27%     
client [30] (testset)   loss: 0.2282 -> 0.2397  accuracy: 97.12% -> 97.12%     
client [88] (testset)   loss: 0.7018 -> 0.4288  accuracy: 75.61% -> 86.59%     
client [60] (testset)   loss: 0.2452 -> 0.2141  accuracy: 94.46% -> 93.73%     
client [91] (testset)   loss: 0.9666 -> 0.9666  accuracy: 92.31% -> 92.31%     
client [82] (testset)   loss: 0.1453 -> 0.1499  accuracy: 98.97% -> 98.63%     
client [57] (testset)   loss: 0.0435 -> 0.0453  accuracy: 99.27% -> 99.27%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 0.4735 -> 0.4768  accuracy: 90.77% -> 89.23%     
client [71] (testset)   loss: 0.0944 -> 0.0947  accuracy: 96.74% -> 96.74%     
client [15] (testset)   loss: 0.2663 -> 0.2786  accuracy: 93.12% -> 93.44%     
client [97] (testset)   loss: 0.0844 -> 0.0863  accuracy: 98.27% -> 98.27%     
client [53] (testset)   loss: 0.0178 -> 0.0148  accuracy: 99.40% -> 99.40%     
client [76] (testset)   loss: 0.5970 -> 0.6122  accuracy: 86.67% -> 86.67%     
client [77] (testset)   loss: 0.0535 -> 0.0525  accuracy: 98.45% -> 98.96%     
client [28] (testset)   loss: 0.0836 -> 0.0832  accuracy: 94.64% -> 94.64%     
client [79] (testset)   loss: 0.3991 -> 0.4159  accuracy: 90.15% -> 89.66%     
client [99] (testset)   loss: 0.1212 -> 0.1045  accuracy: 98.42% -> 98.42%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [86] (testset)   loss: 0.3847 -> 0.4031  accuracy: 88.24% -> 88.24%     
client [34] (testset)   loss: 0.5425 -> 0.5475  accuracy: 96.15% -> 96.15%     
client [97] (testset)   loss: 0.0867 -> 0.0895  accuracy: 98.27% -> 98.27%     
client [73] (testset)   loss: 0.0452 -> 0.0471  accuracy: 99.24% -> 99.24%     
client [96] (testset)   loss: 0.3694 -> 0.3673  accuracy: 91.24% -> 92.70%     
client [5]  (testset)   loss: 0.1474 -> 0.1434  accuracy: 95.71% -> 95.71%     
client [22] (testset)   loss: 0.0629 -> 0.0628  accuracy: 97.94% -> 97.94%     
client [60] (testset)   loss: 0.2526 -> 0.2452  accuracy: 94.10% -> 93.73%     
client [66] (testset)   loss: 0.1460 -> 0.1498  accuracy: 95.62% -> 95.62%     
client [83] (testset)   loss: 0.0366 -> 0.0371  accuracy: 98.73% -> 98.73%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 0.6405 -> 0.6522  accuracy: 86.67% -> 86.67%     
client [65] (testset)   loss: 0.7734 -> 0.7931  accuracy: 87.50% -> 87.50%     
client [95] (testset)   loss: 0.3462 -> 0.3441  accuracy: 94.44% -> 94.44%     
client [17] (testset)   loss: 0.2123 -> 0.2241  accuracy: 94.12% -> 93.05%     
client [35] (testset)   loss: 0.0062 -> 0.0059  accuracy: 100.00% -> 100.00%   
client [98] (testset)   loss: 0.9491 -> 0.9605  accuracy: 89.36% -> 89.36%     
client [8]  (testset)   loss: 0.4753 -> 0.4688  accuracy: 91.37% -> 91.67%     
client [43] (testset)   loss: 0.1237 -> 0.1226  accuracy: 96.92% -> 96.92%     
client [53] (testset)   loss: 0.0164 -> 0.0162  accuracy: 99.40% -> 99.40%     
client [64] (testset)   loss: 0.1917 -> 0.1993  accuracy: 94.74% -> 94.74%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [88] (testset)   loss: 0.5250 -> 0.5516  accuracy: 86.59% -> 86.59%     
client [21] (testset)   loss: 0.2131 -> 0.2435  accuracy: 91.93% -> 92.55%     
client [38] (testset)   loss: 0.8583 -> 0.8852  accuracy: 84.42% -> 84.42%     
client [5]  (testset)   loss: 0.1442 -> 0.1444  accuracy: 95.71% -> 95.71%     
client [3]  (testset)   loss: 0.1830 -> 0.1894  accuracy: 95.72% -> 95.72%     
client [41] (testset)   loss: 0.2752 -> 0.2771  accuracy: 93.15% -> 93.15%     
client [7]  (testset)   loss: 0.0335 -> 0.0421  accuracy: 98.69% -> 98.69%     
client [45] (testset)   loss: 0.4733 -> 0.4181  accuracy: 89.19% -> 89.19%     
client [37] (testset)   loss: 0.2122 -> 0.2200  accuracy: 93.48% -> 93.48%     
client [47] (testset)   loss: 0.1835 -> 0.1385  accuracy: 95.43% -> 96.96%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 0.0310 -> 0.0321  accuracy: 98.33% -> 98.33%     
client [11] (testset)   loss: 0.4356 -> 0.4655  accuracy: 90.13% -> 89.69%     
client [37] (testset)   loss: 0.2184 -> 0.2258  accuracy: 93.48% -> 93.48%     
client [95] (testset)   loss: 0.3164 -> 0.3476  accuracy: 94.44% -> 94.44%     
client [41] (testset)   loss: 0.2789 -> 0.2832  accuracy: 93.15% -> 92.74%     
client [22] (testset)   loss: 0.0656 -> 0.0641  accuracy: 97.94% -> 97.94%     
client [53] (testset)   loss: 0.0163 -> 0.0145  accuracy: 99.40% -> 99.40%     
client [25] (testset)   loss: 0.2284 -> 0.2315  accuracy: 96.15% -> 96.15%     
client [69] (testset)   loss: 0.3922 -> 0.3939  accuracy: 95.68% -> 96.30%     
client [46] (testset)   loss: 0.4218 -> 0.5421  accuracy: 89.58% -> 86.46%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [69] (testset)   loss: 0.4047 -> 0.4020  accuracy: 95.68% -> 95.68%     
client [47] (testset)   loss: 0.1778 -> 0.1800  accuracy: 96.52% -> 96.52%     
client [82] (testset)   loss: 0.1704 -> 0.1714  accuracy: 98.97% -> 98.97%     
client [45] (testset)   loss: 0.5019 -> 0.5232  accuracy: 86.49% -> 86.49%     
client [7]  (testset)   loss: 0.0420 -> 0.0338  accuracy: 99.13% -> 98.69%     
client [35] (testset)   loss: 0.0052 -> 0.0051  accuracy: 100.00% -> 100.00%   
client [50] (testset)   loss: 0.0322 -> 0.0330  accuracy: 98.86% -> 98.86%     
client [24] (testset)   loss: 0.7665 -> 0.7761  accuracy: 88.00% -> 89.71%     
client [15] (testset)   loss: 0.3543 -> 0.3704  accuracy: 93.44% -> 93.44%     
client [58] (testset)   loss: 0.2270 -> 0.2284  accuracy: 94.39% -> 94.39%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [76] (testset)   loss: 0.7158 -> 0.7114  accuracy: 86.67% -> 86.67%     
client [48] (testset)   loss: 0.0054 -> 0.0054  accuracy: 100.00% -> 100.00%   
client [37] (testset)   loss: 0.2304 -> 0.2319  accuracy: 93.48% -> 93.48%     
client [67] (testset)   loss: 0.2975 -> 0.3071  accuracy: 96.22% -> 96.22%     
client [58] (testset)   loss: 0.2308 -> 0.2312  accuracy: 94.39% -> 94.39%     
client [64] (testset)   loss: 0.2103 -> 0.2128  accuracy: 94.74% -> 94.74%     
client [77] (testset)   loss: 0.0571 -> 0.0583  accuracy: 98.96% -> 98.96%     
client [55] (testset)   loss: 0.0004 -> 0.0004  accuracy: 100.00% -> 100.00%   
client [89] (testset)   loss: 0.9103 -> 0.9203  accuracy: 89.47% -> 89.47%     
client [12] (testset)   loss: 0.2228 -> 0.2249  accuracy: 94.31% -> 94.31%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 0.0005 -> 0.0005  accuracy: 100.00% -> 100.00%   
client [51] (testset)   loss: 0.0749 -> 0.0750  accuracy: 97.55% -> 97.55%     
client [8]  (testset)   loss: 0.5293 -> 0.5339  accuracy: 91.37% -> 91.37%     
client [18] (testset)   loss: 0.0243 -> 0.0244  accuracy: 99.50% -> 99.50%     
client [94] (testset)   loss: 0.3073 -> 0.2991  accuracy: 93.89% -> 93.89%     
client [81] (testset)   loss: 0.0829 -> 0.0772  accuracy: 98.15% -> 98.15%     
client [3]  (testset)   loss: 0.2085 -> 0.2020  accuracy: 94.94% -> 95.72%     
client [11] (testset)   loss: 0.4935 -> 0.4818  accuracy: 89.24% -> 88.79%     
client [95] (testset)   loss: 0.3718 -> 0.3749  accuracy: 94.44% -> 94.44%     
client [67] (testset)   loss: 0.3092 -> 0.3121  accuracy: 96.22% -> 96.22%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 0.2676 -> 0.2993  accuracy: 92.55% -> 91.93%     
client [79] (testset)   loss: 0.5645 -> 0.5751  accuracy: 90.15% -> 90.15%     
client [88] (testset)   loss: 0.5934 -> 0.5960  accuracy: 86.59% -> 86.59%     
client [58] (testset)   loss: 0.2364 -> 0.2375  accuracy: 94.39% -> 94.39%     
client [46] (testset)   loss: 0.4739 -> 0.5108  accuracy: 87.50% -> 91.67%     
client [11] (testset)   loss: 0.4847 -> 0.4982  accuracy: 88.79% -> 89.24%     
client [55] (testset)   loss: 0.0004 -> 0.0004  accuracy: 100.00% -> 100.00%   
client [31] (testset)   loss: 0.5212 -> 0.5269  accuracy: 90.77% -> 90.77%     
client [13] (testset)   loss: 0.9302 -> 0.9590  accuracy: 87.82% -> 87.50%     
client [75] (testset)   loss: 0.6560 -> 0.6350  accuracy: 86.60% -> 87.56%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 0.4648 -> 0.4634  accuracy: 89.83% -> 89.83%     
client [7]  (testset)   loss: 0.0359 -> 0.0379  accuracy: 98.69% -> 98.69%     
client [57] (testset)   loss: 0.0563 -> 0.0565  accuracy: 98.91% -> 99.27%     
client [43] (testset)   loss: 0.1428 -> 0.1444  accuracy: 96.92% -> 96.92%     
client [91] (testset)   loss: 1.0971 -> 1.0971  accuracy: 92.31% -> 92.31%     
client [13] (testset)   loss: 0.9595 -> 0.9723  accuracy: 87.82% -> 87.82%     
client [10] (testset)   loss: 0.0076 -> 0.0076  accuracy: 100.00% -> 100.00%   
client [64] (testset)   loss: 0.2192 -> 0.2185  accuracy: 94.74% -> 94.74%     
client [22] (testset)   loss: 0.0627 -> 0.0616  accuracy: 97.94% -> 97.94%     
client [82] (testset)   loss: 0.1821 -> 0.1826  accuracy: 98.97% -> 98.97%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [23] (testset)   loss: 0.2707 -> 0.2807  accuracy: 94.95% -> 94.95%     
client [88] (testset)   loss: 0.6016 -> 0.6095  accuracy: 86.59% -> 86.59%     
client [98] (testset)   loss: 1.1110 -> 1.1114  accuracy: 89.36% -> 89.36%     
client [20] (testset)   loss: 0.1030 -> 0.1033  accuracy: 98.12% -> 98.12%     
client [21] (testset)   loss: 0.2871 -> 0.3059  accuracy: 91.93% -> 91.93%     
client [79] (testset)   loss: 0.5885 -> 0.5948  accuracy: 90.15% -> 90.15%     
client [92] (testset)   loss: 0.2025 -> 0.2054  accuracy: 96.35% -> 96.35%     
client [56] (testset)   loss: 0.8078 -> 0.8284  accuracy: 89.08% -> 89.08%     
client [52] (testset)   loss: 0.4263 -> 0.4263  accuracy: 89.83% -> 89.83%     
client [5]  (testset)   loss: 0.1557 -> 0.1621  accuracy: 95.71% -> 95.71%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [54] (testset)   loss: 0.7472 -> 0.7586  accuracy: 90.91% -> 90.91%     
client [67] (testset)   loss: 0.3411 -> 0.3447  accuracy: 96.22% -> 96.22%     
client [14] (testset)   loss: 0.6203 -> 0.6252  accuracy: 90.00% -> 89.76%     
client [99] (testset)   loss: 0.1545 -> 0.1484  accuracy: 98.42% -> 98.42%     
client [30] (testset)   loss: 0.3218 -> 0.3240  accuracy: 97.12% -> 97.12%     
client [38] (testset)   loss: 0.9922 -> 1.0057  accuracy: 84.42% -> 84.42%     
client [36] (testset)   loss: 0.3836 -> 0.3898  accuracy: 94.42% -> 94.25%     
client [15] (testset)   loss: 0.4034 -> 0.4162  accuracy: 93.44% -> 93.44%     
client [6]  (testset)   loss: 0.1627 -> 0.1635  accuracy: 96.75% -> 96.75%     
client [53] (testset)   loss: 0.0145 -> 0.0144  accuracy: 99.40% -> 99.40%     
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [6]  (testset)   loss: 0.1642 -> 0.1650  accuracy: 96.75% -> 96.75%     
client [83] (testset)   loss: 0.0537 -> 0.0520  accuracy: 98.73% -> 98.73%     
client [99] (testset)   loss: 0.1548 -> 0.1523  accuracy: 98.42% -> 98.42%     
client [34] (testset)   loss: 0.6179 -> 0.6199  accuracy: 96.15% -> 96.15%     
client [15] (testset)   loss: 0.4175 -> 0.4190  accuracy: 93.44% -> 93.44%     
client [42] (testset)   loss: 0.1187 -> 0.1190  accuracy: 98.67% -> 98.79%     
client [47] (testset)   loss: 0.2036 -> 0.2012  accuracy: 96.74% -> 96.74%     
client [51] (testset)   loss: 0.0772 -> 0.0773  accuracy: 97.55% -> 97.55%     
client [55] (testset)   loss: 0.0004 -> 0.0004  accuracy: 100.00% -> 100.00%   
client [95] (testset)   loss: 0.3890 -> 0.3910  accuracy: 94.44% -> 94.44%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 0.1263 -> 0.1246  accuracy: 96.74% -> 96.74%     
client [15] (testset)   loss: 0.4201 -> 0.4229  accuracy: 93.44% -> 93.44%     
client [33] (testset)   loss: 0.1946 -> 0.1929  accuracy: 96.49% -> 95.91%     
client [90] (testset)   loss: 0.1618 -> 0.1625  accuracy: 97.97% -> 97.97%     
client [99] (testset)   loss: 0.1564 -> 0.1577  accuracy: 98.42% -> 98.42%     
client [27] (testset)   loss: 0.0329 -> 0.0336  accuracy: 97.67% -> 97.67%     
client [57] (testset)   loss: 0.0594 -> 0.0599  accuracy: 99.27% -> 99.27%     
client [78] (testset)   loss: 0.0016 -> 0.0016  accuracy: 100.00% -> 100.00%   
client [36] (testset)   loss: 0.3890 -> 0.3930  accuracy: 94.42% -> 94.42%     
client [88] (testset)   loss: 0.6337 -> 0.6433  accuracy: 89.02% -> 86.59%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 0.5057 -> 0.5057  accuracy: 91.89% -> 91.89%     
client [35] (testset)   loss: 0.0041 -> 0.0040  accuracy: 100.00% -> 100.00%   
client [80] (testset)   loss: 0.0139 -> 0.0143  accuracy: 100.00% -> 100.00%   
client [16] (testset)   loss: 0.0328 -> 0.0342  accuracy: 98.33% -> 98.33%     
client [38] (testset)   loss: 1.0306 -> 1.0414  accuracy: 84.42% -> 84.42%     
client [78] (testset)   loss: 0.0015 -> 0.0015  accuracy: 100.00% -> 100.00%   
client [68] (testset)   loss: 0.2713 -> 0.2727  accuracy: 94.55% -> 94.55%     
client [11] (testset)   loss: 0.5459 -> 0.5371  accuracy: 89.24% -> 89.24%     
client [64] (testset)   loss: 0.2282 -> 0.2260  accuracy: 94.74% -> 94.74%     
client [82] (testset)   loss: 0.1912 -> 0.1917  accuracy: 98.97% -> 98.97%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [27] (testset)   loss: 0.0336 -> 0.0324  accuracy: 97.67% -> 97.67%     
client [30] (testset)   loss: 0.3396 -> 0.3410  accuracy: 97.12% -> 97.12%     
client [74] (testset)   loss: 0.7743 -> 0.7857  accuracy: 92.59% -> 92.59%     
client [45] (testset)   loss: 0.6511 -> 0.6534  accuracy: 86.49% -> 86.49%     
client [6]  (testset)   loss: 0.1676 -> 0.1686  accuracy: 96.75% -> 96.75%     
client [63] (testset)   loss: 0.0449 -> 0.0452  accuracy: 98.97% -> 98.97%     
client [76] (testset)   loss: 0.7857 -> 0.7884  accuracy: 86.67% -> 86.67%     
client [83] (testset)   loss: 0.0543 -> 0.0550  accuracy: 98.73% -> 98.73%     
client [86] (testset)   loss: 0.4547 -> 0.4419  accuracy: 88.24% -> 88.24%     
client [36] (testset)   loss: 0.4006 -> 0.4072  accuracy: 94.42% -> 94.25%     
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 0.0553 -> 0.0550  accuracy: 98.73% -> 98.73%     
client [74] (testset)   loss: 0.7906 -> 0.7968  accuracy: 92.59% -> 92.59%     
client [99] (testset)   loss: 0.1595 -> 0.1614  accuracy: 98.42% -> 98.42%     
client [73] (testset)   loss: 0.0512 -> 0.0523  accuracy: 99.24% -> 99.24%     
client [29] (testset)   loss: 0.5765 -> 0.5720  accuracy: 89.87% -> 89.87%     
client [92] (testset)   loss: 0.2145 -> 0.2157  accuracy: 96.35% -> 96.35%     
client [6]  (testset)   loss: 0.1697 -> 0.1709  accuracy: 96.75% -> 96.75%     
client [61] (testset)   loss: 0.0300 -> 0.0294  accuracy: 98.78% -> 97.56%     
client [21] (testset)   loss: 0.3261 -> 0.3338  accuracy: 91.93% -> 91.93%     
client [67] (testset)   loss: 0.3580 -> 0.3594  accuracy: 96.22% -> 96.22%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 0.0553 -> 0.0552  accuracy: 98.73% -> 98.73%     
client [95] (testset)   loss: 0.3951 -> 0.4026  accuracy: 94.44% -> 94.44%     
client [32] (testset)   loss: 0.5467 -> 0.5520  accuracy: 89.72% -> 89.72%     
client [27] (testset)   loss: 0.0324 -> 0.0326  accuracy: 97.67% -> 97.67%     
client [61] (testset)   loss: 0.0298 -> 0.0300  accuracy: 97.56% -> 97.56%     
client [25] (testset)   loss: 0.2633 -> 0.2651  accuracy: 96.15% -> 96.15%     
client [68] (testset)   loss: 0.2813 -> 0.2818  accuracy: 94.55% -> 94.55%     
client [34] (testset)   loss: 0.6365 -> 0.6328  accuracy: 96.15% -> 96.15%     
client [89] (testset)   loss: 0.9823 -> 0.9864  accuracy: 89.47% -> 89.47%     
client [71] (testset)   loss: 0.1311 -> 0.1282  accuracy: 97.28% -> 97.83%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [81] (testset)   loss: 0.0788 -> 0.0824  accuracy: 98.15% -> 98.15%     
client [78] (testset)   loss: 0.0014 -> 0.0013  accuracy: 100.00% -> 100.00%   
client [54] (testset)   loss: 0.7874 -> 0.7953  accuracy: 90.91% -> 90.91%     
client [51] (testset)   loss: 0.0779 -> 0.0786  accuracy: 97.55% -> 97.55%     
client [65] (testset)   loss: 1.0037 -> 1.0072  accuracy: 87.50% -> 87.50%     
client [41] (testset)   loss: 0.3485 -> 0.3494  accuracy: 93.15% -> 93.15%     
client [11] (testset)   loss: 0.5394 -> 0.5629  accuracy: 89.24% -> 89.24%     
client [85] (testset)   loss: 0.0802 -> 0.0802  accuracy: 98.25% -> 98.25%     
client [23] (testset)   loss: 0.3305 -> 0.3286  accuracy: 94.95% -> 94.95%     
client [12] (testset)   loss: 0.2525 -> 0.2538  accuracy: 94.43% -> 94.31%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [65] (testset)   loss: 1.0141 -> 1.0199  accuracy: 87.50% -> 87.50%     
client [16] (testset)   loss: 0.0357 -> 0.0373  accuracy: 98.33% -> 98.33%     
client [58] (testset)   loss: 0.2545 -> 0.2549  accuracy: 94.39% -> 94.39%     
client [53] (testset)   loss: 0.0137 -> 0.0137  accuracy: 99.40% -> 99.40%     
client [72] (testset)   loss: 0.0699 -> 0.0685  accuracy: 96.49% -> 98.25%     
client [71] (testset)   loss: 0.1286 -> 0.1317  accuracy: 97.83% -> 97.28%     
client [7]  (testset)   loss: 0.0386 -> 0.0370  accuracy: 98.25% -> 98.25%     
client [86] (testset)   loss: 0.4597 -> 0.4625  accuracy: 88.24% -> 88.24%     
client [39] (testset)   loss: 0.0007 -> 0.0007  accuracy: 100.00% -> 100.00%   
client [59] (testset)   loss: 0.9303 -> 0.9351  accuracy: 86.86% -> 86.86%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [7]  (testset)   loss: 0.0387 -> 0.0371  accuracy: 98.25% -> 98.25%     
client [99] (testset)   loss: 0.1637 -> 0.1633  accuracy: 98.42% -> 98.42%     
client [17] (testset)   loss: 0.3264 -> 0.3214  accuracy: 93.05% -> 93.05%     
client [64] (testset)   loss: 0.2346 -> 0.2360  accuracy: 94.74% -> 94.74%     
client [37] (testset)   loss: 0.2617 -> 0.2633  accuracy: 93.48% -> 93.48%     
client [29] (testset)   loss: 0.5934 -> 0.6016  accuracy: 89.87% -> 89.87%     
client [93] (testset)   loss: 0.0244 -> 0.0247  accuracy: 98.31% -> 98.31%     
client [73] (testset)   loss: 0.0538 -> 0.0530  accuracy: 99.24% -> 99.24%     
client [40] (testset)   loss: 0.3344 -> 0.3364  accuracy: 95.00% -> 95.00%     
client [76] (testset)   loss: 0.8211 -> 0.8205  accuracy: 86.67% -> 86.67%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [89] (testset)   loss: 0.9991 -> 1.0031  accuracy: 89.47% -> 89.47%     
client [31] (testset)   loss: 0.5791 -> 0.5826  accuracy: 90.77% -> 90.77%     
client [90] (testset)   loss: 0.1787 -> 0.1803  accuracy: 97.97% -> 97.97%     
client [77] (testset)   loss: 0.0656 -> 0.0659  accuracy: 98.96% -> 98.96%     
client [50] (testset)   loss: 0.0386 -> 0.0383  accuracy: 98.86% -> 98.86%     
client [26] (testset)   loss: 0.0897 -> 0.0914  accuracy: 98.09% -> 98.09%     
client [30] (testset)   loss: 0.3556 -> 0.3568  accuracy: 97.12% -> 97.12%     
client [70] (testset)   loss: 0.5221 -> 0.5220  accuracy: 91.89% -> 91.89%     
client [41] (testset)   loss: 0.3549 -> 0.3564  accuracy: 92.74% -> 92.74%     
client [99] (testset)   loss: 0.1636 -> 0.1635  accuracy: 98.42% -> 98.42%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [70] (testset)   loss: 0.5247 -> 0.5256  accuracy: 91.89% -> 91.89%     
client [68] (testset)   loss: 0.2930 -> 0.2963  accuracy: 94.55% -> 94.55%     
client [52] (testset)   loss: 0.4754 -> 0.4785  accuracy: 89.83% -> 89.83%     
client [1]  (testset)   loss: 0.6789 -> 0.6810  accuracy: 93.65% -> 93.65%     
client [67] (testset)   loss: 0.3781 -> 0.3792  accuracy: 96.22% -> 96.22%     
client [2]  (testset)   loss: 0.0172 -> 0.0173  accuracy: 99.34% -> 99.34%     
client [92] (testset)   loss: 0.2304 -> 0.2314  accuracy: 96.35% -> 96.35%     
client [35] (testset)   loss: 0.0036 -> 0.0035  accuracy: 100.00% -> 100.00%   
client [64] (testset)   loss: 0.2376 -> 0.2374  accuracy: 94.74% -> 94.74%     
client [36] (testset)   loss: 0.4256 -> 0.4254  accuracy: 94.42% -> 94.42%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 0.0823 -> 0.0836  accuracy: 97.17% -> 97.17%     
client [6]  (testset)   loss: 0.1767 -> 0.1774  accuracy: 96.75% -> 96.75%     
client [55] (testset)   loss: 0.0004 -> 0.0004  accuracy: 100.00% -> 100.00%   
client [29] (testset)   loss: 0.6149 -> 0.6134  accuracy: 89.87% -> 89.87%     
client [9]  (testset)   loss: 0.3108 -> 0.3125  accuracy: 94.10% -> 94.10%     
client [12] (testset)   loss: 0.2608 -> 0.2614  accuracy: 94.19% -> 94.19%     
client [43] (testset)   loss: 0.1507 -> 0.1515  accuracy: 96.92% -> 96.92%     
client [98] (testset)   loss: 1.2364 -> 1.2408  accuracy: 89.36% -> 89.36%     
client [77] (testset)   loss: 0.0662 -> 0.0662  accuracy: 98.96% -> 98.96%     
client [78] (testset)   loss: 0.0012 -> 0.0012  accuracy: 100.00% -> 100.00%   
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [80] (testset)   loss: 0.0141 -> 0.0143  accuracy: 100.00% -> 100.00%   
client [92] (testset)   loss: 0.2341 -> 0.2346  accuracy: 96.35% -> 96.35%     
client [76] (testset)   loss: 0.8367 -> 0.8350  accuracy: 86.67% -> 86.67%     
client [63] (testset)   loss: 0.0478 -> 0.0484  accuracy: 98.97% -> 98.97%     
client [78] (testset)   loss: 0.0012 -> 0.0012  accuracy: 100.00% -> 100.00%   
client [25] (testset)   loss: 0.2744 -> 0.2765  accuracy: 96.15% -> 96.15%     
client [58] (testset)   loss: 0.2594 -> 0.2601  accuracy: 94.39% -> 94.39%     
client [13] (testset)   loss: 1.0773 -> 1.0980  accuracy: 87.82% -> 87.82%     
client [38] (testset)   loss: 1.1659 -> 1.1730  accuracy: 84.42% -> 84.42%     
client [17] (testset)   loss: 0.3321 -> 0.3317  accuracy: 93.05% -> 93.05%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 0.0691 -> 0.0684  accuracy: 98.25% -> 98.25%     
client [86] (testset)   loss: 0.4704 -> 0.4730  accuracy: 88.24% -> 88.24%     
client [82] (testset)   loss: 0.2022 -> 0.2029  accuracy: 98.97% -> 98.97%     
client [51] (testset)   loss: 0.0806 -> 0.0806  accuracy: 97.55% -> 97.55%     
client [96] (testset)   loss: 0.5003 -> 0.5028  accuracy: 92.70% -> 92.70%     
client [55] (testset)   loss: 0.0003 -> 0.0003  accuracy: 100.00% -> 100.00%   
client [13] (testset)   loss: 1.0953 -> 1.0975  accuracy: 87.82% -> 87.82%     
client [1]  (testset)   loss: 0.6892 -> 0.6917  accuracy: 93.65% -> 93.65%     
client [42] (testset)   loss: 0.1297 -> 0.1301  accuracy: 98.67% -> 98.67%     
client [12] (testset)   loss: 0.2623 -> 0.2631  accuracy: 94.19% -> 94.19%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [23] (testset)   loss: 0.3603 -> 0.3649  accuracy: 94.95% -> 94.95%     
client [68] (testset)   loss: 0.2979 -> 0.2993  accuracy: 94.55% -> 94.55%     
client [46] (testset)   loss: 0.6393 -> 0.6600  accuracy: 90.62% -> 90.62%     
client [25] (testset)   loss: 0.2803 -> 0.2813  accuracy: 96.15% -> 96.15%     
client [41] (testset)   loss: 0.3641 -> 0.3642  accuracy: 92.74% -> 93.15%     
client [58] (testset)   loss: 0.2627 -> 0.2622  accuracy: 94.39% -> 94.39%     
client [33] (testset)   loss: 0.2070 -> 0.2027  accuracy: 95.32% -> 96.49%     
client [14] (testset)   loss: 0.6843 -> 0.6863  accuracy: 89.76% -> 89.76%     
client [85] (testset)   loss: 0.0820 -> 0.0823  accuracy: 98.25% -> 98.25%     
client [62] (testset)   loss: 0.6552 -> 0.6572  accuracy: 90.00% -> 90.00%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 1.2629 -> 1.2662  accuracy: 89.36% -> 89.36%     
client [63] (testset)   loss: 0.0496 -> 0.0499  accuracy: 98.97% -> 98.97%     
client [70] (testset)   loss: 0.5342 -> 0.5340  accuracy: 91.89% -> 91.89%     
client [65] (testset)   loss: 1.0626 -> 1.0642  accuracy: 87.50% -> 87.50%     
client [73] (testset)   loss: 0.0539 -> 0.0549  accuracy: 99.24% -> 99.24%     
client [34] (testset)   loss: 0.6630 -> 0.6622  accuracy: 96.15% -> 96.15%     
client [14] (testset)   loss: 0.6918 -> 0.6929  accuracy: 89.76% -> 89.76%     
client [69] (testset)   loss: 0.4855 -> 0.4868  accuracy: 95.68% -> 95.68%     
client [99] (testset)   loss: 0.1701 -> 0.1700  accuracy: 98.42% -> 98.42%     
client [46] (testset)   loss: 0.6601 -> 0.6442  accuracy: 90.62% -> 90.62%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [93] (testset)   loss: 0.0247 -> 0.0246  accuracy: 98.31% -> 98.31%     
client [11] (testset)   loss: 0.5807 -> 0.5906  accuracy: 89.24% -> 89.24%     
client [99] (testset)   loss: 0.1721 -> 0.1715  accuracy: 98.42% -> 98.42%     
client [81] (testset)   loss: 0.0871 -> 0.0866  accuracy: 98.15% -> 98.15%     
client [85] (testset)   loss: 0.0826 -> 0.0827  accuracy: 98.25% -> 98.25%     
client [58] (testset)   loss: 0.2628 -> 0.2647  accuracy: 94.39% -> 94.39%     
client [89] (testset)   loss: 1.0227 -> 1.0262  accuracy: 89.47% -> 89.47%     
client [45] (testset)   loss: 0.7017 -> 0.7162  accuracy: 86.49% -> 86.49%     
client [68] (testset)   loss: 0.3054 -> 0.3059  accuracy: 94.55% -> 94.55%     
client [8]  (testset)   loss: 0.6087 -> 0.6118  accuracy: 91.37% -> 91.37%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [72] (testset)   loss: 0.0709 -> 0.0698  accuracy: 96.49% -> 98.25%     
client [1]  (testset)   loss: 0.7018 -> 0.7033  accuracy: 93.65% -> 93.65%     
client [67] (testset)   loss: 0.3898 -> 0.3909  accuracy: 96.22% -> 96.22%     
client [78] (testset)   loss: 0.0011 -> 0.0011  accuracy: 100.00% -> 100.00%   
client [83] (testset)   loss: 0.0626 -> 0.0617  accuracy: 98.73% -> 98.73%     
client [21] (testset)   loss: 0.3702 -> 0.3791  accuracy: 91.93% -> 91.93%     
client [44] (testset)   loss: 0.0858 -> 0.0882  accuracy: 97.17% -> 97.17%     
client [56] (testset)   loss: 0.9326 -> 0.9373  accuracy: 88.24% -> 88.24%     
client [27] (testset)   loss: 0.0324 -> 0.0316  accuracy: 97.67% -> 97.67%     
client [92] (testset)   loss: 0.2380 -> 0.2388  accuracy: 96.35% -> 96.35%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [39] (testset)   loss: 0.0006 -> 0.0006  accuracy: 100.00% -> 100.00%   
client [10] (testset)   loss: 0.0060 -> 0.0060  accuracy: 100.00% -> 100.00%   
client [65] (testset)   loss: 1.0849 -> 1.0911  accuracy: 87.50% -> 87.50%     
client [19] (testset)   loss: 0.5709 -> 0.5746  accuracy: 89.83% -> 89.83%     
client [68] (testset)   loss: 0.3078 -> 0.3090  accuracy: 94.55% -> 94.55%     
client [41] (testset)   loss: 0.3709 -> 0.3728  accuracy: 93.15% -> 92.74%     
client [26] (testset)   loss: 0.0977 -> 0.0956  accuracy: 97.93% -> 98.25%     
client [75] (testset)   loss: 0.7393 -> 0.7363  accuracy: 88.04% -> 88.04%     
client [50] (testset)   loss: 0.0406 -> 0.0407  accuracy: 98.86% -> 98.86%     
client [81] (testset)   loss: 0.0858 -> 0.0862  accuracy: 98.15% -> 98.15%     
LG-FedAvg's average time taken by each global epoch: 0 min 2.87 sec.           
LG-FedAvg's total running time: 0 h 20 m 55 s.                                 
==================== LG-FedAvg Experiment Results: ====================        
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.2124 -> 0.2136",                                    
                "accuracy": "95.22% -> 95.32%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.2644 -> 0.2659",                                    
                "accuracy": "95.36% -> 95.38%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.2889 -> 0.2904",                                    
                "accuracy": "95.34% -> 95.34%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.3046 -> 0.3061",                                    
                "accuracy": "95.35% -> 95.33%"                                 
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== LG-FedAvg Max Accuracy ====================               
all_clients:                                                                   
(test) before fine-tuning: 95.36% at epoch 200                                 
(test) after fine-tuning: 95.38% at epoch 200                                  
