==================== LG-FedAvg ====================                            
Experiment Arguments:                                                          
{
    'method': 'lgfedavg',
    'dataset': {
        'name': 'mnist',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'mnist-100clients-0%IID-Dir(0.5)-seed42',
        'alpha': 0.5,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'parallel',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': 24.0,
        'num_gpus': 1.0,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 400,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 5,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'lgfedavg': {
        'num_global_layers': 1
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 0.4716 -> 0.5205  accuracy: 89.41% -> 89.41%     
client [81] (testset)   loss: 0.1755 -> 0.1744  accuracy: 94.61% -> 94.19%     
client [21] (testset)   loss: 0.1004 -> 0.0713  accuracy: 96.65% -> 98.09%     
client [93] (testset)   loss: 0.0909 -> 0.0994  accuracy: 97.16% -> 96.45%     
client [68] (testset)   loss: 0.0909 -> 0.0590  accuracy: 96.88% -> 98.21%     
client [20] (testset)   loss: 0.2235 -> 0.2317  accuracy: 93.66% -> 93.66%     
client [31] (testset)   loss: 0.3061 -> 0.1505  accuracy: 89.84% -> 95.72%     
client [59] (testset)   loss: 0.0766 -> 0.0734  accuracy: 97.92% -> 96.88%     
client [48] (testset)   loss: 0.0612 -> 0.0672  accuracy: 97.87% -> 97.87%     
client [34] (testset)   loss: 0.0840 -> 0.0996  accuracy: 97.38% -> 97.38%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 0.2286 -> 0.1964  accuracy: 92.86% -> 94.29%     
client [99] (testset)   loss: 0.1683 -> 0.1693  accuracy: 92.31% -> 93.49%     
client [67] (testset)   loss: 0.0838 -> 0.0838  accuracy: 97.14% -> 97.14%     
client [0]  (testset)   loss: 0.1716 -> 0.1733  accuracy: 94.90% -> 95.86%     
client [76] (testset)   loss: 0.1025 -> 0.1033  accuracy: 96.17% -> 96.17%     
client [62] (testset)   loss: 0.1152 -> 0.0380  accuracy: 95.76% -> 97.58%     
client [41] (testset)   loss: 0.1947 -> 0.1645  accuracy: 91.93% -> 94.62%     
client [14] (testset)   loss: 0.1882 -> 0.1927  accuracy: 93.75% -> 95.45%     
client [2]  (testset)   loss: 0.1364 -> 0.0671  accuracy: 95.78% -> 97.73%     
client [46] (testset)   loss: 0.1187 -> 0.1220  accuracy: 95.41% -> 95.41%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 0.1691 -> 0.1743  accuracy: 96.84% -> 96.84%     
client [57] (testset)   loss: 0.2570 -> 0.2644  accuracy: 96.81% -> 96.81%     
client [68] (testset)   loss: 0.0669 -> 0.0674  accuracy: 98.21% -> 98.21%     
client [17] (testset)   loss: 0.3678 -> 0.3438  accuracy: 91.13% -> 91.94%     
client [23] (testset)   loss: 0.2041 -> 0.0547  accuracy: 94.78% -> 98.26%     
client [54] (testset)   loss: 0.1692 -> 0.1749  accuracy: 96.02% -> 96.02%     
client [59] (testset)   loss: 0.0898 -> 0.0939  accuracy: 96.88% -> 96.88%     
client [35] (testset)   loss: 0.4762 -> 0.4619  accuracy: 89.08% -> 90.76%     
client [9]  (testset)   loss: 0.2211 -> 0.2259  accuracy: 90.91% -> 90.91%     
client [31] (testset)   loss: 0.1521 -> 0.1561  accuracy: 97.33% -> 97.33%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 0.3798 -> 0.3747  accuracy: 92.86% -> 92.86%     
client [33] (testset)   loss: 0.1208 -> 0.1220  accuracy: 95.58% -> 95.58%     
client [16] (testset)   loss: 0.2255 -> 0.2326  accuracy: 92.44% -> 93.28%     
client [8]  (testset)   loss: 0.0379 -> 0.0427  accuracy: 98.53% -> 97.06%     
client [31] (testset)   loss: 0.1589 -> 0.1615  accuracy: 97.33% -> 97.86%     
client [44] (testset)   loss: 0.1079 -> 0.0710  accuracy: 96.60% -> 98.02%     
client [36] (testset)   loss: 0.1107 -> 0.1010  accuracy: 94.59% -> 95.37%     
client [20] (testset)   loss: 0.3112 -> 0.3244  accuracy: 94.37% -> 94.37%     
client [47] (testset)   loss: 0.1169 -> 0.1185  accuracy: 96.41% -> 96.41%     
client [56] (testset)   loss: 0.1229 -> 0.1222  accuracy: 97.69% -> 98.08%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 0.4441 -> 0.4539  accuracy: 93.67% -> 93.67%     
client [60] (testset)   loss: 0.0990 -> 0.1011  accuracy: 98.04% -> 98.04%     
client [25] (testset)   loss: 0.4721 -> 0.4802  accuracy: 92.96% -> 92.96%     
client [28] (testset)   loss: 0.1025 -> 0.1039  accuracy: 96.57% -> 96.57%     
client [58] (testset)   loss: 0.1928 -> 0.2021  accuracy: 94.90% -> 94.90%     
client [39] (testset)   loss: 0.2048 -> 0.2087  accuracy: 93.25% -> 93.87%     
client [44] (testset)   loss: 0.0720 -> 0.0766  accuracy: 98.02% -> 97.45%     
client [3]  (testset)   loss: 0.7609 -> 0.5561  accuracy: 84.85% -> 85.86%     
client [29] (testset)   loss: 0.0781 -> 0.0696  accuracy: 97.09% -> 97.09%     
client [84] (testset)   loss: 0.1049 -> 0.1074  accuracy: 96.41% -> 95.96%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 0.0737 -> 0.0741  accuracy: 97.61% -> 98.09%     
client [84] (testset)   loss: 0.1094 -> 0.1101  accuracy: 96.41% -> 96.41%     
client [10] (testset)   loss: 0.0298 -> 0.0301  accuracy: 98.53% -> 98.53%     
client [36] (testset)   loss: 0.1057 -> 0.1075  accuracy: 96.14% -> 95.75%     
client [65] (testset)   loss: 0.1114 -> 0.1131  accuracy: 97.45% -> 97.45%     
client [81] (testset)   loss: 0.1868 -> 0.1904  accuracy: 94.61% -> 94.61%     
client [79] (testset)   loss: 0.2675 -> 0.2708  accuracy: 95.24% -> 95.24%     
client [42] (testset)   loss: 0.2327 -> 0.2371  accuracy: 95.19% -> 95.19%     
client [11] (testset)   loss: 0.1220 -> 0.1149  accuracy: 95.07% -> 95.52%     
client [96] (testset)   loss: 0.0809 -> 0.0819  accuracy: 97.89% -> 97.89%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 0.0420 -> 0.0404  accuracy: 97.06% -> 97.06%     
client [53] (testset)   loss: 0.3055 -> 0.3050  accuracy: 93.50% -> 93.50%     
client [52] (testset)   loss: 0.3548 -> 0.3562  accuracy: 96.10% -> 96.10%     
client [42] (testset)   loss: 0.2432 -> 0.2463  accuracy: 95.19% -> 95.19%     
client [69] (testset)   loss: 0.2318 -> 0.2321  accuracy: 93.57% -> 94.29%     
client [59] (testset)   loss: 0.1126 -> 0.1152  accuracy: 96.88% -> 96.88%     
client [7]  (testset)   loss: 0.0543 -> 0.0541  accuracy: 98.67% -> 98.67%     
client [26] (testset)   loss: 0.1755 -> 0.1742  accuracy: 95.93% -> 95.93%     
client [98] (testset)   loss: 0.1742 -> 0.1765  accuracy: 96.19% -> 96.19%     
client [49] (testset)   loss: 0.1690 -> 0.1727  accuracy: 94.85% -> 94.85%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 0.1784 -> 0.1769  accuracy: 96.19% -> 96.19%     
client [21] (testset)   loss: 0.0744 -> 0.0759  accuracy: 98.09% -> 97.61%     
client [47] (testset)   loss: 0.1282 -> 0.1295  accuracy: 96.41% -> 96.98%     
client [77] (testset)   loss: 0.7443 -> 0.7458  accuracy: 89.41% -> 89.41%     
client [91] (testset)   loss: 0.0905 -> 0.0922  accuracy: 98.23% -> 98.23%     
client [95] (testset)   loss: 0.1773 -> 0.1789  accuracy: 94.37% -> 94.37%     
client [14] (testset)   loss: 0.2515 -> 0.2539  accuracy: 94.89% -> 94.89%     
client [99] (testset)   loss: 0.1842 -> 0.1851  accuracy: 92.90% -> 92.31%     
client [20] (testset)   loss: 0.3539 -> 0.3559  accuracy: 94.37% -> 94.37%     
client [39] (testset)   loss: 0.2222 -> 0.2243  accuracy: 93.87% -> 93.87%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 0.3652 -> 0.3657  accuracy: 96.10% -> 96.10%     
client [62] (testset)   loss: 0.0385 -> 0.0387  accuracy: 98.18% -> 98.18%     
client [71] (testset)   loss: 0.2841 -> 0.2835  accuracy: 93.59% -> 93.59%     
client [97] (testset)   loss: 0.2122 -> 0.2137  accuracy: 94.94% -> 94.94%     
client [30] (testset)   loss: 0.0666 -> 0.0668  accuracy: 98.06% -> 98.06%     
client [88] (testset)   loss: 0.0054 -> 0.0054  accuracy: 100.00% -> 100.00%   
client [60] (testset)   loss: 0.1179 -> 0.1186  accuracy: 98.04% -> 98.04%     
client [91] (testset)   loss: 0.0920 -> 0.0929  accuracy: 98.23% -> 98.23%     
client [57] (testset)   loss: 0.3119 -> 0.3129  accuracy: 96.81% -> 96.81%     
client [82] (testset)   loss: 0.0633 -> 0.0624  accuracy: 98.48% -> 98.48%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [15] (testset)   loss: 0.1765 -> 0.1765  accuracy: 95.48% -> 95.48%     
client [31] (testset)   loss: 0.1877 -> 0.1874  accuracy: 97.33% -> 97.86%     
client [71] (testset)   loss: 0.2862 -> 0.2890  accuracy: 93.59% -> 93.59%     
client [97] (testset)   loss: 0.2151 -> 0.2156  accuracy: 94.94% -> 94.94%     
client [77] (testset)   loss: 0.7597 -> 0.7686  accuracy: 89.41% -> 89.41%     
client [53] (testset)   loss: 0.3306 -> 0.3367  accuracy: 92.68% -> 92.68%     
client [79] (testset)   loss: 0.2878 -> 0.2902  accuracy: 95.24% -> 95.24%     
client [76] (testset)   loss: 0.1321 -> 0.1344  accuracy: 96.17% -> 96.17%     
client [99] (testset)   loss: 0.1889 -> 0.1927  accuracy: 92.31% -> 92.90%     
client [28] (testset)   loss: 0.1115 -> 0.1125  accuracy: 96.57% -> 96.57%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 0.2173 -> 0.2185  accuracy: 94.94% -> 94.94%     
client [86] (testset)   loss: 0.3798 -> 0.3840  accuracy: 94.42% -> 94.42%     
client [73] (testset)   loss: 0.0801 -> 0.0814  accuracy: 97.09% -> 97.09%     
client [34] (testset)   loss: 0.1381 -> 0.1392  accuracy: 97.38% -> 97.38%     
client [5]  (testset)   loss: 0.2585 -> 0.2592  accuracy: 93.53% -> 93.53%     
client [96] (testset)   loss: 0.0881 -> 0.0884  accuracy: 97.89% -> 97.89%     
client [22] (testset)   loss: 0.1204 -> 0.1209  accuracy: 96.30% -> 96.30%     
client [60] (testset)   loss: 0.1236 -> 0.1242  accuracy: 98.04% -> 98.04%     
client [66] (testset)   loss: 0.1026 -> 0.1022  accuracy: 97.91% -> 97.91%     
client [83] (testset)   loss: 0.1850 -> 0.1868  accuracy: 96.64% -> 96.64%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 0.1384 -> 0.1398  accuracy: 96.17% -> 96.17%     
client [65] (testset)   loss: 0.1211 -> 0.1224  accuracy: 97.45% -> 97.45%     
client [17] (testset)   loss: 0.4268 -> 0.4349  accuracy: 91.13% -> 91.13%     
client [95] (testset)   loss: 0.1860 -> 0.1870  accuracy: 94.37% -> 94.37%     
client [8]  (testset)   loss: 0.0384 -> 0.0408  accuracy: 97.06% -> 97.06%     
client [35] (testset)   loss: 0.5946 -> 0.5976  accuracy: 90.76% -> 90.76%     
client [98] (testset)   loss: 0.1840 -> 0.1848  accuracy: 96.19% -> 96.19%     
client [53] (testset)   loss: 0.3418 -> 0.3510  accuracy: 92.68% -> 92.68%     
client [43] (testset)   loss: 0.2230 -> 0.2239  accuracy: 92.86% -> 92.86%     
client [64] (testset)   loss: 0.4249 -> 0.4292  accuracy: 92.86% -> 92.86%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [88] (testset)   loss: 0.0054 -> 0.0055  accuracy: 100.00% -> 100.00%   
client [21] (testset)   loss: 0.0777 -> 0.0785  accuracy: 97.61% -> 97.61%     
client [38] (testset)   loss: 0.1337 -> 0.1347  accuracy: 97.38% -> 97.38%     
client [3]  (testset)   loss: 0.6743 -> 0.6813  accuracy: 85.86% -> 85.86%     
client [5]  (testset)   loss: 0.2632 -> 0.2631  accuracy: 93.53% -> 93.53%     
client [41] (testset)   loss: 0.1766 -> 0.1770  accuracy: 95.07% -> 95.52%     
client [37] (testset)   loss: 0.1560 -> 0.1561  accuracy: 98.35% -> 98.35%     
client [7]  (testset)   loss: 0.0580 -> 0.0582  accuracy: 98.67% -> 98.67%     
client [45] (testset)   loss: 0.1070 -> 0.1089  accuracy: 97.89% -> 97.89%     
client [47] (testset)   loss: 0.1361 -> 0.1374  accuracy: 96.79% -> 96.60%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 0.2839 -> 0.2838  accuracy: 91.60% -> 92.44%     
client [11] (testset)   loss: 0.1310 -> 0.1309  accuracy: 95.52% -> 95.52%     
client [37] (testset)   loss: 0.1598 -> 0.1612  accuracy: 98.35% -> 97.52%     
client [41] (testset)   loss: 0.1778 -> 0.1786  accuracy: 95.52% -> 95.52%     
client [53] (testset)   loss: 0.3548 -> 0.3570  accuracy: 92.68% -> 92.68%     
client [95] (testset)   loss: 0.1911 -> 0.1918  accuracy: 94.37% -> 94.37%     
client [25] (testset)   loss: 0.5558 -> 0.5607  accuracy: 92.96% -> 92.96%     
client [22] (testset)   loss: 0.1232 -> 0.1235  accuracy: 96.30% -> 96.30%     
client [46] (testset)   loss: 0.1491 -> 0.1501  accuracy: 95.41% -> 95.41%     
client [69] (testset)   loss: 0.2546 -> 0.2559  accuracy: 94.29% -> 94.29%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [69] (testset)   loss: 0.2569 -> 0.2589  accuracy: 94.29% -> 94.29%     
client [47] (testset)   loss: 0.1421 -> 0.1428  accuracy: 96.98% -> 96.79%     
client [82] (testset)   loss: 0.0679 -> 0.0670  accuracy: 98.48% -> 98.48%     
client [45] (testset)   loss: 0.1094 -> 0.1089  accuracy: 97.89% -> 97.89%     
client [7]  (testset)   loss: 0.0588 -> 0.0600  accuracy: 98.67% -> 98.67%     
client [50] (testset)   loss: 0.1851 -> 0.1844  accuracy: 95.51% -> 95.51%     
client [35] (testset)   loss: 0.6076 -> 0.6136  accuracy: 90.76% -> 90.76%     
client [24] (testset)   loss: 0.2304 -> 0.2314  accuracy: 96.84% -> 96.84%     
client [15] (testset)   loss: 0.1829 -> 0.1851  accuracy: 95.48% -> 95.48%     
client [58] (testset)   loss: 0.2270 -> 0.2290  accuracy: 94.90% -> 94.90%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 0.0822 -> 0.0827  accuracy: 97.16% -> 97.16%     
client [76] (testset)   loss: 0.1431 -> 0.1438  accuracy: 96.17% -> 96.17%     
client [37] (testset)   loss: 0.1624 -> 0.1621  accuracy: 97.52% -> 98.35%     
client [67] (testset)   loss: 0.0965 -> 0.0963  accuracy: 97.14% -> 97.14%     
client [64] (testset)   loss: 0.4436 -> 0.4447  accuracy: 92.86% -> 92.86%     
client [58] (testset)   loss: 0.2305 -> 0.2315  accuracy: 94.90% -> 94.90%     
client [77] (testset)   loss: 0.8092 -> 0.8132  accuracy: 89.41% -> 88.24%     
client [12] (testset)   loss: 0.1956 -> 0.1963  accuracy: 95.74% -> 95.74%     
client [55] (testset)   loss: 0.0868 -> 0.0868  accuracy: 98.13% -> 98.13%     
client [89] (testset)   loss: 0.2211 -> 0.2211  accuracy: 95.34% -> 95.34%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [51] (testset)   loss: 0.0527 -> 0.0529  accuracy: 97.51% -> 97.51%     
client [84] (testset)   loss: 0.1279 -> 0.1282  accuracy: 96.41% -> 96.41%     
client [8]  (testset)   loss: 0.0396 -> 0.0401  accuracy: 97.06% -> 97.06%     
client [18] (testset)   loss: 0.1455 -> 0.1435  accuracy: 96.32% -> 96.32%     
client [94] (testset)   loss: 0.2782 -> 0.2797  accuracy: 93.29% -> 93.29%     
client [3]  (testset)   loss: 0.7005 -> 0.7071  accuracy: 86.87% -> 86.87%     
client [81] (testset)   loss: 0.2163 -> 0.2170  accuracy: 94.61% -> 94.61%     
client [11] (testset)   loss: 0.1343 -> 0.1344  accuracy: 95.52% -> 95.52%     
client [95] (testset)   loss: 0.1961 -> 0.1965  accuracy: 94.37% -> 94.37%     
client [67] (testset)   loss: 0.0965 -> 0.0972  accuracy: 97.14% -> 97.14%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [79] (testset)   loss: 0.3186 -> 0.3192  accuracy: 95.24% -> 95.24%     
client [21] (testset)   loss: 0.0806 -> 0.0810  accuracy: 97.61% -> 97.61%     
client [88] (testset)   loss: 0.0054 -> 0.0053  accuracy: 100.00% -> 100.00%   
client [58] (testset)   loss: 0.2326 -> 0.2343  accuracy: 94.90% -> 94.90%     
client [46] (testset)   loss: 0.1545 -> 0.1548  accuracy: 95.41% -> 95.41%     
client [11] (testset)   loss: 0.1349 -> 0.1355  accuracy: 95.52% -> 95.52%     
client [55] (testset)   loss: 0.0887 -> 0.0899  accuracy: 98.13% -> 98.13%     
client [13] (testset)   loss: 0.3832 -> 0.3848  accuracy: 94.43% -> 94.43%     
client [75] (testset)   loss: 0.0675 -> 0.0686  accuracy: 97.44% -> 97.44%     
client [31] (testset)   loss: 0.1992 -> 0.1988  accuracy: 97.33% -> 97.33%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 0.0966 -> 0.0963  accuracy: 96.55% -> 96.55%     
client [57] (testset)   loss: 0.3467 -> 0.3483  accuracy: 95.74% -> 95.74%     
client [7]  (testset)   loss: 0.0608 -> 0.0605  accuracy: 98.67% -> 98.67%     
client [43] (testset)   loss: 0.2334 -> 0.2335  accuracy: 92.86% -> 92.86%     
client [91] (testset)   loss: 0.0993 -> 0.0998  accuracy: 98.23% -> 98.23%     
client [13] (testset)   loss: 0.3873 -> 0.3893  accuracy: 94.43% -> 94.43%     
client [64] (testset)   loss: 0.4576 -> 0.4586  accuracy: 92.86% -> 92.86%     
client [10] (testset)   loss: 0.0344 -> 0.0350  accuracy: 98.53% -> 98.53%     
client [22] (testset)   loss: 0.1291 -> 0.1295  accuracy: 96.30% -> 96.30%     
client [82] (testset)   loss: 0.0697 -> 0.0698  accuracy: 98.48% -> 98.48%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [23] (testset)   loss: 0.0556 -> 0.0557  accuracy: 98.26% -> 98.26%     
client [20] (testset)   loss: 0.3890 -> 0.3897  accuracy: 94.37% -> 94.37%     
client [88] (testset)   loss: 0.0053 -> 0.0052  accuracy: 100.00% -> 100.00%   
client [98] (testset)   loss: 0.1919 -> 0.1929  accuracy: 96.19% -> 96.19%     
client [79] (testset)   loss: 0.3236 -> 0.3246  accuracy: 95.24% -> 95.24%     
client [92] (testset)   loss: 0.1927 -> 0.1940  accuracy: 96.49% -> 96.49%     
client [21] (testset)   loss: 0.0818 -> 0.0823  accuracy: 97.61% -> 97.61%     
client [5]  (testset)   loss: 0.2745 -> 0.2742  accuracy: 92.94% -> 92.94%     
client [56] (testset)   loss: 0.1622 -> 0.1627  accuracy: 98.08% -> 98.08%     
client [52] (testset)   loss: 0.4143 -> 0.4146  accuracy: 96.10% -> 96.10%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 0.1000 -> 0.1003  accuracy: 97.14% -> 97.14%     
client [54] (testset)   loss: 0.2255 -> 0.2264  accuracy: 96.02% -> 96.02%     
client [14] (testset)   loss: 0.2959 -> 0.2938  accuracy: 94.89% -> 94.89%     
client [99] (testset)   loss: 0.2105 -> 0.2117  accuracy: 92.90% -> 92.90%     
client [30] (testset)   loss: 0.0723 -> 0.0722  accuracy: 98.06% -> 98.06%     
client [36] (testset)   loss: 0.1355 -> 0.1357  accuracy: 95.75% -> 96.14%     
client [38] (testset)   loss: 0.1422 -> 0.1422  accuracy: 97.38% -> 97.38%     
client [15] (testset)   loss: 0.1899 -> 0.1894  accuracy: 95.48% -> 95.48%     
client [6]  (testset)   loss: 0.1922 -> 0.1920  accuracy: 96.05% -> 96.05%     
client [53] (testset)   loss: 0.3948 -> 0.3955  accuracy: 92.68% -> 92.68%     
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [6]  (testset)   loss: 0.1926 -> 0.1913  accuracy: 96.05% -> 96.05%     
client [99] (testset)   loss: 0.2136 -> 0.2143  accuracy: 92.31% -> 92.31%     
client [83] (testset)   loss: 0.2000 -> 0.2002  accuracy: 96.64% -> 96.64%     
client [42] (testset)   loss: 0.2945 -> 0.2960  accuracy: 95.19% -> 95.19%     
client [15] (testset)   loss: 0.1899 -> 0.1910  accuracy: 95.48% -> 95.48%     
client [34] (testset)   loss: 0.1487 -> 0.1492  accuracy: 97.38% -> 97.38%     
client [55] (testset)   loss: 0.0907 -> 0.0909  accuracy: 98.13% -> 98.13%     
client [47] (testset)   loss: 0.1510 -> 0.1514  accuracy: 96.60% -> 96.60%     
client [51] (testset)   loss: 0.0539 -> 0.0541  accuracy: 97.51% -> 97.51%     
client [95] (testset)   loss: 0.2012 -> 0.2017  accuracy: 94.84% -> 94.84%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 0.3169 -> 0.3171  accuracy: 93.59% -> 93.59%     
client [15] (testset)   loss: 0.1914 -> 0.1913  accuracy: 95.48% -> 95.48%     
client [33] (testset)   loss: 0.1397 -> 0.1416  accuracy: 95.03% -> 95.03%     
client [99] (testset)   loss: 0.2159 -> 0.2167  accuracy: 92.90% -> 92.90%     
client [90] (testset)   loss: 0.1867 -> 0.1860  accuracy: 97.12% -> 97.12%     
client [57] (testset)   loss: 0.3604 -> 0.3615  accuracy: 95.74% -> 95.74%     
client [78] (testset)   loss: 0.0838 -> 0.0839  accuracy: 98.80% -> 98.80%     
client [27] (testset)   loss: 0.1704 -> 0.1712  accuracy: 96.95% -> 96.95%     
client [88] (testset)   loss: 0.0051 -> 0.0052  accuracy: 100.00% -> 100.00%   
client [36] (testset)   loss: 0.1370 -> 0.1376  accuracy: 95.75% -> 95.75%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 0.4778 -> 0.4813  accuracy: 86.49% -> 86.49%     
client [35] (testset)   loss: 0.6436 -> 0.6430  accuracy: 90.76% -> 90.76%     
client [16] (testset)   loss: 0.3099 -> 0.3113  accuracy: 91.60% -> 91.60%     
client [80] (testset)   loss: 0.0124 -> 0.0124  accuracy: 100.00% -> 100.00%   
client [78] (testset)   loss: 0.0838 -> 0.0840  accuracy: 98.80% -> 98.80%     
client [38] (testset)   loss: 0.1443 -> 0.1445  accuracy: 97.38% -> 97.38%     
client [11] (testset)   loss: 0.1395 -> 0.1401  accuracy: 95.52% -> 95.52%     
client [68] (testset)   loss: 0.0776 -> 0.0771  accuracy: 98.21% -> 98.21%     
client [64] (testset)   loss: 0.4728 -> 0.4742  accuracy: 93.65% -> 93.65%     
client [82] (testset)   loss: 0.0717 -> 0.0719  accuracy: 98.48% -> 98.48%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 0.0731 -> 0.0735  accuracy: 98.06% -> 98.06%     
client [27] (testset)   loss: 0.1722 -> 0.1728  accuracy: 96.95% -> 96.95%     
client [74] (testset)   loss: 0.1052 -> 0.1057  accuracy: 96.75% -> 96.75%     
client [45] (testset)   loss: 0.1164 -> 0.1168  accuracy: 97.89% -> 97.89%     
client [6]  (testset)   loss: 0.1968 -> 0.1964  accuracy: 96.05% -> 96.05%     
client [36] (testset)   loss: 0.1383 -> 0.1390  accuracy: 96.14% -> 95.75%     
client [63] (testset)   loss: 0.2664 -> 0.2676  accuracy: 95.37% -> 95.37%     
client [76] (testset)   loss: 0.1516 -> 0.1527  accuracy: 96.17% -> 96.17%     
client [83] (testset)   loss: 0.2020 -> 0.2021  accuracy: 96.64% -> 96.64%     
client [86] (testset)   loss: 0.4473 -> 0.4472  accuracy: 94.42% -> 94.42%     
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 0.2025 -> 0.2029  accuracy: 96.64% -> 96.64%     
client [99] (testset)   loss: 0.2186 -> 0.2189  accuracy: 92.90% -> 92.90%     
client [74] (testset)   loss: 0.1062 -> 0.1064  accuracy: 96.75% -> 96.75%     
client [73] (testset)   loss: 0.0918 -> 0.0942  accuracy: 97.09% -> 97.09%     
client [92] (testset)   loss: 0.1964 -> 0.1972  accuracy: 96.49% -> 96.49%     
client [29] (testset)   loss: 0.0775 -> 0.0787  accuracy: 97.09% -> 97.09%     
client [6]  (testset)   loss: 0.1973 -> 0.1983  accuracy: 96.05% -> 96.05%     
client [61] (testset)   loss: 0.1807 -> 0.1814  accuracy: 97.48% -> 97.48%     
client [67] (testset)   loss: 0.1031 -> 0.1032  accuracy: 97.14% -> 97.14%     
client [21] (testset)   loss: 0.0842 -> 0.0845  accuracy: 97.61% -> 97.61%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 0.2034 -> 0.2035  accuracy: 96.64% -> 96.64%     
client [32] (testset)   loss: 0.1923 -> 0.1929  accuracy: 94.70% -> 93.94%     
client [61] (testset)   loss: 0.1833 -> 0.1837  accuracy: 98.11% -> 97.48%     
client [95] (testset)   loss: 0.2045 -> 0.2047  accuracy: 95.31% -> 94.84%     
client [25] (testset)   loss: 0.6039 -> 0.6053  accuracy: 92.96% -> 92.96%     
client [27] (testset)   loss: 0.1736 -> 0.1737  accuracy: 96.95% -> 96.95%     
client [68] (testset)   loss: 0.0776 -> 0.0776  accuracy: 98.21% -> 98.21%     
client [71] (testset)   loss: 0.3211 -> 0.3234  accuracy: 93.59% -> 93.59%     
client [34] (testset)   loss: 0.1516 -> 0.1522  accuracy: 97.38% -> 97.38%     
client [89] (testset)   loss: 0.2301 -> 0.2298  accuracy: 95.34% -> 95.34%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 0.0851 -> 0.0853  accuracy: 98.80% -> 98.80%     
client [81] (testset)   loss: 0.2293 -> 0.2297  accuracy: 94.61% -> 94.61%     
client [51] (testset)   loss: 0.0555 -> 0.0557  accuracy: 97.51% -> 97.51%     
client [54] (testset)   loss: 0.2319 -> 0.2318  accuracy: 96.02% -> 96.02%     
client [65] (testset)   loss: 0.1352 -> 0.1353  accuracy: 97.45% -> 97.45%     
client [41] (testset)   loss: 0.1972 -> 0.1977  accuracy: 95.52% -> 95.52%     
client [11] (testset)   loss: 0.1428 -> 0.1425  accuracy: 95.52% -> 95.52%     
client [12] (testset)   loss: 0.2059 -> 0.2073  accuracy: 95.74% -> 95.74%     
client [85] (testset)   loss: 0.0959 -> 0.0964  accuracy: 97.38% -> 97.38%     
client [23] (testset)   loss: 0.0591 -> 0.0591  accuracy: 98.26% -> 98.26%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 0.3155 -> 0.3161  accuracy: 91.60% -> 91.60%     
client [65] (testset)   loss: 0.1361 -> 0.1364  accuracy: 97.45% -> 97.45%     
client [53] (testset)   loss: 0.4168 -> 0.4188  accuracy: 92.68% -> 92.68%     
client [58] (testset)   loss: 0.2432 -> 0.2451  accuracy: 94.90% -> 94.90%     
client [72] (testset)   loss: 0.0346 -> 0.0344  accuracy: 99.07% -> 99.07%     
client [71] (testset)   loss: 0.3250 -> 0.3236  accuracy: 93.59% -> 93.59%     
client [7]  (testset)   loss: 0.0631 -> 0.0625  accuracy: 98.67% -> 98.67%     
client [59] (testset)   loss: 0.1475 -> 0.1521  accuracy: 96.88% -> 96.88%     
client [86] (testset)   loss: 0.4571 -> 0.4581  accuracy: 94.42% -> 94.42%     
client [39] (testset)   loss: 0.2673 -> 0.2684  accuracy: 95.09% -> 95.09%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 0.2219 -> 0.2226  accuracy: 92.31% -> 92.90%     
client [7]  (testset)   loss: 0.0638 -> 0.0636  accuracy: 98.67% -> 98.67%     
client [17] (testset)   loss: 0.5292 -> 0.5315  accuracy: 91.13% -> 91.13%     
client [64] (testset)   loss: 0.4885 -> 0.4897  accuracy: 93.65% -> 93.65%     
client [37] (testset)   loss: 0.1752 -> 0.1752  accuracy: 97.52% -> 97.52%     
client [29] (testset)   loss: 0.0813 -> 0.0798  accuracy: 97.09% -> 97.09%     
client [93] (testset)   loss: 0.1674 -> 0.1678  accuracy: 97.16% -> 97.16%     
client [73] (testset)   loss: 0.0962 -> 0.0951  accuracy: 97.09% -> 97.09%     
client [40] (testset)   loss: 0.1266 -> 0.1271  accuracy: 98.30% -> 98.30%     
client [76] (testset)   loss: 0.1555 -> 0.1559  accuracy: 96.17% -> 96.17%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 0.2104 -> 0.2107  accuracy: 97.86% -> 97.86%     
client [89] (testset)   loss: 0.2328 -> 0.2331  accuracy: 95.34% -> 95.34%     
client [77] (testset)   loss: 0.8900 -> 0.8898  accuracy: 88.24% -> 88.24%     
client [90] (testset)   loss: 0.1942 -> 0.1943  accuracy: 97.12% -> 97.12%     
client [26] (testset)   loss: 0.1974 -> 0.1973  accuracy: 95.93% -> 95.93%     
client [50] (testset)   loss: 0.2054 -> 0.2053  accuracy: 95.51% -> 95.51%     
client [70] (testset)   loss: 0.4945 -> 0.4934  accuracy: 86.49% -> 86.49%     
client [30] (testset)   loss: 0.0744 -> 0.0741  accuracy: 98.06% -> 98.06%     
client [99] (testset)   loss: 0.2230 -> 0.2235  accuracy: 92.90% -> 92.90%     
client [41] (testset)   loss: 0.2000 -> 0.2000  accuracy: 95.52% -> 95.52%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [70] (testset)   loss: 0.4954 -> 0.4969  accuracy: 86.49% -> 86.49%     
client [52] (testset)   loss: 0.4373 -> 0.4393  accuracy: 96.10% -> 96.10%     
client [68] (testset)   loss: 0.0783 -> 0.0784  accuracy: 98.21% -> 98.21%     
client [1]  (testset)   loss: 0.3375 -> 0.3387  accuracy: 93.22% -> 93.22%     
client [2]  (testset)   loss: 0.0848 -> 0.0848  accuracy: 97.73% -> 97.73%     
client [67] (testset)   loss: 0.1061 -> 0.1063  accuracy: 97.14% -> 97.14%     
client [92] (testset)   loss: 0.2022 -> 0.2036  accuracy: 96.49% -> 96.49%     
client [35] (testset)   loss: 0.6623 -> 0.6645  accuracy: 90.76% -> 90.76%     
client [64] (testset)   loss: 0.4928 -> 0.4934  accuracy: 93.65% -> 93.65%     
client [36] (testset)   loss: 0.1450 -> 0.1456  accuracy: 96.14% -> 96.14%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [6]  (testset)   loss: 0.2034 -> 0.2037  accuracy: 96.05% -> 96.05%     
client [12] (testset)   loss: 0.2083 -> 0.2090  accuracy: 95.74% -> 95.74%     
client [44] (testset)   loss: 0.0871 -> 0.0874  accuracy: 97.73% -> 97.73%     
client [29] (testset)   loss: 0.0809 -> 0.0786  accuracy: 97.09% -> 97.09%     
client [9]  (testset)   loss: 0.3231 -> 0.3236  accuracy: 90.91% -> 90.91%     
client [55] (testset)   loss: 0.0940 -> 0.0943  accuracy: 98.13% -> 98.13%     
client [43] (testset)   loss: 0.2456 -> 0.2459  accuracy: 92.86% -> 92.86%     
client [77] (testset)   loss: 0.8932 -> 0.8954  accuracy: 88.24% -> 88.24%     
client [98] (testset)   loss: 0.2013 -> 0.2017  accuracy: 96.19% -> 96.19%     
client [78] (testset)   loss: 0.0863 -> 0.0864  accuracy: 98.80% -> 98.80%     
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 0.2040 -> 0.2038  accuracy: 96.49% -> 96.49%     
client [80] (testset)   loss: 0.0125 -> 0.0124  accuracy: 100.00% -> 100.00%   
client [76] (testset)   loss: 0.1577 -> 0.1581  accuracy: 96.17% -> 96.17%     
client [63] (testset)   loss: 0.2781 -> 0.2795  accuracy: 95.37% -> 95.37%     
client [25] (testset)   loss: 0.6194 -> 0.6213  accuracy: 92.96% -> 92.96%     
client [78] (testset)   loss: 0.0865 -> 0.0865  accuracy: 98.80% -> 98.80%     
client [58] (testset)   loss: 0.2480 -> 0.2488  accuracy: 94.90% -> 94.90%     
client [13] (testset)   loss: 0.4164 -> 0.4179  accuracy: 94.43% -> 94.43%     
client [17] (testset)   loss: 0.5422 -> 0.5437  accuracy: 91.13% -> 91.13%     
client [38] (testset)   loss: 0.1515 -> 0.1515  accuracy: 97.38% -> 97.38%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 0.0347 -> 0.0347  accuracy: 99.07% -> 99.07%     
client [82] (testset)   loss: 0.0748 -> 0.0748  accuracy: 98.48% -> 98.48%     
client [86] (testset)   loss: 0.4719 -> 0.4734  accuracy: 94.42% -> 94.42%     
client [51] (testset)   loss: 0.0570 -> 0.0571  accuracy: 97.51% -> 97.51%     
client [96] (testset)   loss: 0.0987 -> 0.0988  accuracy: 97.89% -> 97.89%     
client [42] (testset)   loss: 0.3152 -> 0.3157  accuracy: 95.19% -> 95.19%     
client [13] (testset)   loss: 0.4185 -> 0.4198  accuracy: 94.43% -> 94.43%     
client [55] (testset)   loss: 0.0951 -> 0.0950  accuracy: 98.13% -> 98.13%     
client [12] (testset)   loss: 0.2096 -> 0.2101  accuracy: 95.74% -> 95.74%     
client [1]  (testset)   loss: 0.3420 -> 0.3433  accuracy: 93.22% -> 93.22%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [23] (testset)   loss: 0.0617 -> 0.0624  accuracy: 97.39% -> 97.39%     
client [68] (testset)   loss: 0.0790 -> 0.0791  accuracy: 98.21% -> 98.21%     
client [46] (testset)   loss: 0.1679 -> 0.1681  accuracy: 95.41% -> 95.41%     
client [25] (testset)   loss: 0.6270 -> 0.6286  accuracy: 92.96% -> 92.96%     
client [41] (testset)   loss: 0.2039 -> 0.2042  accuracy: 95.52% -> 95.52%     
client [58] (testset)   loss: 0.2485 -> 0.2492  accuracy: 94.90% -> 94.90%     
client [14] (testset)   loss: 0.3153 -> 0.3157  accuracy: 94.89% -> 94.89%     
client [33] (testset)   loss: 0.1464 -> 0.1454  accuracy: 95.03% -> 95.03%     
client [85] (testset)   loss: 0.0986 -> 0.0989  accuracy: 97.38% -> 97.38%     
client [62] (testset)   loss: 0.0420 -> 0.0422  accuracy: 98.18% -> 98.18%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 0.2031 -> 0.2036  accuracy: 96.19% -> 96.19%     
client [70] (testset)   loss: 0.5037 -> 0.5062  accuracy: 86.49% -> 86.49%     
client [63] (testset)   loss: 0.2827 -> 0.2827  accuracy: 95.37% -> 95.37%     
client [14] (testset)   loss: 0.3172 -> 0.3188  accuracy: 94.89% -> 94.89%     
client [65] (testset)   loss: 0.1395 -> 0.1395  accuracy: 97.45% -> 97.45%     
client [73] (testset)   loss: 0.0978 -> 0.0961  accuracy: 97.09% -> 97.09%     
client [34] (testset)   loss: 0.1573 -> 0.1571  accuracy: 97.38% -> 97.38%     
client [99] (testset)   loss: 0.2269 -> 0.2275  accuracy: 92.90% -> 92.90%     
client [69] (testset)   loss: 0.2819 -> 0.2827  accuracy: 94.29% -> 94.29%     
client [46] (testset)   loss: 0.1684 -> 0.1692  accuracy: 95.41% -> 95.41%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [93] (testset)   loss: 0.1717 -> 0.1725  accuracy: 97.16% -> 97.16%     
client [99] (testset)   loss: 0.2285 -> 0.2289  accuracy: 92.90% -> 92.90%     
client [58] (testset)   loss: 0.2511 -> 0.2515  accuracy: 94.90% -> 94.90%     
client [11] (testset)   loss: 0.1474 -> 0.1477  accuracy: 95.52% -> 95.52%     
client [81] (testset)   loss: 0.2376 -> 0.2378  accuracy: 94.61% -> 94.61%     
client [85] (testset)   loss: 0.0992 -> 0.0995  accuracy: 97.38% -> 97.38%     
client [45] (testset)   loss: 0.1222 -> 0.1218  accuracy: 97.89% -> 97.89%     
client [89] (testset)   loss: 0.2352 -> 0.2378  accuracy: 95.34% -> 95.34%     
client [8]  (testset)   loss: 0.0406 -> 0.0407  accuracy: 97.06% -> 97.06%     
client [68] (testset)   loss: 0.0790 -> 0.0791  accuracy: 98.21% -> 98.21%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 0.1080 -> 0.1084  accuracy: 97.14% -> 97.14%     
client [72] (testset)   loss: 0.0349 -> 0.0349  accuracy: 99.07% -> 99.07%     
client [1]  (testset)   loss: 0.3475 -> 0.3484  accuracy: 93.22% -> 93.22%     
client [78] (testset)   loss: 0.0876 -> 0.0878  accuracy: 98.80% -> 98.80%     
client [83] (testset)   loss: 0.2122 -> 0.2123  accuracy: 95.80% -> 95.80%     
client [21] (testset)   loss: 0.0892 -> 0.0892  accuracy: 97.61% -> 97.61%     
client [56] (testset)   loss: 0.1760 -> 0.1761  accuracy: 98.08% -> 98.08%     
client [92] (testset)   loss: 0.2058 -> 0.2057  accuracy: 96.49% -> 96.49%     
client [44] (testset)   loss: 0.0892 -> 0.0890  accuracy: 97.73% -> 97.73%     
client [27] (testset)   loss: 0.1814 -> 0.1822  accuracy: 96.95% -> 96.95%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [39] (testset)   loss: 0.2746 -> 0.2756  accuracy: 95.09% -> 95.09%     
client [10] (testset)   loss: 0.0388 -> 0.0388  accuracy: 98.53% -> 98.53%     
client [26] (testset)   loss: 0.2036 -> 0.2018  accuracy: 95.93% -> 95.93%     
client [65] (testset)   loss: 0.1403 -> 0.1408  accuracy: 97.45% -> 97.45%     
client [19] (testset)   loss: 0.1026 -> 0.1035  accuracy: 96.55% -> 96.55%     
client [68] (testset)   loss: 0.0795 -> 0.0795  accuracy: 98.21% -> 98.21%     
client [41] (testset)   loss: 0.2061 -> 0.2065  accuracy: 95.52% -> 95.52%     
client [50] (testset)   loss: 0.2137 -> 0.2131  accuracy: 95.51% -> 95.51%     
client [75] (testset)   loss: 0.0760 -> 0.0753  accuracy: 97.44% -> 97.44%     
client [81] (testset)   loss: 0.2391 -> 0.2394  accuracy: 94.61% -> 94.61%     
LG-FedAvg's average time taken by each global epoch: 0 min 3.13 sec.           
LG-FedAvg's total running time: 0 h 22 m 39 s.                                 
==================== LG-FedAvg Experiment Results: ====================        
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.1694 -> 0.1708",                                    
                "accuracy": "96.24% -> 96.23%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.1860 -> 0.1866",                                    
                "accuracy": "96.20% -> 96.19%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.1957 -> 0.1962",                                    
                "accuracy": "96.23% -> 96.23%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "0.2022 -> 0.2025",                                    
                "accuracy": "96.21% -> 96.22%"                                 
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== LG-FedAvg Max Accuracy ====================               
all_clients:                                                                   
(test) before fine-tuning: 96.24% at epoch 100                                 
(test) after fine-tuning: 96.23% at epoch 100                                  
