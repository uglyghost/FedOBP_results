==================== APFL ====================                                 
Experiment Arguments:                                                          
{
    'method': 'apfl',
    'dataset': {
        'name': 'medmnistA',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'medmnistA-100clients-0%IID-Dir(0.5)-seed42',
        'alpha': 0.5,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'serial',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': None,
        'num_gpus': None,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 400,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 5,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'apfl': {
        'alpha': 0.5,
        'adaptive_alpha': 1
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 1.8118 -> 1.6762  accuracy: 32.50% -> 32.50%     
client [81] (testset)   loss: 1.6928 -> 1.5750  accuracy: 38.50% -> 38.50%     
client [21] (testset)   loss: 2.3802 -> 1.9993  accuracy: 4.20% -> 21.01%      
client [68] (testset)   loss: 2.0052 -> 1.7775  accuracy: 41.84% -> 41.84%     
client [93] (testset)   loss: 1.2787 -> 1.1752  accuracy: 70.93% -> 70.93%     
client [31] (testset)   loss: 1.6650 -> 1.4951  accuracy: 58.87% -> 58.87%     
client [20] (testset)   loss: 1.8312 -> 1.6199  accuracy: 34.69% -> 34.69%     
client [59] (testset)   loss: 2.4027 -> 1.5453  accuracy: 0.91% -> 41.52%      
client [48] (testset)   loss: 1.9719 -> 1.8656  accuracy: 31.45% -> 31.45%     
client [34] (testset)   loss: 1.8585 -> 1.8196  accuracy: 40.48% -> 40.48%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 1.9841 -> 1.8904  accuracy: 34.13% -> 34.13%     
client [99] (testset)   loss: 1.9760 -> 2.0240  accuracy: 31.58% -> 31.58%     
client [67] (testset)   loss: 1.7845 -> 1.6208  accuracy: 37.43% -> 29.82%     
client [0]  (testset)   loss: 1.7549 -> 1.5710  accuracy: 46.99% -> 46.99%     
client [76] (testset)   loss: 1.9359 -> 1.9177  accuracy: 31.25% -> 31.25%     
client [41] (testset)   loss: 1.6284 -> 1.5100  accuracy: 39.88% -> 36.81%     
client [62] (testset)   loss: 2.1551 -> 1.8924  accuracy: 55.56% -> 55.56%     
client [2]  (testset)   loss: 2.4582 -> 1.9551  accuracy: 1.12% -> 28.09%      
client [14] (testset)   loss: 1.7278 -> 1.7045  accuracy: 41.94% -> 41.94%     
client [46] (testset)   loss: 2.0114 -> 1.9560  accuracy: 23.38% -> 23.38%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 1.9336 -> 1.8960  accuracy: 33.00% -> 33.00%     
client [68] (testset)   loss: 1.8840 -> 1.8087  accuracy: 41.84% -> 41.84%     
client [57] (testset)   loss: 1.8664 -> 1.7808  accuracy: 22.97% -> 31.58%     
client [17] (testset)   loss: 1.5975 -> 1.5890  accuracy: 58.91% -> 58.91%     
client [54] (testset)   loss: 1.6766 -> 1.6053  accuracy: 36.16% -> 36.16%     
client [23] (testset)   loss: 2.6045 -> 1.2062  accuracy: 0.00% -> 61.22%      
client [35] (testset)   loss: 1.8154 -> 1.6509  accuracy: 19.21% -> 36.16%     
client [59] (testset)   loss: 1.6620 -> 1.5325  accuracy: 41.52% -> 41.52%     
client [31] (testset)   loss: 1.7567 -> 1.4568  accuracy: 58.87% -> 58.87%     
client [9]  (testset)   loss: 1.9387 -> 1.8251  accuracy: 34.72% -> 34.72%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 1.9304 -> 1.7646  accuracy: 42.50% -> 42.50%     
client [33] (testset)   loss: 1.9601 -> 1.9271  accuracy: 28.57% -> 27.38%     
client [16] (testset)   loss: 1.9648 -> 1.9325  accuracy: 29.66% -> 15.25%     
client [44] (testset)   loss: 1.6370 -> 1.5297  accuracy: 57.08% -> 57.08%     
client [8]  (testset)   loss: 2.0785 -> 1.9783  accuracy: 29.22% -> 29.22%     
client [31] (testset)   loss: 1.8453 -> 1.4936  accuracy: 58.87% -> 58.87%     
client [47] (testset)   loss: 1.8829 -> 1.8068  accuracy: 40.35% -> 40.35%     
client [36] (testset)   loss: 2.0952 -> 1.8387  accuracy: 13.64% -> 32.58%     
client [20] (testset)   loss: 1.9158 -> 1.6298  accuracy: 36.73% -> 34.69%     
client [56] (testset)   loss: 1.5738 -> 1.5004  accuracy: 47.30% -> 47.30%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 1.8032 -> 1.7639  accuracy: 34.29% -> 34.29%     
client [60] (testset)   loss: 1.9116 -> 1.6390  accuracy: 53.77% -> 53.77%     
client [28] (testset)   loss: 1.8687 -> 1.7648  accuracy: 30.14% -> 30.14%     
client [25] (testset)   loss: 1.8421 -> 1.7623  accuracy: 38.46% -> 38.46%     
client [58] (testset)   loss: 1.9387 -> 1.8613  accuracy: 44.84% -> 44.84%     
client [44] (testset)   loss: 1.5478 -> 1.4877  accuracy: 57.08% -> 57.08%     
client [39] (testset)   loss: 1.8279 -> 1.8239  accuracy: 24.55% -> 24.55%     
client [29] (testset)   loss: 1.7684 -> 1.6010  accuracy: 35.83% -> 35.83%     
client [3]  (testset)   loss: 2.1817 -> 2.0270  accuracy: 13.29% -> 23.78%     
client [84] (testset)   loss: 1.7968 -> 1.7712  accuracy: 26.03% -> 26.03%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 2.0502 -> 1.9990  accuracy: 21.01% -> 21.01%     
client [84] (testset)   loss: 1.8759 -> 1.7340  accuracy: 26.03% -> 29.45%     
client [10] (testset)   loss: 1.2664 -> 1.1547  accuracy: 64.38% -> 64.38%     
client [36] (testset)   loss: 1.8846 -> 1.8695  accuracy: 32.58% -> 32.58%     
client [65] (testset)   loss: 1.9997 -> 1.9219  accuracy: 37.96% -> 37.96%     
client [81] (testset)   loss: 1.9324 -> 1.6010  accuracy: 27.65% -> 38.50%     
client [79] (testset)   loss: 1.8088 -> 1.8277  accuracy: 25.00% -> 25.00%     
client [42] (testset)   loss: 1.8791 -> 1.8118  accuracy: 33.02% -> 33.02%     
client [11] (testset)   loss: 1.8274 -> 1.7003  accuracy: 33.94% -> 33.94%     
client [96] (testset)   loss: 1.4945 -> 1.2639  accuracy: 58.85% -> 58.85%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 2.1166 -> 1.9806  accuracy: 29.22% -> 29.22%     
client [53] (testset)   loss: 1.6547 -> 1.5788  accuracy: 28.46% -> 36.92%     
client [52] (testset)   loss: 2.0013 -> 1.9693  accuracy: 18.92% -> 18.92%     
client [42] (testset)   loss: 1.8936 -> 1.7934  accuracy: 33.02% -> 33.02%     
client [69] (testset)   loss: 1.9658 -> 1.8840  accuracy: 34.13% -> 34.13%     
client [59] (testset)   loss: 1.7128 -> 1.5258  accuracy: 41.52% -> 41.52%     
client [7]  (testset)   loss: 1.5086 -> 1.2880  accuracy: 61.40% -> 61.40%     
client [26] (testset)   loss: 1.3148 -> 1.0511  accuracy: 70.51% -> 70.51%     
client [49] (testset)   loss: 1.9611 -> 1.8836  accuracy: 34.00% -> 34.00%     
client [98] (testset)   loss: 1.8847 -> 1.7653  accuracy: 45.03% -> 45.03%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 1.9863 -> 1.7648  accuracy: 45.03% -> 45.03%     
client [47] (testset)   loss: 1.8049 -> 1.7596  accuracy: 40.35% -> 40.35%     
client [21] (testset)   loss: 2.0446 -> 2.0584  accuracy: 18.49% -> 21.01%     
client [77] (testset)   loss: 1.7802 -> 1.7168  accuracy: 32.50% -> 26.25%     
client [95] (testset)   loss: 1.2303 -> 1.1156  accuracy: 70.40% -> 70.40%     
client [91] (testset)   loss: 1.8420 -> 1.6679  accuracy: 10.78% -> 43.14%     
client [14] (testset)   loss: 1.7026 -> 1.6933  accuracy: 41.94% -> 41.94%     
client [99] (testset)   loss: 2.0338 -> 2.0176  accuracy: 26.32% -> 31.58%     
client [20] (testset)   loss: 1.7742 -> 1.6058  accuracy: 34.69% -> 36.73%     
client [39] (testset)   loss: 1.8448 -> 1.8461  accuracy: 25.45% -> 24.55%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 2.0426 -> 1.9756  accuracy: 18.92% -> 20.27%     
client [62] (testset)   loss: 1.6443 -> 1.4997  accuracy: 55.56% -> 55.56%     
client [71] (testset)   loss: 1.9121 -> 1.8174  accuracy: 45.45% -> 45.45%     
client [97] (testset)   loss: 1.8296 -> 1.5736  accuracy: 48.88% -> 48.88%     
client [30] (testset)   loss: 1.8960 -> 1.7039  accuracy: 15.11% -> 46.04%     
client [88] (testset)   loss: 1.9564 -> 1.6300  accuracy: 23.30% -> 46.60%     
client [60] (testset)   loss: 1.7246 -> 1.6329  accuracy: 53.77% -> 53.77%     
client [82] (testset)   loss: 1.8504 -> 1.7165  accuracy: 24.79% -> 28.21%     
client [91] (testset)   loss: 1.8735 -> 1.6464  accuracy: 8.82% -> 43.14%      
client [57] (testset)   loss: 1.8867 -> 1.7885  accuracy: 22.97% -> 31.58%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 1.6014 -> 1.4757  accuracy: 58.87% -> 58.87%     
client [15] (testset)   loss: 1.7959 -> 1.6818  accuracy: 36.13% -> 36.13%     
client [71] (testset)   loss: 1.8381 -> 1.8161  accuracy: 45.45% -> 45.45%     
client [97] (testset)   loss: 1.7996 -> 1.5725  accuracy: 23.03% -> 48.88%     
client [53] (testset)   loss: 1.6582 -> 1.6125  accuracy: 36.92% -> 28.46%     
client [77] (testset)   loss: 1.8719 -> 1.7283  accuracy: 26.25% -> 26.25%     
client [76] (testset)   loss: 1.8686 -> 1.8817  accuracy: 31.25% -> 18.75%     
client [79] (testset)   loss: 1.8191 -> 1.8485  accuracy: 30.00% -> 30.00%     
client [28] (testset)   loss: 1.8710 -> 1.7721  accuracy: 17.81% -> 30.14%     
client [99] (testset)   loss: 2.0195 -> 2.0095  accuracy: 26.32% -> 31.58%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 1.7931 -> 1.5732  accuracy: 23.03% -> 48.88%     
client [86] (testset)   loss: 1.9064 -> 1.8554  accuracy: 25.32% -> 32.91%     
client [34] (testset)   loss: 1.8816 -> 1.8012  accuracy: 40.48% -> 40.48%     
client [73] (testset)   loss: 1.5219 -> 1.3410  accuracy: 24.46% -> 50.21%     
client [5]  (testset)   loss: 1.3676 -> 1.2537  accuracy: 66.67% -> 66.67%     
client [96] (testset)   loss: 1.6315 -> 1.2582  accuracy: 58.85% -> 58.85%     
client [22] (testset)   loss: 1.4927 -> 1.4161  accuracy: 48.72% -> 48.72%     
client [60] (testset)   loss: 1.7970 -> 1.6296  accuracy: 53.77% -> 53.77%     
client [66] (testset)   loss: 1.8519 -> 1.7439  accuracy: 28.00% -> 30.67%     
client [83] (testset)   loss: 1.5541 -> 1.3419  accuracy: 63.04% -> 63.04%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 1.9022 -> 1.8463  accuracy: 31.25% -> 31.25%     
client [65] (testset)   loss: 2.0717 -> 1.9433  accuracy: 37.96% -> 37.96%     
client [95] (testset)   loss: 1.3223 -> 1.1035  accuracy: 70.40% -> 70.40%     
client [17] (testset)   loss: 1.5507 -> 1.5462  accuracy: 58.91% -> 58.91%     
client [8]  (testset)   loss: 2.0137 -> 1.9740  accuracy: 29.22% -> 29.22%     
client [35] (testset)   loss: 1.7637 -> 1.6646  accuracy: 36.16% -> 28.81%     
client [98] (testset)   loss: 1.8417 -> 1.7634  accuracy: 45.03% -> 45.03%     
client [53] (testset)   loss: 1.7127 -> 1.6117  accuracy: 36.92% -> 36.92%     
client [43] (testset)   loss: 1.6519 -> 1.5080  accuracy: 46.33% -> 46.33%     
client [64] (testset)   loss: 1.8250 -> 1.7916  accuracy: 42.50% -> 42.50%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 2.2186 -> 1.9869  accuracy: 21.01% -> 21.01%     
client [88] (testset)   loss: 1.8017 -> 1.6464  accuracy: 46.60% -> 46.60%     
client [38] (testset)   loss: 1.1853 -> 1.0317  accuracy: 73.33% -> 73.33%     
client [3]  (testset)   loss: 2.1255 -> 2.0213  accuracy: 9.79% -> 23.78%      
client [5]  (testset)   loss: 1.4502 -> 1.2434  accuracy: 66.67% -> 66.67%     
client [41] (testset)   loss: 1.7775 -> 1.4880  accuracy: 39.88% -> 36.81%     
client [7]  (testset)   loss: 1.5302 -> 1.2793  accuracy: 61.40% -> 61.40%     
client [37] (testset)   loss: 1.6085 -> 1.4531  accuracy: 60.33% -> 60.33%     
client [45] (testset)   loss: 2.0398 -> 1.8781  accuracy: 23.21% -> 23.21%     
client [47] (testset)   loss: 1.9694 -> 1.7760  accuracy: 15.20% -> 40.35%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 2.0662 -> 1.8980  accuracy: 15.25% -> 29.66%     
client [11] (testset)   loss: 1.8236 -> 1.6991  accuracy: 33.94% -> 33.94%     
client [37] (testset)   loss: 1.8536 -> 1.4802  accuracy: 60.33% -> 60.33%     
client [41] (testset)   loss: 1.7185 -> 1.4760  accuracy: 36.81% -> 39.88%     
client [95] (testset)   loss: 1.6129 -> 1.1422  accuracy: 70.40% -> 70.40%     
client [53] (testset)   loss: 1.7762 -> 1.5652  accuracy: 28.46% -> 36.92%     
client [22] (testset)   loss: 1.6868 -> 1.3904  accuracy: 48.72% -> 48.72%     
client [25] (testset)   loss: 1.9248 -> 1.7545  accuracy: 38.46% -> 38.46%     
client [69] (testset)   loss: 1.9958 -> 1.8927  accuracy: 34.13% -> 34.13%     
client [46] (testset)   loss: 1.9750 -> 1.8869  accuracy: 23.38% -> 23.38%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 1.7939 -> 1.7523  accuracy: 40.35% -> 40.35%     
client [69] (testset)   loss: 1.9081 -> 1.8768  accuracy: 34.13% -> 34.13%     
client [82] (testset)   loss: 2.0448 -> 1.7316  accuracy: 24.79% -> 28.21%     
client [45] (testset)   loss: 2.0386 -> 1.8708  accuracy: 26.19% -> 23.21%     
client [7]  (testset)   loss: 1.5411 -> 1.3016  accuracy: 61.40% -> 61.40%     
client [50] (testset)   loss: 1.8947 -> 1.6662  accuracy: 20.21% -> 38.83%     
client [35] (testset)   loss: 1.8671 -> 1.6522  accuracy: 19.21% -> 36.16%     
client [24] (testset)   loss: 1.9896 -> 1.9115  accuracy: 26.00% -> 33.00%     
client [15] (testset)   loss: 1.7992 -> 1.6982  accuracy: 36.13% -> 36.13%     
client [58] (testset)   loss: 1.9810 -> 1.8163  accuracy: 44.84% -> 44.84%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 2.0717 -> 1.8746  accuracy: 7.55% -> 31.45%      
client [76] (testset)   loss: 1.9549 -> 1.8439  accuracy: 31.25% -> 18.75%     
client [67] (testset)   loss: 1.9731 -> 1.5842  accuracy: 4.09% -> 37.43%      
client [37] (testset)   loss: 1.5690 -> 1.4496  accuracy: 60.33% -> 60.33%     
client [58] (testset)   loss: 1.8484 -> 1.8580  accuracy: 44.84% -> 44.84%     
client [64] (testset)   loss: 1.8403 -> 1.7712  accuracy: 42.50% -> 42.50%     
client [77] (testset)   loss: 1.9882 -> 1.7074  accuracy: 26.25% -> 26.25%     
client [55] (testset)   loss: 1.9538 -> 1.1345  accuracy: 26.97% -> 61.80%     
client [12] (testset)   loss: 2.1031 -> 1.9349  accuracy: 7.87% -> 23.62%      
client [89] (testset)   loss: 1.9696 -> 1.9410  accuracy: 37.76% -> 37.76%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 1.8581 -> 1.7490  accuracy: 29.45% -> 26.03%     
client [51] (testset)   loss: 2.0164 -> 1.8289  accuracy: 21.62% -> 39.19%     
client [8]  (testset)   loss: 2.0464 -> 1.9753  accuracy: 29.22% -> 29.22%     
client [18] (testset)   loss: 1.9280 -> 1.9511  accuracy: 33.11% -> 33.11%     
client [94] (testset)   loss: 1.7445 -> 1.6200  accuracy: 55.32% -> 55.32%     
client [81] (testset)   loss: 1.9079 -> 1.5632  accuracy: 10.62% -> 38.50%     
client [3]  (testset)   loss: 2.0968 -> 2.0174  accuracy: 13.29% -> 23.78%     
client [11] (testset)   loss: 1.7801 -> 1.7147  accuracy: 15.14% -> 33.94%     
client [95] (testset)   loss: 1.3015 -> 1.1038  accuracy: 70.40% -> 70.40%     
client [67] (testset)   loss: 1.9077 -> 1.5961  accuracy: 37.43% -> 37.43%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 2.1043 -> 1.9974  accuracy: 21.01% -> 21.01%     
client [79] (testset)   loss: 1.8322 -> 1.8582  accuracy: 30.00% -> 30.00%     
client [58] (testset)   loss: 1.8322 -> 1.8294  accuracy: 44.84% -> 44.84%     
client [88] (testset)   loss: 1.9129 -> 1.6448  accuracy: 46.60% -> 46.60%     
client [46] (testset)   loss: 1.9473 -> 1.8934  accuracy: 23.38% -> 23.38%     
client [11] (testset)   loss: 2.1002 -> 1.7136  accuracy: 11.93% -> 33.94%     
client [55] (testset)   loss: 1.9670 -> 1.1111  accuracy: 26.97% -> 61.80%     
client [13] (testset)   loss: 1.7226 -> 1.3695  accuracy: 39.35% -> 39.35%     
client [31] (testset)   loss: 1.5473 -> 1.4510  accuracy: 58.87% -> 58.87%     
client [75] (testset)   loss: 1.5623 -> 1.0507  accuracy: 65.00% -> 65.00%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 1.8637 -> 1.7797  accuracy: 23.23% -> 38.38%     
client [7]  (testset)   loss: 1.7297 -> 1.3288  accuracy: 61.40% -> 61.40%     
client [57] (testset)   loss: 1.8518 -> 1.8109  accuracy: 31.58% -> 22.97%     
client [13] (testset)   loss: 1.5212 -> 1.3643  accuracy: 41.67% -> 39.35%     
client [43] (testset)   loss: 1.7000 -> 1.5194  accuracy: 26.61% -> 46.33%     
client [91] (testset)   loss: 1.9001 -> 1.6429  accuracy: 18.63% -> 43.14%     
client [10] (testset)   loss: 1.4158 -> 1.1520  accuracy: 64.38% -> 64.38%     
client [64] (testset)   loss: 1.8788 -> 1.7755  accuracy: 42.50% -> 42.50%     
client [82] (testset)   loss: 1.9521 -> 1.7218  accuracy: 24.79% -> 28.21%     
client [22] (testset)   loss: 1.7595 -> 1.3993  accuracy: 48.72% -> 48.72%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 1.7867 -> 1.6201  accuracy: 34.69% -> 34.69%     
client [23] (testset)   loss: 1.4916 -> 1.1330  accuracy: 61.22% -> 61.22%     
client [88] (testset)   loss: 1.9401 -> 1.6305  accuracy: 46.60% -> 46.60%     
client [98] (testset)   loss: 1.9466 -> 1.7618  accuracy: 45.03% -> 45.03%     
client [79] (testset)   loss: 1.8515 -> 1.8484  accuracy: 30.00% -> 25.00%     
client [21] (testset)   loss: 1.9862 -> 2.0605  accuracy: 21.01% -> 21.01%     
client [92] (testset)   loss: 2.0401 -> 1.8193  accuracy: 47.44% -> 47.44%     
client [56] (testset)   loss: 1.7169 -> 1.4783  accuracy: 18.92% -> 47.30%     
client [5]  (testset)   loss: 1.4380 -> 1.2446  accuracy: 66.67% -> 66.67%     
client [52] (testset)   loss: 2.0692 -> 1.9769  accuracy: 18.92% -> 18.92%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 1.9589 -> 1.6219  accuracy: 37.43% -> 37.43%     
client [54] (testset)   loss: 1.7499 -> 1.6013  accuracy: 36.16% -> 36.16%     
client [14] (testset)   loss: 1.7671 -> 1.6878  accuracy: 41.94% -> 41.94%     
client [99] (testset)   loss: 2.1388 -> 2.0387  accuracy: 26.32% -> 31.58%     
client [36] (testset)   loss: 1.9356 -> 1.8334  accuracy: 32.58% -> 32.58%     
client [30] (testset)   loss: 1.9312 -> 1.7216  accuracy: 15.11% -> 46.04%     
client [38] (testset)   loss: 1.3234 -> 1.0345  accuracy: 73.33% -> 73.33%     
client [15] (testset)   loss: 1.8319 -> 1.7034  accuracy: 31.94% -> 36.13%     
client [6]  (testset)   loss: 2.0915 -> 2.0947  accuracy: 21.43% -> 21.43%     
client [53] (testset)   loss: 1.7073 -> 1.5887  accuracy: 28.46% -> 36.92%     
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 2.0202 -> 2.0294  accuracy: 26.32% -> 31.58%     
client [6]  (testset)   loss: 2.0754 -> 2.0859  accuracy: 21.43% -> 20.54%     
client [83] (testset)   loss: 1.4930 -> 1.3071  accuracy: 63.04% -> 63.04%     
client [42] (testset)   loss: 1.8611 -> 1.8097  accuracy: 33.02% -> 33.02%     
client [34] (testset)   loss: 1.9120 -> 1.8100  accuracy: 40.48% -> 40.48%     
client [15] (testset)   loss: 1.7750 -> 1.7044  accuracy: 36.13% -> 36.13%     
client [47] (testset)   loss: 1.7854 -> 1.7674  accuracy: 40.35% -> 40.35%     
client [55] (testset)   loss: 2.0685 -> 1.1613  accuracy: 26.97% -> 61.80%     
client [51] (testset)   loss: 1.9360 -> 1.8515  accuracy: 39.19% -> 39.19%     
client [95] (testset)   loss: 1.5866 -> 1.0923  accuracy: 70.40% -> 70.40%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 1.8253 -> 1.8145  accuracy: 45.45% -> 45.45%     
client [15] (testset)   loss: 1.8480 -> 1.7157  accuracy: 36.13% -> 36.13%     
client [33] (testset)   loss: 1.9245 -> 1.9178  accuracy: 28.57% -> 27.38%     
client [99] (testset)   loss: 2.0460 -> 2.0174  accuracy: 26.32% -> 31.58%     
client [90] (testset)   loss: 1.6966 -> 1.5123  accuracy: 40.28% -> 40.28%     
client [57] (testset)   loss: 1.9191 -> 1.8088  accuracy: 31.58% -> 31.58%     
client [27] (testset)   loss: 2.0507 -> 2.0606  accuracy: 27.12% -> 27.12%     
client [78] (testset)   loss: 1.9559 -> 1.6711  accuracy: 31.98% -> 31.98%     
client [36] (testset)   loss: 1.9523 -> 1.8403  accuracy: 32.58% -> 32.58%     
client [88] (testset)   loss: 1.8531 -> 1.6410  accuracy: 46.60% -> 46.60%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 1.8740 -> 1.8198  accuracy: 34.53% -> 34.53%     
client [35] (testset)   loss: 1.7400 -> 1.6202  accuracy: 36.16% -> 36.16%     
client [16] (testset)   loss: 2.0520 -> 1.8868  accuracy: 10.17% -> 29.66%     
client [80] (testset)   loss: 1.9973 -> 1.6876  accuracy: 52.67% -> 52.67%     
client [38] (testset)   loss: 1.2075 -> 1.0280  accuracy: 73.33% -> 73.33%     
client [78] (testset)   loss: 2.0794 -> 1.6755  accuracy: 17.12% -> 31.98%     
client [68] (testset)   loss: 1.8410 -> 1.7511  accuracy: 41.84% -> 41.84%     
client [11] (testset)   loss: 1.8934 -> 1.6967  accuracy: 26.15% -> 33.94%     
client [64] (testset)   loss: 1.8278 -> 1.7810  accuracy: 42.50% -> 42.50%     
client [82] (testset)   loss: 1.8493 -> 1.7263  accuracy: 28.21% -> 28.21%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 1.9483 -> 1.6925  accuracy: 15.11% -> 46.04%     
client [27] (testset)   loss: 2.0917 -> 2.0365  accuracy: 27.12% -> 27.12%     
client [74] (testset)   loss: 1.6648 -> 1.3620  accuracy: 63.33% -> 63.33%     
client [45] (testset)   loss: 1.9496 -> 1.8803  accuracy: 23.21% -> 23.21%     
client [6]  (testset)   loss: 2.0969 -> 2.0860  accuracy: 16.07% -> 21.43%     
client [36] (testset)   loss: 1.9048 -> 1.8306  accuracy: 32.58% -> 32.58%     
client [63] (testset)   loss: 2.0659 -> 1.9663  accuracy: 38.52% -> 38.52%     
client [76] (testset)   loss: 1.8922 -> 1.8326  accuracy: 31.25% -> 18.75%     
client [83] (testset)   loss: 1.6948 -> 1.3240  accuracy: 16.30% -> 63.04%     
client [86] (testset)   loss: 1.8646 -> 1.8466  accuracy: 32.91% -> 32.91%     
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 1.4859 -> 1.3098  accuracy: 63.04% -> 63.04%     
client [99] (testset)   loss: 1.9996 -> 2.0060  accuracy: 31.58% -> 31.58%     
client [74] (testset)   loss: 1.6658 -> 1.3643  accuracy: 63.33% -> 63.33%     
client [73] (testset)   loss: 1.9405 -> 1.3466  accuracy: 50.21% -> 50.21%     
client [29] (testset)   loss: 1.8011 -> 1.6020  accuracy: 10.16% -> 35.83%     
client [92] (testset)   loss: 1.9467 -> 1.8357  accuracy: 47.44% -> 47.44%     
client [6]  (testset)   loss: 2.0893 -> 2.0876  accuracy: 21.43% -> 21.43%     
client [61] (testset)   loss: 2.0302 -> 1.9721  accuracy: 22.52% -> 22.52%     
client [21] (testset)   loss: 2.0988 -> 1.9970  accuracy: 21.01% -> 21.01%     
client [67] (testset)   loss: 2.1227 -> 1.5927  accuracy: 12.28% -> 37.43%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 1.4252 -> 1.3114  accuracy: 63.04% -> 63.04%     
client [32] (testset)   loss: 2.0264 -> 1.9932  accuracy: 27.86% -> 27.86%     
client [95] (testset)   loss: 1.6256 -> 1.1453  accuracy: 70.40% -> 70.40%     
client [61] (testset)   loss: 2.0032 -> 1.9703  accuracy: 22.52% -> 22.52%     
client [27] (testset)   loss: 2.0992 -> 2.0339  accuracy: 27.12% -> 27.12%     
client [25] (testset)   loss: 1.8660 -> 1.7382  accuracy: 38.46% -> 38.46%     
client [68] (testset)   loss: 1.7974 -> 1.7753  accuracy: 41.84% -> 41.84%     
client [34] (testset)   loss: 1.9547 -> 1.8031  accuracy: 40.48% -> 40.48%     
client [71] (testset)   loss: 1.9212 -> 1.8394  accuracy: 45.45% -> 45.45%     
client [89] (testset)   loss: 1.9499 -> 1.9389  accuracy: 37.76% -> 37.76%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 2.2104 -> 1.6687  accuracy: 31.98% -> 31.08%     
client [81] (testset)   loss: 2.0762 -> 1.5663  accuracy: 9.29% -> 38.50%      
client [51] (testset)   loss: 1.9826 -> 1.8546  accuracy: 21.62% -> 39.19%     
client [54] (testset)   loss: 1.7694 -> 1.6030  accuracy: 36.16% -> 36.16%     
client [65] (testset)   loss: 1.9938 -> 1.9351  accuracy: 37.96% -> 37.96%     
client [41] (testset)   loss: 1.8415 -> 1.4786  accuracy: 39.88% -> 39.88%     
client [11] (testset)   loss: 2.0898 -> 1.6990  accuracy: 15.14% -> 33.94%     
client [85] (testset)   loss: 1.8906 -> 1.7592  accuracy: 30.29% -> 30.29%     
client [12] (testset)   loss: 2.0493 -> 1.9403  accuracy: 17.32% -> 23.62%     
client [23] (testset)   loss: 1.6378 -> 1.1876  accuracy: 61.22% -> 61.22%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 2.0662 -> 1.8942  accuracy: 15.25% -> 29.66%     
client [65] (testset)   loss: 2.0552 -> 1.9300  accuracy: 37.96% -> 37.96%     
client [53] (testset)   loss: 1.8042 -> 1.5966  accuracy: 36.92% -> 28.46%     
client [58] (testset)   loss: 1.8613 -> 1.8409  accuracy: 44.84% -> 44.84%     
client [72] (testset)   loss: 1.5389 -> 1.4404  accuracy: 57.50% -> 57.50%     
client [7]  (testset)   loss: 1.7157 -> 1.2861  accuracy: 61.40% -> 61.40%     
client [71] (testset)   loss: 1.8373 -> 1.8284  accuracy: 45.45% -> 45.45%     
client [59] (testset)   loss: 1.7475 -> 1.5330  accuracy: 41.52% -> 41.52%     
client [86] (testset)   loss: 1.8928 -> 1.8396  accuracy: 32.91% -> 32.91%     
client [39] (testset)   loss: 1.7958 -> 1.8050  accuracy: 24.55% -> 24.55%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 2.0199 -> 2.0310  accuracy: 31.58% -> 31.58%     
client [7]  (testset)   loss: 1.7107 -> 1.3358  accuracy: 61.40% -> 61.40%     
client [17] (testset)   loss: 2.1499 -> 1.6235  accuracy: 58.91% -> 58.91%     
client [64] (testset)   loss: 1.8575 -> 1.7592  accuracy: 42.50% -> 42.50%     
client [37] (testset)   loss: 1.8095 -> 1.4557  accuracy: 60.33% -> 60.33%     
client [29] (testset)   loss: 2.0220 -> 1.5995  accuracy: 10.16% -> 35.83%     
client [93] (testset)   loss: 1.4105 -> 1.1050  accuracy: 70.93% -> 70.93%     
client [73] (testset)   loss: 2.0275 -> 1.3451  accuracy: 50.21% -> 50.21%     
client [40] (testset)   loss: 1.9028 -> 1.8315  accuracy: 27.00% -> 27.00%     
client [76] (testset)   loss: 1.9038 -> 1.8163  accuracy: 31.25% -> 31.25%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 1.5680 -> 1.4588  accuracy: 58.87% -> 58.87%     
client [89] (testset)   loss: 1.9969 -> 1.9627  accuracy: 37.76% -> 37.76%     
client [77] (testset)   loss: 1.8484 -> 1.7020  accuracy: 26.25% -> 26.25%     
client [90] (testset)   loss: 1.6457 -> 1.4997  accuracy: 27.78% -> 40.28%     
client [26] (testset)   loss: 1.5440 -> 1.0804  accuracy: 70.51% -> 70.51%     
client [50] (testset)   loss: 1.8060 -> 1.6814  accuracy: 12.23% -> 38.83%     
client [30] (testset)   loss: 2.0765 -> 1.6841  accuracy: 15.11% -> 46.04%     
client [70] (testset)   loss: 1.9074 -> 1.8210  accuracy: 26.01% -> 34.53%     
client [41] (testset)   loss: 1.8467 -> 1.4752  accuracy: 4.91% -> 36.81%      
client [99] (testset)   loss: 2.0624 -> 2.0280  accuracy: 26.32% -> 31.58%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 1.9262 -> 1.7626  accuracy: 41.84% -> 41.84%     
client [70] (testset)   loss: 1.8261 -> 1.8146  accuracy: 34.53% -> 34.53%     
client [52] (testset)   loss: 2.1447 -> 1.9636  accuracy: 11.26% -> 20.27%     
client [1]  (testset)   loss: 1.7848 -> 1.7012  accuracy: 24.49% -> 28.57%     
client [2]  (testset)   loss: 2.0556 -> 1.9741  accuracy: 28.09% -> 28.09%     
client [67] (testset)   loss: 2.3387 -> 1.6452  accuracy: 4.09% -> 37.43%      
client [92] (testset)   loss: 2.0671 -> 1.8623  accuracy: 8.97% -> 47.44%      
client [35] (testset)   loss: 1.8723 -> 1.6526  accuracy: 36.16% -> 36.16%     
client [36] (testset)   loss: 1.9684 -> 1.8341  accuracy: 13.64% -> 32.58%     
client [64] (testset)   loss: 1.9053 -> 1.7519  accuracy: 10.83% -> 42.50%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 1.6672 -> 1.4918  accuracy: 57.08% -> 57.08%     
client [6]  (testset)   loss: 2.0881 -> 2.0880  accuracy: 20.54% -> 20.54%     
client [12] (testset)   loss: 1.9996 -> 1.9397  accuracy: 23.62% -> 23.62%     
client [55] (testset)   loss: 1.5007 -> 1.1232  accuracy: 61.80% -> 61.80%     
client [29] (testset)   loss: 2.1640 -> 1.5946  accuracy: 35.83% -> 35.83%     
client [9]  (testset)   loss: 1.9038 -> 1.8275  accuracy: 34.72% -> 34.72%     
client [43] (testset)   loss: 1.8727 -> 1.5506  accuracy: 5.05% -> 46.33%      
client [77] (testset)   loss: 1.8622 -> 1.6974  accuracy: 26.25% -> 26.25%     
client [98] (testset)   loss: 1.9736 -> 1.7582  accuracy: 7.28% -> 45.03%      
client [78] (testset)   loss: 2.1492 -> 1.6752  accuracy: 3.15% -> 31.98%      
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 1.9887 -> 1.8319  accuracy: 47.44% -> 47.44%     
client [80] (testset)   loss: 1.9030 -> 1.6748  accuracy: 52.67% -> 52.67%     
client [63] (testset)   loss: 2.0030 -> 1.9520  accuracy: 38.52% -> 38.52%     
client [76] (testset)   loss: 1.8855 -> 1.8318  accuracy: 31.25% -> 31.25%     
client [78] (testset)   loss: 2.1584 -> 1.6705  accuracy: 0.90% -> 31.08%      
client [25] (testset)   loss: 1.7807 -> 1.7717  accuracy: 26.92% -> 38.46%     
client [58] (testset)   loss: 1.8587 -> 1.8236  accuracy: 44.84% -> 44.84%     
client [13] (testset)   loss: 1.8513 -> 1.3618  accuracy: 39.35% -> 39.35%     
client [17] (testset)   loss: 1.7895 -> 1.5570  accuracy: 58.91% -> 58.91%     
client [38] (testset)   loss: 1.4152 -> 1.0366  accuracy: 73.33% -> 73.33%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 1.5597 -> 1.4510  accuracy: 57.50% -> 57.50%     
client [82] (testset)   loss: 1.8294 -> 1.7393  accuracy: 24.79% -> 28.21%     
client [86] (testset)   loss: 1.9122 -> 1.8377  accuracy: 32.91% -> 32.91%     
client [51] (testset)   loss: 1.9160 -> 1.8455  accuracy: 39.19% -> 39.19%     
client [96] (testset)   loss: 2.7535 -> 1.2826  accuracy: 0.96% -> 58.85%      
client [42] (testset)   loss: 1.8900 -> 1.8039  accuracy: 33.02% -> 33.02%     
client [55] (testset)   loss: 2.5785 -> 1.1161  accuracy: 0.00% -> 61.80%      
client [13] (testset)   loss: 1.5182 -> 1.3659  accuracy: 41.67% -> 39.35%     
client [1]  (testset)   loss: 1.7909 -> 1.6929  accuracy: 24.49% -> 28.57%     
client [12] (testset)   loss: 1.9867 -> 1.9245  accuracy: 17.32% -> 23.62%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 1.8415 -> 1.7881  accuracy: 41.84% -> 41.84%     
client [23] (testset)   loss: 3.1689 -> 1.1553  accuracy: 1.02% -> 61.22%      
client [46] (testset)   loss: 1.9994 -> 1.8884  accuracy: 23.38% -> 23.38%     
client [41] (testset)   loss: 1.8894 -> 1.4784  accuracy: 39.88% -> 39.88%     
client [25] (testset)   loss: 1.8187 -> 1.7655  accuracy: 38.46% -> 38.46%     
client [58] (testset)   loss: 1.8698 -> 1.8133  accuracy: 44.84% -> 44.84%     
client [14] (testset)   loss: 1.8025 -> 1.7070  accuracy: 41.94% -> 41.94%     
client [33] (testset)   loss: 1.9091 -> 1.9146  accuracy: 28.57% -> 27.38%     
client [85] (testset)   loss: 1.9196 -> 1.8003  accuracy: 30.29% -> 30.29%     
client [62] (testset)   loss: 1.7281 -> 1.4783  accuracy: 55.56% -> 55.56%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 2.0859 -> 1.7447  accuracy: 7.28% -> 45.03%      
client [63] (testset)   loss: 2.0289 -> 1.9433  accuracy: 38.52% -> 38.52%     
client [70] (testset)   loss: 1.9106 -> 1.8352  accuracy: 26.01% -> 34.53%     
client [65] (testset)   loss: 2.0199 -> 1.9278  accuracy: 37.96% -> 37.96%     
client [14] (testset)   loss: 1.7930 -> 1.7028  accuracy: 41.94% -> 41.94%     
client [73] (testset)   loss: 1.8914 -> 1.3686  accuracy: 24.46% -> 50.21%     
client [34] (testset)   loss: 1.9200 -> 1.7892  accuracy: 40.48% -> 40.48%     
client [99] (testset)   loss: 2.0450 -> 2.0142  accuracy: 26.32% -> 31.58%     
client [69] (testset)   loss: 1.9967 -> 1.8837  accuracy: 34.13% -> 34.13%     
client [46] (testset)   loss: 1.9547 -> 1.8880  accuracy: 23.38% -> 23.38%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 2.0389 -> 2.0137  accuracy: 26.32% -> 31.58%     
client [93] (testset)   loss: 1.3332 -> 1.0950  accuracy: 70.93% -> 70.93%     
client [11] (testset)   loss: 2.0183 -> 1.7115  accuracy: 15.14% -> 33.94%     
client [58] (testset)   loss: 1.8264 -> 1.8193  accuracy: 44.84% -> 44.84%     
client [81] (testset)   loss: 2.0963 -> 1.5889  accuracy: 10.62% -> 38.50%     
client [85] (testset)   loss: 1.8514 -> 1.7620  accuracy: 30.29% -> 30.29%     
client [89] (testset)   loss: 1.9384 -> 1.9343  accuracy: 37.76% -> 37.76%     
client [45] (testset)   loss: 2.0007 -> 1.8733  accuracy: 23.21% -> 23.21%     
client [8]  (testset)   loss: 2.0369 -> 1.9748  accuracy: 29.22% -> 29.22%     
client [68] (testset)   loss: 1.8364 -> 1.7895  accuracy: 41.84% -> 41.84%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 2.6643 -> 1.6338  accuracy: 0.00% -> 37.43%      
client [72] (testset)   loss: 1.8049 -> 1.4988  accuracy: 57.50% -> 57.50%     
client [1]  (testset)   loss: 1.7669 -> 1.7011  accuracy: 24.49% -> 28.57%     
client [78] (testset)   loss: 2.1675 -> 1.6743  accuracy: 31.08% -> 31.98%     
client [83] (testset)   loss: 2.1463 -> 1.3276  accuracy: 3.80% -> 63.04%      
client [21] (testset)   loss: 2.0886 -> 2.0122  accuracy: 18.49% -> 21.01%     
client [56] (testset)   loss: 1.6709 -> 1.4804  accuracy: 47.30% -> 47.30%     
client [44] (testset)   loss: 1.6005 -> 1.4980  accuracy: 57.08% -> 57.08%     
client [92] (testset)   loss: 1.8819 -> 1.8157  accuracy: 47.44% -> 47.44%     
client [27] (testset)   loss: 2.1287 -> 2.0324  accuracy: 13.14% -> 27.12%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 1.6742 -> 1.1464  accuracy: 64.38% -> 64.38%     
client [39] (testset)   loss: 1.8233 -> 1.7839  accuracy: 24.55% -> 24.55%     
client [65] (testset)   loss: 2.0163 -> 1.9357  accuracy: 37.96% -> 37.96%     
client [26] (testset)   loss: 1.7411 -> 1.0595  accuracy: 14.74% -> 70.51%     
client [19] (testset)   loss: 1.8713 -> 1.7775  accuracy: 38.38% -> 38.38%     
client [68] (testset)   loss: 1.8141 -> 1.7860  accuracy: 41.84% -> 41.84%     
client [41] (testset)   loss: 1.7791 -> 1.5035  accuracy: 39.88% -> 39.88%     
client [50] (testset)   loss: 1.7809 -> 1.6693  accuracy: 38.83% -> 38.83%     
client [75] (testset)   loss: 2.0402 -> 1.0571  accuracy: 24.00% -> 65.00%     
client [81] (testset)   loss: 1.8876 -> 1.5694  accuracy: 9.29% -> 38.50%      
APFL's average time taken by each global epoch: 0 min 6.03 sec.                
APFL's total running time: 0 h 42 m 11 s.                                      
==================== APFL Experiment Results: ====================             
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.8276 -> 1.6501",                                    
                "accuracy": "32.09% -> 41.01%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.8505 -> 1.6510",                                    
                "accuracy": "36.32% -> 40.89%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.8945 -> 1.6511",                                    
                "accuracy": "31.38% -> 41.03%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.9149 -> 1.6508",                                    
                "accuracy": "33.79% -> 41.24%"                                 
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== APFL Max Accuracy ====================                    
all_clients:                                                                   
(test) before fine-tuning: 36.32% at epoch 200                                 
(test) after fine-tuning: 41.24% at epoch 400                                  
