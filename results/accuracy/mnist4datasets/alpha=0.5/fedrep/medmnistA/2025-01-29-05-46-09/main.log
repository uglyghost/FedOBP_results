==================== FedRep ====================                               
Experiment Arguments:                                                          
{
    'method': 'fedrep',
    'dataset': {
        'name': 'medmnistA',
        'client_num': 100,
        'test_ratio': 0.25,
        'val_ratio': 0.0,
        'seed': 42,
        'split': 'sample',
        'IID_ratio': 0.0,
        'monitor_window_name_suffix': 'medmnistA-100clients-0%IID-Dir(0.5)-seed42',
        'alpha': 0.5,
        'min_samples_per_client': 10
    },
    'model': {
        'name': 'avgcnn',
        'use_torchvision_pretrained_weights': True,
        'external_model_weights_path': None
    },
    'optimizer': {
        'lr': 0.01,
        'dampening': 0,
        'weight_decay': 0,
        'momentum': 0.7,
        'nesterov': False,
        'name': 'sgd'
    },
    'mode': 'serial',
    'parallel': {
        'ray_cluster_addr': None,
        'num_cpus': None,
        'num_gpus': None,
        'num_workers': 2
    },
    'common': {
        'seed': 42,
        'join_ratio': 0.1,
        'global_epoch': 400,
        'local_epoch': 5,
        'batch_size': 32,
        'reset_optimizer_on_global_epoch': True,
        'straggler_ratio': 0,
        'straggler_min_local_epoch': 0,
        'buffers': 'global',
        'client_side_evaluation': True,
        'test': {
            'client': {
                'interval': 100,
                'finetune_epoch': 5,
                'train': False,
                'val': False,
                'test': True
            },
            'server': {
                'interval': -1,
                'train': False,
                'val': False,
                'test': True,
                'model_in_train_mode': False
            }
        },
        'verbose_gap': 10,
        'monitor': None,
        'use_cuda': True,
        'save_log': True,
        'save_model': False,
        'save_learning_curve_plot': True,
        'save_metrics': True,
        'delete_useless_run': True
    },
    'fedprox': {
        'mu': 0.01
    },
    'pfedsim': {
        'warmup_round': 0.5
    },
    'fedrep': {
        'train_body_epoch': 1
    }
}
---------------------------- TRAINING EPOCH: 10 ----------------------------   
client [77] (testset)   loss: 1.7420 -> 1.7257  accuracy: 26.25% -> 26.25%     
client [81] (testset)   loss: 1.5848 -> 1.5835  accuracy: 27.65% -> 38.50%     
client [21] (testset)   loss: 2.5437 -> 2.0028  accuracy: 4.20% -> 21.01%      
client [68] (testset)   loss: 1.7905 -> 1.7798  accuracy: 41.84% -> 41.84%     
client [93] (testset)   loss: 1.1358 -> 1.1708  accuracy: 70.93% -> 70.93%     
client [31] (testset)   loss: 1.6307 -> 1.4612  accuracy: 58.87% -> 58.87%     
client [20] (testset)   loss: 1.6251 -> 1.6204  accuracy: 34.69% -> 34.69%     
client [59] (testset)   loss: 2.5944 -> 1.5506  accuracy: 0.91% -> 41.52%      
client [48] (testset)   loss: 1.8696 -> 1.8543  accuracy: 31.45% -> 31.45%     
client [34] (testset)   loss: 1.8354 -> 1.7981  accuracy: 40.48% -> 40.48%     
---------------------------- TRAINING EPOCH: 20 ----------------------------   
client [69] (testset)   loss: 1.9606 -> 1.8943  accuracy: 34.13% -> 34.13%     
client [99] (testset)   loss: 2.0189 -> 2.0099  accuracy: 31.58% -> 31.58%     
client [67] (testset)   loss: 1.5884 -> 1.6039  accuracy: 37.43% -> 37.43%     
client [0]  (testset)   loss: 1.5665 -> 1.5605  accuracy: 46.99% -> 46.99%     
client [76] (testset)   loss: 1.8205 -> 1.8387  accuracy: 31.25% -> 31.25%     
client [41] (testset)   loss: 1.4947 -> 1.4931  accuracy: 36.81% -> 36.81%     
client [62] (testset)   loss: 1.9535 -> 1.6885  accuracy: 55.56% -> 55.56%     
client [2]  (testset)   loss: 2.8118 -> 1.9638  accuracy: 1.12% -> 28.09%      
client [14] (testset)   loss: 1.6637 -> 1.6743  accuracy: 41.94% -> 41.94%     
client [46] (testset)   loss: 1.8972 -> 1.9113  accuracy: 23.38% -> 23.38%     
---------------------------- TRAINING EPOCH: 30 ----------------------------   
client [24] (testset)   loss: 1.9197 -> 1.9011  accuracy: 33.00% -> 33.00%     
client [68] (testset)   loss: 1.7703 -> 1.7973  accuracy: 41.84% -> 41.84%     
client [57] (testset)   loss: 1.8065 -> 1.7991  accuracy: 22.97% -> 22.97%     
client [17] (testset)   loss: 1.5991 -> 1.6549  accuracy: 58.91% -> 58.91%     
client [54] (testset)   loss: 1.5998 -> 1.6223  accuracy: 36.16% -> 36.16%     
client [23] (testset)   loss: 3.1507 -> 1.2286  accuracy: 0.00% -> 61.22%      
client [35] (testset)   loss: 1.6924 -> 1.6502  accuracy: 19.21% -> 36.16%     
client [59] (testset)   loss: 1.5271 -> 1.5395  accuracy: 41.52% -> 41.52%     
client [31] (testset)   loss: 1.4526 -> 1.4574  accuracy: 58.87% -> 58.87%     
client [9]  (testset)   loss: 1.8524 -> 1.8360  accuracy: 34.72% -> 34.72%     
---------------------------- TRAINING EPOCH: 40 ----------------------------   
client [64] (testset)   loss: 1.7538 -> 1.7468  accuracy: 42.50% -> 42.50%     
client [33] (testset)   loss: 1.8969 -> 1.9114  accuracy: 28.57% -> 27.38%     
client [16] (testset)   loss: 1.9236 -> 1.9167  accuracy: 15.25% -> 29.66%     
client [44] (testset)   loss: 1.5372 -> 1.5326  accuracy: 57.08% -> 57.08%     
client [8]  (testset)   loss: 1.9769 -> 1.9735  accuracy: 29.22% -> 29.22%     
client [31] (testset)   loss: 1.4954 -> 1.5604  accuracy: 58.87% -> 58.87%     
client [47] (testset)   loss: 1.7305 -> 1.7503  accuracy: 40.35% -> 40.35%     
client [36] (testset)   loss: 1.8386 -> 1.8402  accuracy: 32.58% -> 32.58%     
client [20] (testset)   loss: 1.6241 -> 1.6071  accuracy: 34.69% -> 34.69%     
client [56] (testset)   loss: 1.4606 -> 1.4689  accuracy: 47.30% -> 47.30%     
---------------------------- TRAINING EPOCH: 50 ----------------------------   
client [4]  (testset)   loss: 1.7811 -> 1.7607  accuracy: 34.29% -> 34.29%     
client [60] (testset)   loss: 1.6413 -> 1.6472  accuracy: 53.77% -> 53.77%     
client [28] (testset)   loss: 1.7748 -> 1.7716  accuracy: 24.66% -> 30.14%     
client [25] (testset)   loss: 1.7636 -> 1.7617  accuracy: 38.46% -> 38.46%     
client [58] (testset)   loss: 1.8377 -> 1.8695  accuracy: 44.84% -> 44.84%     
client [44] (testset)   loss: 1.5215 -> 1.4902  accuracy: 57.08% -> 57.08%     
client [39] (testset)   loss: 1.8340 -> 1.7990  accuracy: 24.55% -> 24.55%     
client [29] (testset)   loss: 1.5986 -> 1.5905  accuracy: 35.83% -> 35.83%     
client [3]  (testset)   loss: 2.0457 -> 2.0265  accuracy: 13.29% -> 23.78%     
client [84] (testset)   loss: 1.7354 -> 1.7808  accuracy: 26.03% -> 26.03%     
---------------------------- TRAINING EPOCH: 60 ----------------------------   
client [21] (testset)   loss: 1.9861 -> 2.0009  accuracy: 21.01% -> 21.01%     
client [84] (testset)   loss: 1.7353 -> 1.7349  accuracy: 26.03% -> 26.03%     
client [10] (testset)   loss: 1.1724 -> 1.1696  accuracy: 64.38% -> 64.38%     
client [36] (testset)   loss: 1.8493 -> 1.8479  accuracy: 32.58% -> 32.58%     
client [65] (testset)   loss: 1.9295 -> 1.9392  accuracy: 37.96% -> 37.96%     
client [81] (testset)   loss: 1.5840 -> 1.5682  accuracy: 38.50% -> 38.50%     
client [79] (testset)   loss: 1.7981 -> 1.8184  accuracy: 25.00% -> 30.00%     
client [42] (testset)   loss: 1.8016 -> 1.7970  accuracy: 33.02% -> 33.02%     
client [11] (testset)   loss: 1.7115 -> 1.7027  accuracy: 33.94% -> 33.94%     
client [96] (testset)   loss: 1.2630 -> 1.2686  accuracy: 58.85% -> 58.85%     
---------------------------- TRAINING EPOCH: 70 ----------------------------   
client [8]  (testset)   loss: 1.9798 -> 1.9734  accuracy: 29.22% -> 29.22%     
client [53] (testset)   loss: 1.5855 -> 1.5660  accuracy: 36.92% -> 36.92%     
client [52] (testset)   loss: 1.9740 -> 1.9630  accuracy: 20.27% -> 20.27%     
client [42] (testset)   loss: 1.8112 -> 1.8262  accuracy: 33.02% -> 33.02%     
client [69] (testset)   loss: 1.8743 -> 1.8964  accuracy: 34.13% -> 34.13%     
client [59] (testset)   loss: 1.5383 -> 1.5313  accuracy: 41.52% -> 41.52%     
client [7]  (testset)   loss: 1.3969 -> 1.2857  accuracy: 61.40% -> 61.40%     
client [26] (testset)   loss: 1.0864 -> 1.1007  accuracy: 70.51% -> 70.51%     
client [49] (testset)   loss: 1.8927 -> 1.8770  accuracy: 34.00% -> 34.00%     
client [98] (testset)   loss: 1.7536 -> 1.7625  accuracy: 45.03% -> 45.03%     
---------------------------- TRAINING EPOCH: 80 ----------------------------   
client [98] (testset)   loss: 1.7658 -> 1.7757  accuracy: 45.03% -> 45.03%     
client [47] (testset)   loss: 1.8027 -> 1.7671  accuracy: 40.35% -> 40.35%     
client [21] (testset)   loss: 2.0121 -> 2.0075  accuracy: 21.01% -> 21.01%     
client [77] (testset)   loss: 1.6812 -> 1.6962  accuracy: 26.25% -> 26.25%     
client [95] (testset)   loss: 1.1266 -> 1.1113  accuracy: 70.40% -> 70.40%     
client [91] (testset)   loss: 1.6689 -> 1.6646  accuracy: 43.14% -> 43.14%     
client [14] (testset)   loss: 1.6738 -> 1.6817  accuracy: 41.94% -> 41.94%     
client [99] (testset)   loss: 2.0158 -> 2.0177  accuracy: 31.58% -> 31.58%     
client [20] (testset)   loss: 1.6735 -> 1.6164  accuracy: 34.69% -> 34.69%     
client [39] (testset)   loss: 1.8330 -> 1.7999  accuracy: 24.55% -> 24.55%     
---------------------------- TRAINING EPOCH: 90 ----------------------------   
client [52] (testset)   loss: 1.9703 -> 1.9627  accuracy: 20.27% -> 18.92%     
client [62] (testset)   loss: 1.4902 -> 1.5984  accuracy: 55.56% -> 55.56%     
client [71] (testset)   loss: 1.8269 -> 1.8045  accuracy: 45.45% -> 45.45%     
client [97] (testset)   loss: 1.5680 -> 1.5895  accuracy: 48.88% -> 48.88%     
client [30] (testset)   loss: 1.6848 -> 1.6980  accuracy: 46.04% -> 46.04%     
client [88] (testset)   loss: 1.6288 -> 1.6426  accuracy: 46.60% -> 46.60%     
client [60] (testset)   loss: 1.6326 -> 1.6347  accuracy: 53.77% -> 53.77%     
client [82] (testset)   loss: 1.7174 -> 1.7178  accuracy: 28.21% -> 28.21%     
client [91] (testset)   loss: 1.6468 -> 1.6456  accuracy: 43.14% -> 43.14%     
client [57] (testset)   loss: 1.8218 -> 1.7914  accuracy: 22.97% -> 22.97%     
---------------------------- TRAINING EPOCH: 100 ----------------------------  
client [31] (testset)   loss: 1.4689 -> 1.4652  accuracy: 58.87% -> 58.87%     
client [15] (testset)   loss: 1.6812 -> 1.6930  accuracy: 36.13% -> 36.13%     
client [71] (testset)   loss: 1.8207 -> 1.8442  accuracy: 45.45% -> 45.45%     
client [97] (testset)   loss: 1.5640 -> 1.5658  accuracy: 48.88% -> 48.88%     
client [53] (testset)   loss: 1.5773 -> 1.5727  accuracy: 36.92% -> 36.92%     
client [77] (testset)   loss: 1.7025 -> 1.6994  accuracy: 26.25% -> 26.25%     
client [76] (testset)   loss: 1.8164 -> 1.8567  accuracy: 31.25% -> 18.75%     
client [79] (testset)   loss: 1.8087 -> 1.8221  accuracy: 30.00% -> 30.00%     
client [28] (testset)   loss: 1.7822 -> 1.7731  accuracy: 17.81% -> 24.66%     
client [99] (testset)   loss: 2.0115 -> 2.0063  accuracy: 31.58% -> 31.58%     
---------------------------- TRAINING EPOCH: 110 ----------------------------  
client [97] (testset)   loss: 1.5680 -> 1.5678  accuracy: 48.88% -> 48.88%     
client [86] (testset)   loss: 1.8404 -> 1.8406  accuracy: 32.91% -> 32.91%     
client [34] (testset)   loss: 1.8111 -> 1.8257  accuracy: 40.48% -> 40.48%     
client [73] (testset)   loss: 1.3190 -> 1.3233  accuracy: 50.21% -> 50.21%     
client [5]  (testset)   loss: 1.2768 -> 1.2455  accuracy: 66.67% -> 66.67%     
client [96] (testset)   loss: 1.2894 -> 1.2657  accuracy: 58.85% -> 58.85%     
client [22] (testset)   loss: 1.3888 -> 1.3917  accuracy: 48.72% -> 48.72%     
client [60] (testset)   loss: 1.6419 -> 1.6321  accuracy: 53.77% -> 53.77%     
client [66] (testset)   loss: 1.7375 -> 1.7335  accuracy: 30.67% -> 30.67%     
client [83] (testset)   loss: 1.3309 -> 1.3810  accuracy: 63.04% -> 63.04%     
---------------------------- TRAINING EPOCH: 120 ----------------------------  
client [76] (testset)   loss: 1.8032 -> 1.8493  accuracy: 31.25% -> 18.75%     
client [65] (testset)   loss: 1.9153 -> 1.9489  accuracy: 37.96% -> 37.96%     
client [95] (testset)   loss: 1.1048 -> 1.1158  accuracy: 70.40% -> 70.40%     
client [17] (testset)   loss: 1.7508 -> 1.5556  accuracy: 58.91% -> 58.91%     
client [8]  (testset)   loss: 1.9842 -> 1.9750  accuracy: 29.22% -> 29.22%     
client [35] (testset)   loss: 1.6273 -> 1.6556  accuracy: 36.16% -> 36.16%     
client [98] (testset)   loss: 1.7976 -> 1.7520  accuracy: 45.03% -> 45.03%     
client [53] (testset)   loss: 1.5996 -> 1.6033  accuracy: 28.46% -> 36.92%     
client [43] (testset)   loss: 1.5122 -> 1.5205  accuracy: 46.33% -> 46.33%     
client [64] (testset)   loss: 1.7717 -> 1.7700  accuracy: 42.50% -> 42.50%     
---------------------------- TRAINING EPOCH: 130 ----------------------------  
client [21] (testset)   loss: 2.0168 -> 2.0029  accuracy: 21.01% -> 21.01%     
client [88] (testset)   loss: 1.6395 -> 1.6414  accuracy: 46.60% -> 46.60%     
client [38] (testset)   loss: 1.0324 -> 1.0265  accuracy: 73.33% -> 73.33%     
client [3]  (testset)   loss: 2.0133 -> 2.0258  accuracy: 23.78% -> 23.78%     
client [5]  (testset)   loss: 1.2436 -> 1.2392  accuracy: 66.67% -> 66.67%     
client [41] (testset)   loss: 1.4804 -> 1.4857  accuracy: 36.81% -> 39.88%     
client [7]  (testset)   loss: 1.2912 -> 1.2850  accuracy: 61.40% -> 61.40%     
client [37] (testset)   loss: 1.4978 -> 1.4549  accuracy: 60.33% -> 60.33%     
client [45] (testset)   loss: 1.8859 -> 1.8697  accuracy: 23.21% -> 23.21%     
client [47] (testset)   loss: 1.7406 -> 1.7259  accuracy: 40.35% -> 40.35%     
---------------------------- TRAINING EPOCH: 140 ----------------------------  
client [16] (testset)   loss: 1.8988 -> 1.8940  accuracy: 29.66% -> 29.66%     
client [11] (testset)   loss: 1.7124 -> 1.7084  accuracy: 33.94% -> 33.94%     
client [37] (testset)   loss: 1.4531 -> 1.4787  accuracy: 60.33% -> 60.33%     
client [41] (testset)   loss: 1.5051 -> 1.4694  accuracy: 36.81% -> 39.88%     
client [95] (testset)   loss: 1.1294 -> 1.1265  accuracy: 70.40% -> 70.40%     
client [53] (testset)   loss: 1.6288 -> 1.5706  accuracy: 28.46% -> 36.92%     
client [22] (testset)   loss: 1.4099 -> 1.3918  accuracy: 48.72% -> 48.72%     
client [25] (testset)   loss: 1.7640 -> 1.7854  accuracy: 38.46% -> 38.46%     
client [69] (testset)   loss: 1.8688 -> 1.8968  accuracy: 34.13% -> 34.13%     
client [46] (testset)   loss: 1.8935 -> 1.8990  accuracy: 23.38% -> 23.38%     
---------------------------- TRAINING EPOCH: 150 ----------------------------  
client [47] (testset)   loss: 1.7417 -> 1.7420  accuracy: 40.35% -> 40.35%     
client [69] (testset)   loss: 1.8756 -> 1.8796  accuracy: 34.13% -> 34.13%     
client [82] (testset)   loss: 1.7219 -> 1.7216  accuracy: 28.21% -> 28.21%     
client [45] (testset)   loss: 1.8801 -> 1.8697  accuracy: 23.21% -> 23.21%     
client [7]  (testset)   loss: 1.3085 -> 1.2912  accuracy: 61.40% -> 61.40%     
client [50] (testset)   loss: 1.6637 -> 1.6673  accuracy: 38.83% -> 38.83%     
client [35] (testset)   loss: 1.6693 -> 1.6356  accuracy: 19.21% -> 36.16%     
client [24] (testset)   loss: 1.8987 -> 1.9090  accuracy: 33.00% -> 33.00%     
client [15] (testset)   loss: 1.7049 -> 1.7353  accuracy: 36.13% -> 36.13%     
client [58] (testset)   loss: 1.8145 -> 1.8075  accuracy: 44.84% -> 44.84%     
---------------------------- TRAINING EPOCH: 160 ----------------------------  
client [48] (testset)   loss: 1.8592 -> 1.9219  accuracy: 31.45% -> 31.45%     
client [76] (testset)   loss: 1.8540 -> 1.8291  accuracy: 18.75% -> 18.75%     
client [67] (testset)   loss: 1.5853 -> 1.5915  accuracy: 37.43% -> 37.43%     
client [37] (testset)   loss: 1.4511 -> 1.4609  accuracy: 60.33% -> 60.33%     
client [58] (testset)   loss: 1.8115 -> 1.8565  accuracy: 44.84% -> 44.84%     
client [64] (testset)   loss: 1.7618 -> 1.7870  accuracy: 42.50% -> 42.50%     
client [77] (testset)   loss: 1.7104 -> 1.6971  accuracy: 26.25% -> 26.25%     
client [55] (testset)   loss: 1.1262 -> 1.1194  accuracy: 61.80% -> 61.80%     
client [12] (testset)   loss: 1.9322 -> 1.9233  accuracy: 23.62% -> 23.62%     
client [89] (testset)   loss: 1.9299 -> 1.9358  accuracy: 37.76% -> 37.76%     
---------------------------- TRAINING EPOCH: 170 ----------------------------  
client [84] (testset)   loss: 1.7461 -> 1.7439  accuracy: 26.03% -> 26.03%     
client [51] (testset)   loss: 1.8421 -> 1.8403  accuracy: 39.19% -> 39.19%     
client [8]  (testset)   loss: 1.9731 -> 1.9906  accuracy: 29.22% -> 29.22%     
client [18] (testset)   loss: 1.9735 -> 1.9656  accuracy: 33.11% -> 33.11%     
client [94] (testset)   loss: 1.6180 -> 1.6140  accuracy: 55.32% -> 55.32%     
client [81] (testset)   loss: 1.5767 -> 1.5615  accuracy: 38.50% -> 38.50%     
client [3]  (testset)   loss: 2.0272 -> 2.0227  accuracy: 23.78% -> 23.78%     
client [11] (testset)   loss: 1.7021 -> 1.6948  accuracy: 33.94% -> 33.94%     
client [95] (testset)   loss: 1.1212 -> 1.1126  accuracy: 70.40% -> 70.40%     
client [67] (testset)   loss: 1.6020 -> 1.6004  accuracy: 37.43% -> 37.43%     
---------------------------- TRAINING EPOCH: 180 ----------------------------  
client [21] (testset)   loss: 1.9961 -> 2.0043  accuracy: 21.01% -> 21.01%     
client [79] (testset)   loss: 1.8023 -> 1.8319  accuracy: 30.00% -> 30.00%     
client [58] (testset)   loss: 1.8095 -> 1.8189  accuracy: 44.84% -> 44.84%     
client [88] (testset)   loss: 1.6424 -> 1.6297  accuracy: 46.60% -> 46.60%     
client [46] (testset)   loss: 1.8839 -> 1.9030  accuracy: 23.38% -> 23.38%     
client [11] (testset)   loss: 1.7042 -> 1.7133  accuracy: 33.94% -> 33.94%     
client [55] (testset)   loss: 1.1227 -> 1.1247  accuracy: 61.80% -> 61.80%     
client [13] (testset)   loss: 1.3747 -> 1.3658  accuracy: 41.67% -> 39.35%     
client [31] (testset)   loss: 1.5174 -> 1.4510  accuracy: 58.87% -> 58.87%     
client [75] (testset)   loss: 1.0900 -> 1.0480  accuracy: 65.00% -> 65.00%     
---------------------------- TRAINING EPOCH: 190 ----------------------------  
client [19] (testset)   loss: 1.7849 -> 1.7996  accuracy: 38.38% -> 38.38%     
client [7]  (testset)   loss: 1.2827 -> 1.3192  accuracy: 61.40% -> 61.40%     
client [57] (testset)   loss: 1.7945 -> 1.8038  accuracy: 22.97% -> 22.97%     
client [13] (testset)   loss: 1.3550 -> 1.3572  accuracy: 41.67% -> 39.35%     
client [43] (testset)   loss: 1.5211 -> 1.5455  accuracy: 46.33% -> 46.33%     
client [91] (testset)   loss: 1.6781 -> 1.6423  accuracy: 43.14% -> 43.14%     
client [10] (testset)   loss: 1.1422 -> 1.1550  accuracy: 64.38% -> 64.38%     
client [64] (testset)   loss: 1.7510 -> 1.7582  accuracy: 42.50% -> 42.50%     
client [82] (testset)   loss: 1.7277 -> 1.7252  accuracy: 28.21% -> 28.21%     
client [22] (testset)   loss: 1.3932 -> 1.3983  accuracy: 48.72% -> 48.72%     
---------------------------- TRAINING EPOCH: 200 ----------------------------  
client [20] (testset)   loss: 1.6573 -> 1.6234  accuracy: 34.69% -> 34.69%     
client [23] (testset)   loss: 1.1438 -> 1.1465  accuracy: 61.22% -> 61.22%     
client [88] (testset)   loss: 1.6593 -> 1.6500  accuracy: 46.60% -> 46.60%     
client [98] (testset)   loss: 1.7558 -> 1.7893  accuracy: 45.03% -> 45.03%     
client [79] (testset)   loss: 1.7876 -> 1.8229  accuracy: 30.00% -> 30.00%     
client [21] (testset)   loss: 1.9954 -> 2.0254  accuracy: 21.01% -> 21.01%     
client [92] (testset)   loss: 1.8308 -> 1.8187  accuracy: 47.44% -> 47.44%     
client [56] (testset)   loss: 1.4995 -> 1.4691  accuracy: 47.30% -> 47.30%     
client [5]  (testset)   loss: 1.2663 -> 1.2459  accuracy: 66.67% -> 66.67%     
client [52] (testset)   loss: 1.9702 -> 1.9650  accuracy: 20.27% -> 20.27%     
---------------------------- TRAINING EPOCH: 210 ----------------------------  
client [67] (testset)   loss: 1.6159 -> 1.5958  accuracy: 37.43% -> 37.43%     
client [54] (testset)   loss: 1.6002 -> 1.6080  accuracy: 36.16% -> 36.16%     
client [14] (testset)   loss: 1.7333 -> 1.6848  accuracy: 41.94% -> 41.94%     
client [99] (testset)   loss: 2.1320 -> 2.0682  accuracy: 31.58% -> 31.58%     
client [36] (testset)   loss: 1.8304 -> 1.8306  accuracy: 32.58% -> 32.58%     
client [30] (testset)   loss: 1.6997 -> 1.6934  accuracy: 46.04% -> 46.04%     
client [38] (testset)   loss: 1.0243 -> 1.0305  accuracy: 73.33% -> 73.33%     
client [15] (testset)   loss: 1.7304 -> 1.6912  accuracy: 36.13% -> 36.13%     
client [6]  (testset)   loss: 2.1224 -> 2.0812  accuracy: 20.54% -> 21.43%     
client [53] (testset)   loss: 1.5749 -> 1.5842  accuracy: 36.92% -> 36.92%     
---------------------------- TRAINING EPOCH: 220 ----------------------------  
client [99] (testset)   loss: 1.9978 -> 2.0342  accuracy: 31.58% -> 31.58%     
client [6]  (testset)   loss: 2.0751 -> 2.0782  accuracy: 21.43% -> 21.43%     
client [83] (testset)   loss: 1.3213 -> 1.3314  accuracy: 63.04% -> 63.04%     
client [42] (testset)   loss: 1.7964 -> 1.8402  accuracy: 33.02% -> 33.02%     
client [34] (testset)   loss: 1.8302 -> 1.8082  accuracy: 40.48% -> 40.48%     
client [15] (testset)   loss: 1.6882 -> 1.6882  accuracy: 36.13% -> 36.13%     
client [47] (testset)   loss: 1.7305 -> 1.7601  accuracy: 40.35% -> 40.35%     
client [55] (testset)   loss: 1.1486 -> 1.1521  accuracy: 61.80% -> 61.80%     
client [51] (testset)   loss: 1.8377 -> 1.8749  accuracy: 39.19% -> 39.19%     
client [95] (testset)   loss: 1.0939 -> 1.1470  accuracy: 70.40% -> 70.40%     
---------------------------- TRAINING EPOCH: 230 ----------------------------  
client [71] (testset)   loss: 1.8164 -> 1.8147  accuracy: 45.45% -> 45.45%     
client [15] (testset)   loss: 1.6896 -> 1.6899  accuracy: 36.13% -> 36.13%     
client [33] (testset)   loss: 1.9340 -> 1.9361  accuracy: 27.38% -> 27.38%     
client [99] (testset)   loss: 2.0544 -> 1.9762  accuracy: 31.58% -> 31.58%     
client [90] (testset)   loss: 1.5077 -> 1.4972  accuracy: 40.28% -> 40.28%     
client [57] (testset)   loss: 1.7885 -> 1.7929  accuracy: 31.58% -> 22.97%     
client [27] (testset)   loss: 2.0335 -> 2.0636  accuracy: 27.12% -> 27.12%     
client [78] (testset)   loss: 1.6621 -> 1.6632  accuracy: 31.98% -> 31.98%     
client [36] (testset)   loss: 1.8350 -> 1.8492  accuracy: 32.58% -> 32.58%     
client [88] (testset)   loss: 1.6395 -> 1.6296  accuracy: 46.60% -> 46.60%     
---------------------------- TRAINING EPOCH: 240 ----------------------------  
client [70] (testset)   loss: 1.8175 -> 1.8198  accuracy: 34.53% -> 34.53%     
client [35] (testset)   loss: 1.6542 -> 1.6492  accuracy: 19.21% -> 36.16%     
client [16] (testset)   loss: 1.8864 -> 1.9191  accuracy: 29.66% -> 29.66%     
client [80] (testset)   loss: 1.6894 -> 1.6802  accuracy: 52.67% -> 52.67%     
client [38] (testset)   loss: 1.0255 -> 1.0264  accuracy: 73.33% -> 73.33%     
client [78] (testset)   loss: 1.6643 -> 1.6731  accuracy: 31.98% -> 31.08%     
client [68] (testset)   loss: 1.7689 -> 1.7686  accuracy: 41.84% -> 41.84%     
client [11] (testset)   loss: 1.6930 -> 1.6914  accuracy: 33.94% -> 33.94%     
client [64] (testset)   loss: 1.7583 -> 1.7746  accuracy: 42.50% -> 42.50%     
client [82] (testset)   loss: 1.7178 -> 1.7213  accuracy: 28.21% -> 28.21%     
---------------------------- TRAINING EPOCH: 250 ----------------------------  
client [30] (testset)   loss: 1.7149 -> 1.7064  accuracy: 46.04% -> 46.04%     
client [27] (testset)   loss: 2.0447 -> 2.0345  accuracy: 27.12% -> 27.12%     
client [74] (testset)   loss: 1.3442 -> 1.3631  accuracy: 63.33% -> 63.33%     
client [45] (testset)   loss: 1.8825 -> 1.8714  accuracy: 23.21% -> 23.21%     
client [6]  (testset)   loss: 2.1184 -> 2.0838  accuracy: 20.54% -> 21.43%     
client [36] (testset)   loss: 1.8455 -> 1.8547  accuracy: 32.58% -> 32.58%     
client [63] (testset)   loss: 1.9616 -> 1.9724  accuracy: 38.52% -> 38.52%     
client [76] (testset)   loss: 1.8204 -> 1.8364  accuracy: 31.25% -> 18.75%     
client [83] (testset)   loss: 1.4131 -> 1.3999  accuracy: 63.04% -> 63.04%     
client [86] (testset)   loss: 1.8750 -> 1.8394  accuracy: 32.91% -> 32.91%     
---------------------------- TRAINING EPOCH: 260 ----------------------------  
client [83] (testset)   loss: 1.3371 -> 1.3174  accuracy: 63.04% -> 63.04%     
client [99] (testset)   loss: 1.9913 -> 1.9851  accuracy: 31.58% -> 31.58%     
client [74] (testset)   loss: 1.3469 -> 1.3428  accuracy: 63.33% -> 63.33%     
client [73] (testset)   loss: 1.3222 -> 1.3267  accuracy: 50.21% -> 50.21%     
client [29] (testset)   loss: 1.5995 -> 1.5927  accuracy: 35.83% -> 35.83%     
client [92] (testset)   loss: 1.8428 -> 1.8819  accuracy: 47.44% -> 47.44%     
client [6]  (testset)   loss: 2.0752 -> 2.0781  accuracy: 21.43% -> 21.43%     
client [61] (testset)   loss: 1.9832 -> 1.9725  accuracy: 22.52% -> 22.52%     
client [21] (testset)   loss: 2.0186 -> 2.0074  accuracy: 21.01% -> 21.01%     
client [67] (testset)   loss: 1.5886 -> 1.6210  accuracy: 37.43% -> 37.43%     
---------------------------- TRAINING EPOCH: 270 ----------------------------  
client [83] (testset)   loss: 1.2960 -> 1.3145  accuracy: 63.04% -> 63.04%     
client [32] (testset)   loss: 1.9931 -> 1.9787  accuracy: 27.86% -> 27.86%     
client [95] (testset)   loss: 1.1063 -> 1.1154  accuracy: 70.40% -> 70.40%     
client [61] (testset)   loss: 1.9678 -> 1.9670  accuracy: 22.52% -> 22.52%     
client [27] (testset)   loss: 2.0548 -> 2.0346  accuracy: 27.12% -> 27.12%     
client [25] (testset)   loss: 1.7561 -> 1.7487  accuracy: 38.46% -> 38.46%     
client [68] (testset)   loss: 1.7735 -> 1.7868  accuracy: 41.84% -> 41.84%     
client [34] (testset)   loss: 1.8000 -> 1.8145  accuracy: 40.48% -> 40.48%     
client [71] (testset)   loss: 1.8107 -> 1.9066  accuracy: 45.45% -> 45.45%     
client [89] (testset)   loss: 1.9266 -> 1.9284  accuracy: 37.76% -> 37.76%     
---------------------------- TRAINING EPOCH: 280 ----------------------------  
client [78] (testset)   loss: 1.6673 -> 1.6693  accuracy: 31.08% -> 31.98%     
client [81] (testset)   loss: 1.5630 -> 1.5648  accuracy: 38.50% -> 38.50%     
client [51] (testset)   loss: 1.8393 -> 1.8701  accuracy: 39.19% -> 39.19%     
client [54] (testset)   loss: 1.5957 -> 1.5989  accuracy: 36.16% -> 36.16%     
client [65] (testset)   loss: 1.9207 -> 1.9440  accuracy: 37.96% -> 37.96%     
client [41] (testset)   loss: 1.4701 -> 1.4875  accuracy: 39.88% -> 39.88%     
client [11] (testset)   loss: 1.6918 -> 1.6951  accuracy: 33.94% -> 33.94%     
client [85] (testset)   loss: 1.7674 -> 1.7587  accuracy: 30.29% -> 30.29%     
client [12] (testset)   loss: 1.9352 -> 1.9292  accuracy: 23.62% -> 23.62%     
client [23] (testset)   loss: 1.1636 -> 1.1892  accuracy: 61.22% -> 61.22%     
---------------------------- TRAINING EPOCH: 290 ----------------------------  
client [16] (testset)   loss: 1.8923 -> 1.9055  accuracy: 29.66% -> 29.66%     
client [65] (testset)   loss: 1.9369 -> 1.9348  accuracy: 37.96% -> 37.96%     
client [53] (testset)   loss: 1.5768 -> 1.5726  accuracy: 36.92% -> 36.92%     
client [58] (testset)   loss: 1.8283 -> 1.8789  accuracy: 44.84% -> 44.84%     
client [72] (testset)   loss: 1.4549 -> 1.4458  accuracy: 57.50% -> 57.50%     
client [7]  (testset)   loss: 1.2869 -> 1.2855  accuracy: 61.40% -> 61.40%     
client [71] (testset)   loss: 1.8176 -> 1.8221  accuracy: 45.45% -> 45.45%     
client [59] (testset)   loss: 1.5261 -> 1.5299  accuracy: 41.52% -> 41.52%     
client [86] (testset)   loss: 1.8440 -> 1.8348  accuracy: 32.91% -> 32.91%     
client [39] (testset)   loss: 1.7976 -> 1.8085  accuracy: 24.55% -> 24.55%     
---------------------------- TRAINING EPOCH: 300 ----------------------------  
client [99] (testset)   loss: 1.9794 -> 2.0310  accuracy: 31.58% -> 31.58%     
client [7]  (testset)   loss: 1.2905 -> 1.3935  accuracy: 61.40% -> 61.40%     
client [17] (testset)   loss: 1.5308 -> 1.8450  accuracy: 58.91% -> 58.91%     
client [64] (testset)   loss: 1.7880 -> 1.7598  accuracy: 42.50% -> 42.50%     
client [37] (testset)   loss: 1.4767 -> 1.4493  accuracy: 60.33% -> 60.33%     
client [29] (testset)   loss: 1.5977 -> 1.5916  accuracy: 35.83% -> 35.83%     
client [93] (testset)   loss: 1.0901 -> 1.1224  accuracy: 70.93% -> 70.93%     
client [73] (testset)   loss: 1.3246 -> 1.3266  accuracy: 50.21% -> 50.21%     
client [40] (testset)   loss: 1.8461 -> 1.8454  accuracy: 27.00% -> 27.00%     
client [76] (testset)   loss: 1.8413 -> 1.8452  accuracy: 18.75% -> 31.25%     
---------------------------- TRAINING EPOCH: 310 ----------------------------  
client [31] (testset)   loss: 1.4614 -> 1.4522  accuracy: 58.87% -> 58.87%     
client [89] (testset)   loss: 1.9448 -> 1.9908  accuracy: 37.76% -> 37.76%     
client [77] (testset)   loss: 1.7046 -> 1.6992  accuracy: 26.25% -> 26.25%     
client [90] (testset)   loss: 1.4927 -> 1.4988  accuracy: 40.28% -> 40.28%     
client [26] (testset)   loss: 1.0645 -> 1.1093  accuracy: 70.51% -> 70.51%     
client [50] (testset)   loss: 1.6647 -> 1.6806  accuracy: 38.83% -> 38.83%     
client [30] (testset)   loss: 1.6952 -> 1.6874  accuracy: 46.04% -> 46.04%     
client [70] (testset)   loss: 1.8171 -> 1.8222  accuracy: 34.53% -> 34.53%     
client [41] (testset)   loss: 1.4704 -> 1.4778  accuracy: 39.88% -> 39.88%     
client [99] (testset)   loss: 2.0768 -> 2.0291  accuracy: 31.58% -> 31.58%     
---------------------------- TRAINING EPOCH: 320 ----------------------------  
client [68] (testset)   loss: 1.7660 -> 1.7735  accuracy: 41.84% -> 41.84%     
client [70] (testset)   loss: 1.8190 -> 1.8171  accuracy: 34.53% -> 34.53%     
client [52] (testset)   loss: 1.9666 -> 1.9648  accuracy: 18.92% -> 20.27%     
client [1]  (testset)   loss: 1.7057 -> 1.6934  accuracy: 28.57% -> 28.57%     
client [2]  (testset)   loss: 1.9618 -> 1.9880  accuracy: 28.09% -> 28.09%     
client [67] (testset)   loss: 1.6001 -> 1.6376  accuracy: 37.43% -> 37.43%     
client [92] (testset)   loss: 1.8202 -> 1.8664  accuracy: 47.44% -> 47.44%     
client [35] (testset)   loss: 1.6333 -> 1.6422  accuracy: 36.16% -> 36.16%     
client [36] (testset)   loss: 1.8392 -> 1.8355  accuracy: 32.58% -> 32.58%     
client [64] (testset)   loss: 1.7617 -> 1.7508  accuracy: 42.50% -> 42.50%     
---------------------------- TRAINING EPOCH: 330 ----------------------------  
client [44] (testset)   loss: 1.4895 -> 1.5445  accuracy: 57.08% -> 57.08%     
client [6]  (testset)   loss: 2.0711 -> 2.1023  accuracy: 20.54% -> 21.43%     
client [12] (testset)   loss: 1.9292 -> 1.9266  accuracy: 23.62% -> 23.62%     
client [55] (testset)   loss: 1.1248 -> 1.1242  accuracy: 61.80% -> 61.80%     
client [29] (testset)   loss: 1.5935 -> 1.5898  accuracy: 35.83% -> 35.83%     
client [9]  (testset)   loss: 1.8234 -> 1.8238  accuracy: 34.72% -> 34.72%     
client [43] (testset)   loss: 1.5606 -> 1.5465  accuracy: 46.33% -> 46.33%     
client [77] (testset)   loss: 1.6956 -> 1.6980  accuracy: 26.25% -> 26.25%     
client [98] (testset)   loss: 1.7607 -> 1.7563  accuracy: 45.03% -> 45.03%     
client [78] (testset)   loss: 1.6764 -> 1.7142  accuracy: 31.98% -> 31.98%     
---------------------------- TRAINING EPOCH: 340 ----------------------------  
client [92] (testset)   loss: 1.8536 -> 1.8305  accuracy: 47.44% -> 47.44%     
client [80] (testset)   loss: 1.6778 -> 1.6757  accuracy: 52.67% -> 52.67%     
client [63] (testset)   loss: 1.9557 -> 1.9514  accuracy: 38.52% -> 38.52%     
client [76] (testset)   loss: 1.8198 -> 1.8266  accuracy: 18.75% -> 31.25%     
client [78] (testset)   loss: 1.6660 -> 1.6699  accuracy: 31.98% -> 31.98%     
client [25] (testset)   loss: 1.7596 -> 1.7574  accuracy: 38.46% -> 38.46%     
client [58] (testset)   loss: 1.8228 -> 1.8316  accuracy: 44.84% -> 44.84%     
client [13] (testset)   loss: 1.3718 -> 1.3997  accuracy: 41.67% -> 41.67%     
client [17] (testset)   loss: 1.5590 -> 1.5027  accuracy: 58.91% -> 58.91%     
client [38] (testset)   loss: 1.0259 -> 1.0309  accuracy: 73.33% -> 73.33%     
---------------------------- TRAINING EPOCH: 350 ----------------------------  
client [72] (testset)   loss: 1.4475 -> 1.4648  accuracy: 57.50% -> 57.50%     
client [82] (testset)   loss: 1.7188 -> 1.7165  accuracy: 28.21% -> 28.21%     
client [86] (testset)   loss: 1.8371 -> 1.8361  accuracy: 32.91% -> 32.91%     
client [51] (testset)   loss: 1.8537 -> 1.8438  accuracy: 39.19% -> 39.19%     
client [96] (testset)   loss: 1.2682 -> 1.2661  accuracy: 58.85% -> 58.85%     
client [42] (testset)   loss: 1.7949 -> 1.8015  accuracy: 33.02% -> 33.02%     
client [55] (testset)   loss: 1.1455 -> 1.1215  accuracy: 61.80% -> 61.80%     
client [13] (testset)   loss: 1.3592 -> 1.3585  accuracy: 41.67% -> 41.67%     
client [1]  (testset)   loss: 1.7104 -> 1.6958  accuracy: 28.57% -> 28.57%     
client [12] (testset)   loss: 1.9332 -> 1.9276  accuracy: 23.62% -> 23.62%     
---------------------------- TRAINING EPOCH: 360 ----------------------------  
client [68] (testset)   loss: 1.7751 -> 1.7992  accuracy: 41.84% -> 41.84%     
client [23] (testset)   loss: 1.1701 -> 1.1754  accuracy: 61.22% -> 61.22%     
client [46] (testset)   loss: 1.8882 -> 1.8918  accuracy: 23.38% -> 23.38%     
client [41] (testset)   loss: 1.4876 -> 1.4769  accuracy: 39.88% -> 39.88%     
client [25] (testset)   loss: 1.7599 -> 1.7658  accuracy: 38.46% -> 38.46%     
client [58] (testset)   loss: 1.8107 -> 1.8044  accuracy: 44.84% -> 44.84%     
client [14] (testset)   loss: 1.6808 -> 1.7000  accuracy: 41.94% -> 41.94%     
client [33] (testset)   loss: 1.9110 -> 1.9100  accuracy: 27.38% -> 27.38%     
client [85] (testset)   loss: 1.7722 -> 1.7794  accuracy: 30.29% -> 30.29%     
client [62] (testset)   loss: 1.4910 -> 1.5026  accuracy: 55.56% -> 55.56%     
---------------------------- TRAINING EPOCH: 370 ----------------------------  
client [98] (testset)   loss: 1.7570 -> 1.7589  accuracy: 45.03% -> 45.03%     
client [63] (testset)   loss: 1.9527 -> 1.9551  accuracy: 38.52% -> 38.52%     
client [70] (testset)   loss: 1.8183 -> 1.8370  accuracy: 34.53% -> 34.53%     
client [65] (testset)   loss: 1.9285 -> 1.9289  accuracy: 37.96% -> 37.96%     
client [14] (testset)   loss: 1.6759 -> 1.6838  accuracy: 41.94% -> 41.94%     
client [73] (testset)   loss: 1.3232 -> 1.3334  accuracy: 50.21% -> 50.21%     
client [34] (testset)   loss: 1.7958 -> 1.8004  accuracy: 40.48% -> 40.48%     
client [99] (testset)   loss: 2.0010 -> 1.9837  accuracy: 31.58% -> 31.58%     
client [69] (testset)   loss: 1.8701 -> 1.8797  accuracy: 34.13% -> 34.13%     
client [46] (testset)   loss: 1.8911 -> 1.9088  accuracy: 23.38% -> 23.38%     
---------------------------- TRAINING EPOCH: 380 ----------------------------  
client [99] (testset)   loss: 2.1110 -> 2.0089  accuracy: 31.58% -> 31.58%     
client [93] (testset)   loss: 1.1002 -> 1.1705  accuracy: 70.93% -> 70.93%     
client [11] (testset)   loss: 1.6937 -> 1.7018  accuracy: 33.94% -> 33.94%     
client [58] (testset)   loss: 1.8128 -> 1.8195  accuracy: 44.84% -> 44.84%     
client [81] (testset)   loss: 1.5626 -> 1.5823  accuracy: 38.50% -> 38.50%     
client [85] (testset)   loss: 1.7785 -> 1.7813  accuracy: 30.29% -> 30.29%     
client [89] (testset)   loss: 1.9668 -> 1.9337  accuracy: 37.76% -> 37.76%     
client [45] (testset)   loss: 1.8699 -> 1.8743  accuracy: 23.21% -> 23.21%     
client [8]  (testset)   loss: 1.9746 -> 1.9713  accuracy: 29.22% -> 29.22%     
client [68] (testset)   loss: 1.7706 -> 1.7814  accuracy: 41.84% -> 41.84%     
---------------------------- TRAINING EPOCH: 390 ----------------------------  
client [67] (testset)   loss: 1.6272 -> 1.6146  accuracy: 37.43% -> 37.43%     
client [72] (testset)   loss: 1.4497 -> 1.5174  accuracy: 57.50% -> 57.50%     
client [1]  (testset)   loss: 1.6985 -> 1.7035  accuracy: 28.57% -> 28.57%     
client [78] (testset)   loss: 1.6696 -> 1.6660  accuracy: 31.98% -> 31.98%     
client [83] (testset)   loss: 1.3166 -> 1.3213  accuracy: 63.04% -> 63.04%     
client [21] (testset)   loss: 1.9949 -> 1.9951  accuracy: 21.01% -> 21.01%     
client [56] (testset)   loss: 1.4597 -> 1.4618  accuracy: 47.30% -> 47.30%     
client [44] (testset)   loss: 1.5301 -> 1.5481  accuracy: 57.08% -> 57.08%     
client [92] (testset)   loss: 1.8570 -> 1.8245  accuracy: 47.44% -> 47.44%     
client [27] (testset)   loss: 2.0377 -> 2.0340  accuracy: 27.12% -> 27.12%     
---------------------------- TRAINING EPOCH: 400 ----------------------------  
client [10] (testset)   loss: 1.1440 -> 1.1430  accuracy: 64.38% -> 64.38%     
client [39] (testset)   loss: 1.7869 -> 1.7961  accuracy: 24.55% -> 24.55%     
client [65] (testset)   loss: 1.9276 -> 1.9311  accuracy: 37.96% -> 37.96%     
client [26] (testset)   loss: 1.0594 -> 1.0575  accuracy: 70.51% -> 70.51%     
client [19] (testset)   loss: 1.7984 -> 1.7945  accuracy: 38.38% -> 38.38%     
client [68] (testset)   loss: 1.7721 -> 1.7692  accuracy: 41.84% -> 41.84%     
client [41] (testset)   loss: 1.4698 -> 1.4705  accuracy: 36.81% -> 39.88%     
client [50] (testset)   loss: 1.6622 -> 1.6789  accuracy: 38.83% -> 38.83%     
client [75] (testset)   loss: 1.0370 -> 1.1098  accuracy: 65.00% -> 65.00%     
client [81] (testset)   loss: 1.5627 -> 1.5599  accuracy: 38.50% -> 38.50%     
FedRep's average time taken by each global epoch: 0 min 2.92 sec.              
FedRep's total running time: 0 h 21 m 20 s.                                    
==================== FedRep Experiment Results: ====================           
Display format: (before local fine-tuning) -> (after local fine-tuning)        
 So if finetune_epoch = 0, x.xx% -> 0.00% is normal.                           
 Centralized testing ONLY happens after model aggregation, so the stats between
'->' are the same.                                                             
{                                                                              
    "100": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.6569 -> 1.6525",                                    
                "accuracy": "40.49% -> 40.28%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "200": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.6545 -> 1.6490",                                    
                "accuracy": "40.78% -> 41.07%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "300": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.6530 -> 1.6483",                                    
                "accuracy": "40.99% -> 41.23%"                                 
            }                                                                  
        }                                                                      
    },                                                                         
    "400": {                                                                   
        "all_clients": {                                                       
            "test": {                                                          
                "loss": "1.6511 -> 1.6492",                                    
                "accuracy": "41.20% -> 41.08%"                                 
            }                                                                  
        }                                                                      
    }                                                                          
}                                                                              
==================== FedRep Max Accuracy ====================                  
all_clients:                                                                   
(test) before fine-tuning: 41.20% at epoch 400                                 
(test) after fine-tuning: 41.23% at epoch 300                                  
